
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="wiseodd">
      
      
        <link rel="canonical" href="https://aleximmer.github.io/Laplace/api_reference/lllaplace/">
      
      
        <link rel="prev" href="../functionallaplace/">
      
      
        <link rel="next" href="../subnetlaplace/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>Last-Layer Laplace - laplace-torch</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../css/mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#laplace.lllaplace" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="laplace-torch" class="md-header__button md-logo" aria-label="laplace-torch" data-md-component="logo">
      
  <img src="../../assets/laplace_logo_inv.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            laplace-torch
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Last-Layer Laplace
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/aleximmer/laplace" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    laplace
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="laplace-torch" class="md-nav__button md-logo" aria-label="laplace-torch" data-md-component="logo">
      
  <img src="../../assets/laplace_logo_inv.png" alt="logo">

    </a>
    laplace-torch
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/aleximmer/laplace" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    laplace
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../devs_guide/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Developer's Guide
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../regression_example/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Example: Regression
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../calibration_example/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Example: Calibration
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../calibration_gp_example/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Example: GP Inference
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../huggingface_example/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Example: Huggingface LLMs
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reward_modeling_example/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Example: Reward Modeling
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" checked>
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../laplace/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Laplace Frontend
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../enums/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Laplace Options
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../baselaplace/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Base Laplace
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../parametriclaplace/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parametric Laplace
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../functionallaplace/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Functional Laplace
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Last-Layer Laplace
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Last-Layer Laplace
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LLLaplace
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" LLLaplace">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(model)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(likelihood)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(sigma_noise)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;sigma_noise
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(prior_precision)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(prior_mean)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;prior_mean
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(temperature)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;temperature
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(enable_backprop)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;enable_backprop
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(feature_reduction)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;feature_reduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(dict_key_x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;dict_key_x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(dict_key_y)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;dict_key_y
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(backend)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;backend
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(last_layer_name)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;last_layer_name
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(backend_kwargs)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;backend_kwargs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.scatter" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;scatter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_det_prior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_det_posterior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_posterior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_det_ratio" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_ratio
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.posterior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.prior_precision_diag" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;prior_precision_diag
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_marginal_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_marginal_likelihood
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_marginal_likelihood">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_marginal_likelihood(prior_precision)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_marginal_likelihood(sigma_noise)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;sigma_noise
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__call__
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" __call__">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(fitting)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;fitting
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_forward_call
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_forward_call">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call(likelihood)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.square_norm" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;square_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_prob" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_prob
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_prob">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_prob(value)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;value
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_prob(normalized)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;normalized
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.predictive_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.predictive_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_variance" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_variance
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_variance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_variance(Js)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;Js
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_covariance
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_covariance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_covariance(Js)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;Js
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.sample" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;sample
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" sample">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.sample(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.sample(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.fit" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.fit(train_loader)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;train_loader
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.fit(override)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;override
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.fit(progress_bar)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;progress_bar
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_variance_fast" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_variance_fast
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_variance_fast">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_variance_fast(X)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;X
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DiagLLLaplace
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" DiagLLLaplace">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.prior_precision_diag" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;prior_precision_diag
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.scatter" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;scatter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_det_prior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_det_ratio" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_ratio
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.posterior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.posterior_scale" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_scale
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.posterior_variance" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_variance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.fit" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.fit(train_loader)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;train_loader
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.fit(override)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;override
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.fit(progress_bar)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;progress_bar
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_marginal_likelihood
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_marginal_likelihood">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood(prior_precision)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood(sigma_noise)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;sigma_noise
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__call__
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" __call__">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(fitting)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;fitting
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_forward_call
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_forward_call">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(likelihood)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_prob" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_prob
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_prob">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_prob(value)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;value
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_prob(normalized)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;normalized
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;KronLLLaplace
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" KronLLLaplace">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.prior_precision_diag" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;prior_precision_diag
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.scatter" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;scatter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_det_prior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_det_ratio" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_ratio
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.posterior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.fit" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.fit(train_loader)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;train_loader
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.fit(override)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;override
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.fit(progress_bar)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;progress_bar
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_marginal_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_marginal_likelihood
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_marginal_likelihood">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_marginal_likelihood(prior_precision)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_marginal_likelihood(sigma_noise)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;sigma_noise
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__call__
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" __call__">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(fitting)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;fitting
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_forward_call
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_forward_call">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(likelihood)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_prob" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_prob
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_prob">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_prob(value)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;value
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_prob(normalized)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;normalized
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.functional_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.functional_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;FullLLLaplace
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" FullLLLaplace">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.prior_precision_diag" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;prior_precision_diag
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.scatter" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;scatter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_det_prior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_det_ratio" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_ratio
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.posterior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.posterior_scale" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_scale
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.posterior_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_covariance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.fit" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.fit(train_loader)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;train_loader
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.fit(override)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;override
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.fit(progress_bar)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;progress_bar
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_marginal_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_marginal_likelihood
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_marginal_likelihood">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_marginal_likelihood(prior_precision)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_marginal_likelihood(sigma_noise)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;sigma_noise
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__call__
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" __call__">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(fitting)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;fitting
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_forward_call
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_forward_call">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(likelihood)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_prob" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_prob
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_prob">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_prob(value)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;value
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_prob(normalized)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;normalized
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_variance_fast" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_variance_fast
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_variance_fast">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_variance_fast(X)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;X
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../subnetlaplace/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Subnet Laplace
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../curvatures/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Curvatures
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../marglik_training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Marglik Training Utils
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utilities
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;LLLaplace
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" LLLaplace">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(model)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;model
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(likelihood)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(sigma_noise)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;sigma_noise
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(prior_precision)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(prior_mean)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;prior_mean
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(temperature)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;temperature
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(enable_backprop)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;enable_backprop
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(feature_reduction)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;feature_reduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(dict_key_x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;dict_key_x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(dict_key_y)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;dict_key_y
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(backend)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;backend
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(last_layer_name)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;last_layer_name
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace(backend_kwargs)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;backend_kwargs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.scatter" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;scatter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_det_prior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_det_posterior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_posterior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_det_ratio" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_ratio
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.posterior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.prior_precision_diag" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;prior_precision_diag
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_marginal_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_marginal_likelihood
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_marginal_likelihood">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_marginal_likelihood(prior_precision)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_marginal_likelihood(sigma_noise)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;sigma_noise
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__call__
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" __call__">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.__call__(fitting)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;fitting
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_forward_call
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_forward_call">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call(likelihood)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_forward_call(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.square_norm" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;square_norm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_prob" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_prob
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_prob">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_prob(value)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;value
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.log_prob(normalized)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;normalized
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.predictive_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.predictive_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_variance" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_variance
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_variance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_variance(Js)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;Js
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_covariance
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_covariance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_covariance(Js)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;Js
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.sample" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;sample
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" sample">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.sample(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.sample(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.fit" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.fit(train_loader)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;train_loader
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.fit(override)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;override
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.fit(progress_bar)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;progress_bar
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_variance_fast" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_variance_fast
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_variance_fast">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.LLLaplace.functional_variance_fast(X)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;X
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DiagLLLaplace
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" DiagLLLaplace">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.prior_precision_diag" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;prior_precision_diag
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.scatter" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;scatter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_det_prior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_det_ratio" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_ratio
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.posterior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.posterior_scale" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_scale
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.posterior_variance" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_variance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.fit" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.fit(train_loader)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;train_loader
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.fit(override)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;override
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.fit(progress_bar)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;progress_bar
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_marginal_likelihood
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_marginal_likelihood">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood(prior_precision)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood(sigma_noise)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;sigma_noise
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__call__
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" __call__">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.__call__(fitting)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;fitting
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_forward_call
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_forward_call">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(likelihood)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_prob" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_prob
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_prob">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_prob(value)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;value
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.log_prob(normalized)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;normalized
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;KronLLLaplace
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" KronLLLaplace">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.prior_precision_diag" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;prior_precision_diag
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.scatter" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;scatter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_det_prior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_det_ratio" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_ratio
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.posterior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.fit" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.fit(train_loader)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;train_loader
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.fit(override)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;override
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.fit(progress_bar)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;progress_bar
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_marginal_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_marginal_likelihood
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_marginal_likelihood">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_marginal_likelihood(prior_precision)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_marginal_likelihood(sigma_noise)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;sigma_noise
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__call__
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" __call__">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.__call__(fitting)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;fitting
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_forward_call
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_forward_call">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(likelihood)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_prob" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_prob
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_prob">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_prob(value)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;value
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.log_prob(normalized)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;normalized
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.functional_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.functional_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;FullLLLaplace
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" FullLLLaplace">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.prior_precision_diag" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;prior_precision_diag
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.scatter" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;scatter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_det_prior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_det_ratio" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;log_det_ratio
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.posterior_precision" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.posterior_scale" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_scale
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.posterior_covariance" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;posterior_covariance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.fit" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.fit(train_loader)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;train_loader
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.fit(override)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;override
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.fit(progress_bar)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;progress_bar
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_marginal_likelihood" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_marginal_likelihood
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_marginal_likelihood">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_marginal_likelihood(prior_precision)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;prior_precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_marginal_likelihood(sigma_noise)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;sigma_noise
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__call__
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" __call__">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.__call__(fitting)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;fitting
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_forward_call
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_forward_call">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(likelihood)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;likelihood
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(link_approx)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;link_approx
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(joint)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;joint
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;_glm_predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" _glm_predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(f_mu)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_mu
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(f_var)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;f_var
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_prob" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;log_prob
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" log_prob">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_prob(value)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;value
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.log_prob(normalized)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;normalized
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.predictive_samples" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;predictive_samples
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" predictive_samples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(x)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;x
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(pred_type)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;pred_type
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(n_samples)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;n_samples
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(diagonal_output)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;diagonal_output
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(generator)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;generator
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_variance_fast" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;functional_variance_fast
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" functional_variance_fast">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#laplace.lllaplace.FullLLLaplace.functional_variance_fast(X)" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-parameter"></code>&nbsp;X
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<div class="doc doc-object doc-module">



<h1 id="laplace.lllaplace" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">laplace.lllaplace</span>


<a href="#laplace.lllaplace" class="headerlink" title="Permanent link">#</a></h1>

    <div class="doc doc-contents first">







<p><span class="doc-section-title">Classes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace" href="#laplace.lllaplace.LLLaplace">LLLaplace</a></code></b>
          –
          <div class="doc-md-description">
            <p>Baseclass for all last-layer Laplace approximations in this library.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace" href="#laplace.lllaplace.DiagLLLaplace">DiagLLLaplace</a></code></b>
          –
          <div class="doc-md-description">
            <p>Last-layer Laplace approximation with diagonal log likelihood Hessian approximation</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace" href="#laplace.lllaplace.KronLLLaplace">KronLLLaplace</a></code></b>
          –
          <div class="doc-md-description">
            <p>Last-layer Laplace approximation with Kronecker factored log likelihood Hessian approximation</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace" href="#laplace.lllaplace.FullLLLaplace">FullLLLaplace</a></code></b>
          –
          <div class="doc-md-description">
            <p>Last-layer Laplace approximation with full, i.e., dense, log likelihood Hessian approximation</p>
          </div>
        </li>
    </ul>







  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="laplace.lllaplace.LLLaplace" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">LLLaplace</span>


<a href="#laplace.lllaplace.LLLaplace" class="headerlink" title="Permanent link">#</a></h2>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">LLLaplace</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(model)">model</a></span><span class="p">:</span> <span class="n"><span title="torch.nn.Module">Module</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(likelihood)">likelihood</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(sigma_noise)">sigma_noise</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(prior_precision)">prior_precision</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(prior_mean)">prior_mean</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(temperature)">temperature</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(enable_backprop)">enable_backprop</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(feature_reduction)">feature_reduction</a></span><span class="p">:</span> <span class="n"><span title="laplace.utils.feature_extractor.FeatureReduction">FeatureReduction</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(dict_key_x)">dict_key_x</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(dict_key_y)">dict_key_y</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="s1">&#39;labels&#39;</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(backend)">backend</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#type">type</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="laplace.curvature.curvature.CurvatureInterface" href="../curvatures/#laplace.curvature.CurvatureInterface">CurvatureInterface</a></span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(last_layer_name)">last_layer_name</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace(backend_kwargs)">backend_kwargs</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">asdl_fisher_kwargs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="laplace.baselaplace.ParametricLaplace" href="../parametriclaplace/#laplace.baselaplace.ParametricLaplace">ParametricLaplace</a></code></p>


        <p>Baseclass for all last-layer Laplace approximations in this library.
Subclasses specify the structure of the Hessian approximation.
See <code>BaseLaplace</code> for the full interface.</p>
<p>A Laplace approximation is represented by a MAP which is given by the
<code>model</code> parameter and a posterior precision or covariance specifying
a Gaussian distribution <span class="arithmatex">\(\mathcal{N}(\theta_{MAP}, P^{-1})\)</span>.
Here, only the parameters of the last layer of the neural network
are treated probabilistically.
The goal of this class is to compute the posterior precision <span class="arithmatex">\(P\)</span>
which sums as</p>
<div class="arithmatex">\[
    P = \sum_{n=1}^N \nabla^2_\theta \log p(\mathcal{D}_n \mid \theta)
    \vert_{\theta_{MAP}} + \nabla^2_\theta \log p(\theta) \vert_{\theta_{MAP}}.
\]</div>
<p>Every subclass implements different approximations to the log likelihood Hessians,
for example, a diagonal one. The prior is assumed to be Gaussian and therefore we have
a simple form for <span class="arithmatex">\(\nabla^2_\theta \log p(\theta) \vert_{\theta_{MAP}} = P_0 \)</span>.
In particular, we assume a scalar or diagonal prior precision so that in
all cases <span class="arithmatex">\(P_0 = \textrm{diag}(p_0)\)</span> and the structure of <span class="arithmatex">\(p_0\)</span> can be varied.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(model)" class="doc doc-heading doc-heading-parameter">              <b><code>model</code></b>
<a href="#laplace.lllaplace.LLLaplace(model)" class="headerlink" title="Permanent link">#</a></h3>              (<code>torch.nn.Module or `laplace.utils.feature_extractor.FeatureExtractor`</code>)
          –
          <div class="doc-md-description">
            
          </div>
        </li>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(likelihood)" class="doc doc-heading doc-heading-parameter">              <b><code>likelihood</code></b>
<a href="#laplace.lllaplace.LLLaplace(likelihood)" class="headerlink" title="Permanent link">#</a></h3>              (<code><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a> or {&#39;classification&#39;, &#39;regression&#39;}</code>)
          –
          <div class="doc-md-description">
            <p>determines the log likelihood Hessian approximation</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(sigma_noise)" class="doc doc-heading doc-heading-parameter">              <b><code>sigma_noise</code></b>
<a href="#laplace.lllaplace.LLLaplace(sigma_noise)" class="headerlink" title="Permanent link">#</a></h3>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>, default:
                  <code>1</code>
)
          –
          <div class="doc-md-description">
            <p>observation noise for the regression setting; must be 1 for classification</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(prior_precision)" class="doc doc-heading doc-heading-parameter">              <b><code>prior_precision</code></b>
<a href="#laplace.lllaplace.LLLaplace(prior_precision)" class="headerlink" title="Permanent link">#</a></h3>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>, default:
                  <code>1</code>
)
          –
          <div class="doc-md-description">
            <p>prior precision of a Gaussian prior (= weight decay);
can be scalar, per-layer, or diagonal in the most general case</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(prior_mean)" class="doc doc-heading doc-heading-parameter">              <b><code>prior_mean</code></b>
<a href="#laplace.lllaplace.LLLaplace(prior_mean)" class="headerlink" title="Permanent link">#</a></h3>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>, default:
                  <code>0</code>
)
          –
          <div class="doc-md-description">
            <p>prior mean of a Gaussian prior, useful for continual learning</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(temperature)" class="doc doc-heading doc-heading-parameter">              <b><code>temperature</code></b>
<a href="#laplace.lllaplace.LLLaplace(temperature)" class="headerlink" title="Permanent link">#</a></h3>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>, default:
                  <code>1</code>
)
          –
          <div class="doc-md-description">
            <p>temperature of the likelihood; lower temperature leads to more
concentrated posterior and vice versa.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(enable_backprop)" class="doc doc-heading doc-heading-parameter">              <b><code>enable_backprop</code></b>
<a href="#laplace.lllaplace.LLLaplace(enable_backprop)" class="headerlink" title="Permanent link">#</a></h3>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to enable backprop to the input <code>x</code> through the Laplace predictive.
Useful for e.g. Bayesian optimization.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(feature_reduction)" class="doc doc-heading doc-heading-parameter">              <b><code>feature_reduction</code></b>
<a href="#laplace.lllaplace.LLLaplace(feature_reduction)" class="headerlink" title="Permanent link">#</a></h3>              (<code><span title="laplace.utils.feature_extractor.FeatureReduction">FeatureReduction</span> | <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>when the last-layer <code>features</code> is a tensor of dim &gt;= 3, this tells how to reduce
it into a dim-2 tensor. E.g. in LLMs for non-language modeling problems,
the penultultimate output is a tensor of shape <code>(batch_size, seq_len, embd_dim)</code>.
But the last layer maps <code>(batch_size, embd_dim)</code> to <code>(batch_size, n_classes)</code>.
Note: Make sure that this option faithfully reflects the reduction in the model
definition. When inputting a string, available options are
<code>{'pick_first', 'pick_last', 'average'}</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(dict_key_x)" class="doc doc-heading doc-heading-parameter">              <b><code>dict_key_x</code></b>
<a href="#laplace.lllaplace.LLLaplace(dict_key_x)" class="headerlink" title="Permanent link">#</a></h3>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></code>, default:
                  <code>&#39;input_ids&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>The dictionary key under which the input tensor <code>x</code> is stored. Only has effect
when the model takes a <code>MutableMapping</code> as the input. Useful for Huggingface
LLM models.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(dict_key_y)" class="doc doc-heading doc-heading-parameter">              <b><code>dict_key_y</code></b>
<a href="#laplace.lllaplace.LLLaplace(dict_key_y)" class="headerlink" title="Permanent link">#</a></h3>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></code>, default:
                  <code>&#39;labels&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>The dictionary key under which the target tensor <code>y</code> is stored. Only has effect
when the model takes a <code>MutableMapping</code> as the input. Useful for Huggingface
LLM models.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(backend)" class="doc doc-heading doc-heading-parameter">              <b><code>backend</code></b>
<a href="#laplace.lllaplace.LLLaplace(backend)" class="headerlink" title="Permanent link">#</a></h3>              (<code>subclasses of `laplace.curvature.CurvatureInterface`</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>backend for access to curvature/Hessian approximations</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(last_layer_name)" class="doc doc-heading doc-heading-parameter">              <b><code>last_layer_name</code></b>
<a href="#laplace.lllaplace.LLLaplace(last_layer_name)" class="headerlink" title="Permanent link">#</a></h3>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a> | None</code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>name of the model's last layer, if None it will be determined automatically</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h3 id="laplace.lllaplace.LLLaplace(backend_kwargs)" class="doc doc-heading doc-heading-parameter">              <b><code>backend_kwargs</code></b>
<a href="#laplace.lllaplace.LLLaplace(backend_kwargs)" class="headerlink" title="Permanent link">#</a></h3>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>arguments passed to the backend on initialization, for example to
set the number of MC samples for stochastic approximations.</p>
          </div>
        </li>
    </ul>









<p><span class="doc-section-title">Methods:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.log_marginal_likelihood" href="#laplace.lllaplace.LLLaplace.log_marginal_likelihood">log_marginal_likelihood</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the Laplace approximation to the log marginal likelihood subject</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.__call__" href="#laplace.lllaplace.LLLaplace.__call__">__call__</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the posterior predictive on input data <code>x</code>.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.square_norm" href="#laplace.lllaplace.LLLaplace.square_norm">square_norm</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the square norm under post. Precision with <code>value-self.mean</code> as 𝛥:</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.log_prob" href="#laplace.lllaplace.LLLaplace.log_prob">log_prob</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the log probability under the (current) Laplace approximation.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.functional_samples" href="#laplace.lllaplace.LLLaplace.functional_samples">functional_samples</a></code></b>
            –
            <div class="doc-md-description">
              <p>Sample from the function-space posterior on input data <code>x</code>.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.predictive_samples" href="#laplace.lllaplace.LLLaplace.predictive_samples">predictive_samples</a></code></b>
            –
            <div class="doc-md-description">
              <p>Sample from the posterior predictive on input data <code>x</code>. I.e., the respective</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.functional_variance" href="#laplace.lllaplace.LLLaplace.functional_variance">functional_variance</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute functional variance for the <code>'glm'</code> predictive:</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.functional_covariance" href="#laplace.lllaplace.LLLaplace.functional_covariance">functional_covariance</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute functional covariance for the <code>'glm'</code> predictive:</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.sample" href="#laplace.lllaplace.LLLaplace.sample">sample</a></code></b>
            –
            <div class="doc-md-description">
              <p>Sample from the Laplace posterior approximation, i.e.,</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.fit" href="#laplace.lllaplace.LLLaplace.fit">fit</a></code></b>
            –
            <div class="doc-md-description">
              <p>Fit the local Laplace approximation at the parameters of the model.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.functional_variance_fast" href="#laplace.lllaplace.LLLaplace.functional_variance_fast">functional_variance_fast</a></code></b>
            –
            <div class="doc-md-description">
              <p>Should be overriden if there exists a trick to make this fast!</p>
            </div>
          </li>
    </ul>




<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.log_likelihood" href="#laplace.lllaplace.LLLaplace.log_likelihood">log_likelihood</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute log likelihood on the training data after <code>.fit()</code> has been called.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.scatter" href="#laplace.lllaplace.LLLaplace.scatter">scatter</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Computes the <em>scatter</em>, a term of the log marginal likelihood that</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.log_det_prior_precision" href="#laplace.lllaplace.LLLaplace.log_det_prior_precision">log_det_prior_precision</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute log determinant of the prior precision</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.log_det_posterior_precision" href="#laplace.lllaplace.LLLaplace.log_det_posterior_precision">log_det_posterior_precision</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute log determinant of the posterior precision</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.log_det_ratio" href="#laplace.lllaplace.LLLaplace.log_det_ratio">log_det_ratio</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute the log determinant ratio, a part of the log marginal likelihood.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.posterior_precision" href="#laplace.lllaplace.LLLaplace.posterior_precision">posterior_precision</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute or return the posterior precision <span class="arithmatex">\(P\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace.prior_precision_diag" href="#laplace.lllaplace.LLLaplace.prior_precision_diag">prior_precision_diag</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Obtain the diagonal prior precision <span class="arithmatex">\(p_0\)</span> constructed from either</p>
          </div>
        </li>
    </ul>

                  <details class="quote">
                    <summary>Source code in <code>laplace/lllaplace.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>    <span class="n">likelihood</span><span class="p">:</span> <span class="n">Likelihood</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="n">sigma_noise</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>    <span class="n">prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="n">enable_backprop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="n">feature_reduction</span><span class="p">:</span> <span class="n">FeatureReduction</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="n">dict_key_x</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="n">dict_key_y</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="n">backend</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">CurvatureInterface</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="n">last_layer_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="n">backend_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="n">asdl_fisher_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="p">):</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="k">if</span> <span class="n">asdl_fisher_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Last-layer Laplace does not support asdl_fisher_kwargs.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">H</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>        <span class="n">model</span><span class="p">,</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>        <span class="n">likelihood</span><span class="p">,</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>        <span class="n">sigma_noise</span><span class="o">=</span><span class="n">sigma_noise</span><span class="p">,</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>        <span class="n">prior_precision</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>        <span class="n">prior_mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="n">enable_backprop</span><span class="o">=</span><span class="n">enable_backprop</span><span class="p">,</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="n">dict_key_x</span><span class="o">=</span><span class="n">dict_key_x</span><span class="p">,</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>        <span class="n">dict_key_y</span><span class="o">=</span><span class="n">dict_key_y</span><span class="p">,</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>        <span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="n">backend_kwargs</span><span class="o">=</span><span class="n">backend_kwargs</span><span class="p">,</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>    <span class="p">)</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">FeatureExtractor</span><span class="p">(</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>        <span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="n">last_layer_name</span><span class="o">=</span><span class="n">last_layer_name</span><span class="p">,</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="n">enable_backprop</span><span class="o">=</span><span class="n">enable_backprop</span><span class="p">,</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>        <span class="n">feature_reduction</span><span class="o">=</span><span class="n">feature_reduction</span><span class="p">,</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>    <span class="p">)</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>        <span class="c1"># ignore checks of prior mean setter temporarily, check on .fit()</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">prior_precision</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">prior_mean</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>            <span class="n">parameters_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">prior_precision</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">prior_mean</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_init_H</span><span class="p">()</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_backend_kwargs</span><span class="p">[</span><span class="s2">&quot;last_layer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_last_layer_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="n">last_layer_name</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.LLLaplace.log_likelihood" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_likelihood</span>


<a href="#laplace.lllaplace.LLLaplace.log_likelihood" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_likelihood</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute log likelihood on the training data after <code>.fit()</code> has been called.
The log likelihood is computed on-demand based on the loss and, for example,
the observation noise which makes it differentiable in the latter for
iterative updates.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_likelihood</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.LLLaplace.scatter" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">scatter</span>


<a href="#laplace.lllaplace.LLLaplace.scatter" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">scatter</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the <em>scatter</em>, a term of the log marginal likelihood that
corresponds to L-2 regularization:
<code>scatter</code> = <span class="arithmatex">\((\theta_{MAP} - \mu_0)^{T} P_0 (\theta_{MAP} - \mu_0) \)</span>.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>scatter</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.LLLaplace.log_det_prior_precision" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_det_prior_precision</span>


<a href="#laplace.lllaplace.LLLaplace.log_det_prior_precision" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_det_prior_precision</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute log determinant of the prior precision
<span class="arithmatex">\(\log \det P_0\)</span></p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_det</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.LLLaplace.log_det_posterior_precision" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_det_posterior_precision</span>


<a href="#laplace.lllaplace.LLLaplace.log_det_posterior_precision" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_det_posterior_precision</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute log determinant of the posterior precision
<span class="arithmatex">\(\log \det P\)</span> which depends on the subclasses structure
used for the Hessian approximation.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_det</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.LLLaplace.log_det_ratio" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_det_ratio</span>


<a href="#laplace.lllaplace.LLLaplace.log_det_ratio" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_det_ratio</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the log determinant ratio, a part of the log marginal likelihood.</p>
<div class="arithmatex">\[
    \log \frac{\det P}{\det P_0} = \log \det P - \log \det P_0
\]</div>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_det_ratio</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.LLLaplace.posterior_precision" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">posterior_precision</span>


<a href="#laplace.lllaplace.LLLaplace.posterior_precision" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">posterior_precision</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute or return the posterior precision <span class="arithmatex">\(P\)</span>.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>posterior_prec</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.LLLaplace.prior_precision_diag" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">prior_precision_diag</span>


<a href="#laplace.lllaplace.LLLaplace.prior_precision_diag" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">prior_precision_diag</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Obtain the diagonal prior precision <span class="arithmatex">\(p_0\)</span> constructed from either
a scalar or diagonal prior precision.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>prior_precision_diag</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace.log_marginal_likelihood" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">log_marginal_likelihood</span>


<a href="#laplace.lllaplace.LLLaplace.log_marginal_likelihood" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">log_marginal_likelihood</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.log_marginal_likelihood(prior_precision)">prior_precision</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.log_marginal_likelihood(sigma_noise)">sigma_noise</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the Laplace approximation to the log marginal likelihood subject
to specific Hessian approximations that subclasses implement.
Requires that the Laplace approximation has been fit before.
The resulting torch.Tensor is differentiable in <code>prior_precision</code> and
<code>sigma_noise</code> if these have gradients enabled.
By passing <code>prior_precision</code> or <code>sigma_noise</code>, the current value is
overwritten. This is useful for iterating on the log marginal likelihood.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.log_marginal_likelihood(prior_precision)" class="doc doc-heading doc-heading-parameter">              <b><code>prior_precision</code></b>
<a href="#laplace.lllaplace.LLLaplace.log_marginal_likelihood(prior_precision)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>prior precision if should be changed from current <code>prior_precision</code> value</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.log_marginal_likelihood(sigma_noise)" class="doc doc-heading doc-heading-parameter">              <b><code>sigma_noise</code></b>
<a href="#laplace.lllaplace.LLLaplace.log_marginal_likelihood(sigma_noise)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>observation noise standard deviation if should be changed</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_marglik</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1018">1018</a></span>
<span class="normal"><a href="#__codelineno-0-1019">1019</a></span>
<span class="normal"><a href="#__codelineno-0-1020">1020</a></span>
<span class="normal"><a href="#__codelineno-0-1021">1021</a></span>
<span class="normal"><a href="#__codelineno-0-1022">1022</a></span>
<span class="normal"><a href="#__codelineno-0-1023">1023</a></span>
<span class="normal"><a href="#__codelineno-0-1024">1024</a></span>
<span class="normal"><a href="#__codelineno-0-1025">1025</a></span>
<span class="normal"><a href="#__codelineno-0-1026">1026</a></span>
<span class="normal"><a href="#__codelineno-0-1027">1027</a></span>
<span class="normal"><a href="#__codelineno-0-1028">1028</a></span>
<span class="normal"><a href="#__codelineno-0-1029">1029</a></span>
<span class="normal"><a href="#__codelineno-0-1030">1030</a></span>
<span class="normal"><a href="#__codelineno-0-1031">1031</a></span>
<span class="normal"><a href="#__codelineno-0-1032">1032</a></span>
<span class="normal"><a href="#__codelineno-0-1033">1033</a></span>
<span class="normal"><a href="#__codelineno-0-1034">1034</a></span>
<span class="normal"><a href="#__codelineno-0-1035">1035</a></span>
<span class="normal"><a href="#__codelineno-0-1036">1036</a></span>
<span class="normal"><a href="#__codelineno-0-1037">1037</a></span>
<span class="normal"><a href="#__codelineno-0-1038">1038</a></span>
<span class="normal"><a href="#__codelineno-0-1039">1039</a></span>
<span class="normal"><a href="#__codelineno-0-1040">1040</a></span>
<span class="normal"><a href="#__codelineno-0-1041">1041</a></span>
<span class="normal"><a href="#__codelineno-0-1042">1042</a></span>
<span class="normal"><a href="#__codelineno-0-1043">1043</a></span>
<span class="normal"><a href="#__codelineno-0-1044">1044</a></span>
<span class="normal"><a href="#__codelineno-0-1045">1045</a></span>
<span class="normal"><a href="#__codelineno-0-1046">1046</a></span>
<span class="normal"><a href="#__codelineno-0-1047">1047</a></span>
<span class="normal"><a href="#__codelineno-0-1048">1048</a></span>
<span class="normal"><a href="#__codelineno-0-1049">1049</a></span>
<span class="normal"><a href="#__codelineno-0-1050">1050</a></span>
<span class="normal"><a href="#__codelineno-0-1051">1051</a></span>
<span class="normal"><a href="#__codelineno-0-1052">1052</a></span>
<span class="normal"><a href="#__codelineno-0-1053">1053</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1018" name="__codelineno-0-1018"></a><span class="k">def</span> <span class="nf">log_marginal_likelihood</span><span class="p">(</span>
<a id="__codelineno-0-1019" name="__codelineno-0-1019"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1020" name="__codelineno-0-1020"></a>    <span class="n">prior_precision</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1021" name="__codelineno-0-1021"></a>    <span class="n">sigma_noise</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1022" name="__codelineno-0-1022"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1023" name="__codelineno-0-1023"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the Laplace approximation to the log marginal likelihood subject</span>
<a id="__codelineno-0-1024" name="__codelineno-0-1024"></a><span class="sd">    to specific Hessian approximations that subclasses implement.</span>
<a id="__codelineno-0-1025" name="__codelineno-0-1025"></a><span class="sd">    Requires that the Laplace approximation has been fit before.</span>
<a id="__codelineno-0-1026" name="__codelineno-0-1026"></a><span class="sd">    The resulting torch.Tensor is differentiable in `prior_precision` and</span>
<a id="__codelineno-0-1027" name="__codelineno-0-1027"></a><span class="sd">    `sigma_noise` if these have gradients enabled.</span>
<a id="__codelineno-0-1028" name="__codelineno-0-1028"></a><span class="sd">    By passing `prior_precision` or `sigma_noise`, the current value is</span>
<a id="__codelineno-0-1029" name="__codelineno-0-1029"></a><span class="sd">    overwritten. This is useful for iterating on the log marginal likelihood.</span>
<a id="__codelineno-0-1030" name="__codelineno-0-1030"></a>
<a id="__codelineno-0-1031" name="__codelineno-0-1031"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1032" name="__codelineno-0-1032"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1033" name="__codelineno-0-1033"></a><span class="sd">    prior_precision : torch.Tensor, optional</span>
<a id="__codelineno-0-1034" name="__codelineno-0-1034"></a><span class="sd">        prior precision if should be changed from current `prior_precision` value</span>
<a id="__codelineno-0-1035" name="__codelineno-0-1035"></a><span class="sd">    sigma_noise : torch.Tensor, optional</span>
<a id="__codelineno-0-1036" name="__codelineno-0-1036"></a><span class="sd">        observation noise standard deviation if should be changed</span>
<a id="__codelineno-0-1037" name="__codelineno-0-1037"></a>
<a id="__codelineno-0-1038" name="__codelineno-0-1038"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1039" name="__codelineno-0-1039"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1040" name="__codelineno-0-1040"></a><span class="sd">    log_marglik : torch.Tensor</span>
<a id="__codelineno-0-1041" name="__codelineno-0-1041"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1042" name="__codelineno-0-1042"></a>    <span class="c1"># update prior precision (useful when iterating on marglik)</span>
<a id="__codelineno-0-1043" name="__codelineno-0-1043"></a>    <span class="k">if</span> <span class="n">prior_precision</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1044" name="__codelineno-0-1044"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_precision</span> <span class="o">=</span> <span class="n">prior_precision</span>
<a id="__codelineno-0-1045" name="__codelineno-0-1045"></a>
<a id="__codelineno-0-1046" name="__codelineno-0-1046"></a>    <span class="c1"># update sigma_noise (useful when iterating on marglik)</span>
<a id="__codelineno-0-1047" name="__codelineno-0-1047"></a>    <span class="k">if</span> <span class="n">sigma_noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1048" name="__codelineno-0-1048"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="o">!=</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-1049" name="__codelineno-0-1049"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Can only change sigma_noise for regression.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1050" name="__codelineno-0-1050"></a>
<a id="__codelineno-0-1051" name="__codelineno-0-1051"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_noise</span> <span class="o">=</span> <span class="n">sigma_noise</span>
<a id="__codelineno-0-1052" name="__codelineno-0-1052"></a>
<a id="__codelineno-0-1053" name="__codelineno-0-1053"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_det_ratio</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scatter</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace.__call__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">__call__</span>


<a href="#laplace.lllaplace.LLLaplace.__call__" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="fm">__call__</span><span class="p">(</span><span class="nf"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.__call__(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.__call__(pred_type)">pred_type</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType" href="../enums/#laplace.utils.enums.PredType">PredType</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType.GLM" href="../enums/#laplace.utils.enums.PredType.GLM">GLM</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.__call__(joint)">joint</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.__call__(link_approx)">link_approx</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox" href="../enums/#laplace.utils.enums.LinkApprox">LinkApprox</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox.PROBIT" href="../enums/#laplace.utils.enums.LinkApprox.PROBIT">PROBIT</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.__call__(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.__call__(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.__call__(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.__call__(fitting)">fitting</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">**model_kwargs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the posterior predictive on input data <code>x</code>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.__call__(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.LLLaplace.__call__(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p><code>(batch_size, input_shape)</code> if tensor. If MutableMapping, must contain
the said tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.__call__(pred_type)" class="doc doc-heading doc-heading-parameter">              <b><code>pred_type</code></b>
<a href="#laplace.lllaplace.LLLaplace.__call__(pred_type)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;glm&#39;, &#39;nn&#39;)</code>, default:
                  <code>&#39;glm&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>type of posterior predictive, linearized GLM predictive or neural
network sampling predictive. The GLM predictive is consistent with
the curvature approximations used here. When Laplace is done only
on subset of parameters (i.e. some grad are disabled),
only <code>nn</code> predictive is supported.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.__call__(link_approx)" class="doc doc-heading doc-heading-parameter">              <b><code>link_approx</code></b>
<a href="#laplace.lllaplace.LLLaplace.__call__(link_approx)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;)</code>, default:
                  <code>&#39;mc&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>how to approximate the classification link function for the <code>'glm'</code>.
For <code>pred_type='nn'</code>, only 'mc' is possible.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.__call__(joint)" class="doc doc-heading doc-heading-parameter">              <b><code>joint</code></b>
<a href="#laplace.lllaplace.LLLaplace.__call__(joint)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to output a joint predictive distribution in regression with
<code>pred_type='glm'</code>. If set to <code>True</code>, the predictive distribution
has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).
If <code>False</code>, then only outputs the marginal predictive distribution.
Only available for regression and GLM predictive.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.__call__(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.LLLaplace.__call__(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples for <code>link_approx='mc'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.__call__(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.LLLaplace.__call__(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized posterior predictive on the outputs.
Only works for <code>pred_type='glm'</code> when <code>joint=False</code> in regression.
In the case of last-layer Laplace with a diagonal or Kron Hessian,
setting this to <code>True</code> makes computation much(!) faster for large
number of outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.__call__(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.LLLaplace.__call__(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.__call__(fitting)" class="doc doc-heading doc-heading-parameter">              <b><code>fitting</code></b>
<a href="#laplace.lllaplace.LLLaplace.__call__(fitting)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether or not this predictive call is done during fitting. Only useful for
reward modeling: the likelihood is set to <code>"regression"</code> when <code>False</code> and
<code>"classification"</code> when <code>True</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>predictive</code></b> (              <code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<span title="torch.Tensor">Tensor</span>]</code>
)          –
          <div class="doc-md-description">
            <p>For <code>likelihood='classification'</code>, a torch.Tensor is returned with
a distribution over classes (similar to a Softmax).
For <code>likelihood='regression'</code>, a tuple of torch.Tensor is returned
with the mean and the predictive variance.
For <code>likelihood='regression'</code> and <code>joint=True</code>, a tuple of torch.Tensor
is returned with the mean and the predictive covariance.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1055">1055</a></span>
<span class="normal"><a href="#__codelineno-0-1056">1056</a></span>
<span class="normal"><a href="#__codelineno-0-1057">1057</a></span>
<span class="normal"><a href="#__codelineno-0-1058">1058</a></span>
<span class="normal"><a href="#__codelineno-0-1059">1059</a></span>
<span class="normal"><a href="#__codelineno-0-1060">1060</a></span>
<span class="normal"><a href="#__codelineno-0-1061">1061</a></span>
<span class="normal"><a href="#__codelineno-0-1062">1062</a></span>
<span class="normal"><a href="#__codelineno-0-1063">1063</a></span>
<span class="normal"><a href="#__codelineno-0-1064">1064</a></span>
<span class="normal"><a href="#__codelineno-0-1065">1065</a></span>
<span class="normal"><a href="#__codelineno-0-1066">1066</a></span>
<span class="normal"><a href="#__codelineno-0-1067">1067</a></span>
<span class="normal"><a href="#__codelineno-0-1068">1068</a></span>
<span class="normal"><a href="#__codelineno-0-1069">1069</a></span>
<span class="normal"><a href="#__codelineno-0-1070">1070</a></span>
<span class="normal"><a href="#__codelineno-0-1071">1071</a></span>
<span class="normal"><a href="#__codelineno-0-1072">1072</a></span>
<span class="normal"><a href="#__codelineno-0-1073">1073</a></span>
<span class="normal"><a href="#__codelineno-0-1074">1074</a></span>
<span class="normal"><a href="#__codelineno-0-1075">1075</a></span>
<span class="normal"><a href="#__codelineno-0-1076">1076</a></span>
<span class="normal"><a href="#__codelineno-0-1077">1077</a></span>
<span class="normal"><a href="#__codelineno-0-1078">1078</a></span>
<span class="normal"><a href="#__codelineno-0-1079">1079</a></span>
<span class="normal"><a href="#__codelineno-0-1080">1080</a></span>
<span class="normal"><a href="#__codelineno-0-1081">1081</a></span>
<span class="normal"><a href="#__codelineno-0-1082">1082</a></span>
<span class="normal"><a href="#__codelineno-0-1083">1083</a></span>
<span class="normal"><a href="#__codelineno-0-1084">1084</a></span>
<span class="normal"><a href="#__codelineno-0-1085">1085</a></span>
<span class="normal"><a href="#__codelineno-0-1086">1086</a></span>
<span class="normal"><a href="#__codelineno-0-1087">1087</a></span>
<span class="normal"><a href="#__codelineno-0-1088">1088</a></span>
<span class="normal"><a href="#__codelineno-0-1089">1089</a></span>
<span class="normal"><a href="#__codelineno-0-1090">1090</a></span>
<span class="normal"><a href="#__codelineno-0-1091">1091</a></span>
<span class="normal"><a href="#__codelineno-0-1092">1092</a></span>
<span class="normal"><a href="#__codelineno-0-1093">1093</a></span>
<span class="normal"><a href="#__codelineno-0-1094">1094</a></span>
<span class="normal"><a href="#__codelineno-0-1095">1095</a></span>
<span class="normal"><a href="#__codelineno-0-1096">1096</a></span>
<span class="normal"><a href="#__codelineno-0-1097">1097</a></span>
<span class="normal"><a href="#__codelineno-0-1098">1098</a></span>
<span class="normal"><a href="#__codelineno-0-1099">1099</a></span>
<span class="normal"><a href="#__codelineno-0-1100">1100</a></span>
<span class="normal"><a href="#__codelineno-0-1101">1101</a></span>
<span class="normal"><a href="#__codelineno-0-1102">1102</a></span>
<span class="normal"><a href="#__codelineno-0-1103">1103</a></span>
<span class="normal"><a href="#__codelineno-0-1104">1104</a></span>
<span class="normal"><a href="#__codelineno-0-1105">1105</a></span>
<span class="normal"><a href="#__codelineno-0-1106">1106</a></span>
<span class="normal"><a href="#__codelineno-0-1107">1107</a></span>
<span class="normal"><a href="#__codelineno-0-1108">1108</a></span>
<span class="normal"><a href="#__codelineno-0-1109">1109</a></span>
<span class="normal"><a href="#__codelineno-0-1110">1110</a></span>
<span class="normal"><a href="#__codelineno-0-1111">1111</a></span>
<span class="normal"><a href="#__codelineno-0-1112">1112</a></span>
<span class="normal"><a href="#__codelineno-0-1113">1113</a></span>
<span class="normal"><a href="#__codelineno-0-1114">1114</a></span>
<span class="normal"><a href="#__codelineno-0-1115">1115</a></span>
<span class="normal"><a href="#__codelineno-0-1116">1116</a></span>
<span class="normal"><a href="#__codelineno-0-1117">1117</a></span>
<span class="normal"><a href="#__codelineno-0-1118">1118</a></span>
<span class="normal"><a href="#__codelineno-0-1119">1119</a></span>
<span class="normal"><a href="#__codelineno-0-1120">1120</a></span>
<span class="normal"><a href="#__codelineno-0-1121">1121</a></span>
<span class="normal"><a href="#__codelineno-0-1122">1122</a></span>
<span class="normal"><a href="#__codelineno-0-1123">1123</a></span>
<span class="normal"><a href="#__codelineno-0-1124">1124</a></span>
<span class="normal"><a href="#__codelineno-0-1125">1125</a></span>
<span class="normal"><a href="#__codelineno-0-1126">1126</a></span>
<span class="normal"><a href="#__codelineno-0-1127">1127</a></span>
<span class="normal"><a href="#__codelineno-0-1128">1128</a></span>
<span class="normal"><a href="#__codelineno-0-1129">1129</a></span>
<span class="normal"><a href="#__codelineno-0-1130">1130</a></span>
<span class="normal"><a href="#__codelineno-0-1131">1131</a></span>
<span class="normal"><a href="#__codelineno-0-1132">1132</a></span>
<span class="normal"><a href="#__codelineno-0-1133">1133</a></span>
<span class="normal"><a href="#__codelineno-0-1134">1134</a></span>
<span class="normal"><a href="#__codelineno-0-1135">1135</a></span>
<span class="normal"><a href="#__codelineno-0-1136">1136</a></span>
<span class="normal"><a href="#__codelineno-0-1137">1137</a></span>
<span class="normal"><a href="#__codelineno-0-1138">1138</a></span>
<span class="normal"><a href="#__codelineno-0-1139">1139</a></span>
<span class="normal"><a href="#__codelineno-0-1140">1140</a></span>
<span class="normal"><a href="#__codelineno-0-1141">1141</a></span>
<span class="normal"><a href="#__codelineno-0-1142">1142</a></span>
<span class="normal"><a href="#__codelineno-0-1143">1143</a></span>
<span class="normal"><a href="#__codelineno-0-1144">1144</a></span>
<span class="normal"><a href="#__codelineno-0-1145">1145</a></span>
<span class="normal"><a href="#__codelineno-0-1146">1146</a></span>
<span class="normal"><a href="#__codelineno-0-1147">1147</a></span>
<span class="normal"><a href="#__codelineno-0-1148">1148</a></span>
<span class="normal"><a href="#__codelineno-0-1149">1149</a></span>
<span class="normal"><a href="#__codelineno-0-1150">1150</a></span>
<span class="normal"><a href="#__codelineno-0-1151">1151</a></span>
<span class="normal"><a href="#__codelineno-0-1152">1152</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1055" name="__codelineno-0-1055"></a><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
<a id="__codelineno-0-1056" name="__codelineno-0-1056"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1057" name="__codelineno-0-1057"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1058" name="__codelineno-0-1058"></a>    <span class="n">pred_type</span><span class="p">:</span> <span class="n">PredType</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">,</span>
<a id="__codelineno-0-1059" name="__codelineno-0-1059"></a>    <span class="n">joint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1060" name="__codelineno-0-1060"></a>    <span class="n">link_approx</span><span class="p">:</span> <span class="n">LinkApprox</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">PROBIT</span><span class="p">,</span>
<a id="__codelineno-0-1061" name="__codelineno-0-1061"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-1062" name="__codelineno-0-1062"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1063" name="__codelineno-0-1063"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1064" name="__codelineno-0-1064"></a>    <span class="n">fitting</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1065" name="__codelineno-0-1065"></a>    <span class="o">**</span><span class="n">model_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1066" name="__codelineno-0-1066"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-1067" name="__codelineno-0-1067"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the posterior predictive on input data `x`.</span>
<a id="__codelineno-0-1068" name="__codelineno-0-1068"></a>
<a id="__codelineno-0-1069" name="__codelineno-0-1069"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1070" name="__codelineno-0-1070"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1071" name="__codelineno-0-1071"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-1072" name="__codelineno-0-1072"></a><span class="sd">        `(batch_size, input_shape)` if tensor. If MutableMapping, must contain</span>
<a id="__codelineno-0-1073" name="__codelineno-0-1073"></a><span class="sd">        the said tensor.</span>
<a id="__codelineno-0-1074" name="__codelineno-0-1074"></a>
<a id="__codelineno-0-1075" name="__codelineno-0-1075"></a><span class="sd">    pred_type : {&#39;glm&#39;, &#39;nn&#39;}, default=&#39;glm&#39;</span>
<a id="__codelineno-0-1076" name="__codelineno-0-1076"></a><span class="sd">        type of posterior predictive, linearized GLM predictive or neural</span>
<a id="__codelineno-0-1077" name="__codelineno-0-1077"></a><span class="sd">        network sampling predictive. The GLM predictive is consistent with</span>
<a id="__codelineno-0-1078" name="__codelineno-0-1078"></a><span class="sd">        the curvature approximations used here. When Laplace is done only</span>
<a id="__codelineno-0-1079" name="__codelineno-0-1079"></a><span class="sd">        on subset of parameters (i.e. some grad are disabled),</span>
<a id="__codelineno-0-1080" name="__codelineno-0-1080"></a><span class="sd">        only `nn` predictive is supported.</span>
<a id="__codelineno-0-1081" name="__codelineno-0-1081"></a>
<a id="__codelineno-0-1082" name="__codelineno-0-1082"></a><span class="sd">    link_approx : {&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;}</span>
<a id="__codelineno-0-1083" name="__codelineno-0-1083"></a><span class="sd">        how to approximate the classification link function for the `&#39;glm&#39;`.</span>
<a id="__codelineno-0-1084" name="__codelineno-0-1084"></a><span class="sd">        For `pred_type=&#39;nn&#39;`, only &#39;mc&#39; is possible.</span>
<a id="__codelineno-0-1085" name="__codelineno-0-1085"></a>
<a id="__codelineno-0-1086" name="__codelineno-0-1086"></a><span class="sd">    joint : bool</span>
<a id="__codelineno-0-1087" name="__codelineno-0-1087"></a><span class="sd">        Whether to output a joint predictive distribution in regression with</span>
<a id="__codelineno-0-1088" name="__codelineno-0-1088"></a><span class="sd">        `pred_type=&#39;glm&#39;`. If set to `True`, the predictive distribution</span>
<a id="__codelineno-0-1089" name="__codelineno-0-1089"></a><span class="sd">        has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).</span>
<a id="__codelineno-0-1090" name="__codelineno-0-1090"></a><span class="sd">        If `False`, then only outputs the marginal predictive distribution.</span>
<a id="__codelineno-0-1091" name="__codelineno-0-1091"></a><span class="sd">        Only available for regression and GLM predictive.</span>
<a id="__codelineno-0-1092" name="__codelineno-0-1092"></a>
<a id="__codelineno-0-1093" name="__codelineno-0-1093"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-1094" name="__codelineno-0-1094"></a><span class="sd">        number of samples for `link_approx=&#39;mc&#39;`.</span>
<a id="__codelineno-0-1095" name="__codelineno-0-1095"></a>
<a id="__codelineno-0-1096" name="__codelineno-0-1096"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-1097" name="__codelineno-0-1097"></a><span class="sd">        whether to use a diagonalized posterior predictive on the outputs.</span>
<a id="__codelineno-0-1098" name="__codelineno-0-1098"></a><span class="sd">        Only works for `pred_type=&#39;glm&#39;` when `joint=False` in regression.</span>
<a id="__codelineno-0-1099" name="__codelineno-0-1099"></a><span class="sd">        In the case of last-layer Laplace with a diagonal or Kron Hessian,</span>
<a id="__codelineno-0-1100" name="__codelineno-0-1100"></a><span class="sd">        setting this to `True` makes computation much(!) faster for large</span>
<a id="__codelineno-0-1101" name="__codelineno-0-1101"></a><span class="sd">        number of outputs.</span>
<a id="__codelineno-0-1102" name="__codelineno-0-1102"></a>
<a id="__codelineno-0-1103" name="__codelineno-0-1103"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1104" name="__codelineno-0-1104"></a><span class="sd">        random number generator to control the samples (if sampling used).</span>
<a id="__codelineno-0-1105" name="__codelineno-0-1105"></a>
<a id="__codelineno-0-1106" name="__codelineno-0-1106"></a><span class="sd">    fitting : bool, default=False</span>
<a id="__codelineno-0-1107" name="__codelineno-0-1107"></a><span class="sd">        whether or not this predictive call is done during fitting. Only useful for</span>
<a id="__codelineno-0-1108" name="__codelineno-0-1108"></a><span class="sd">        reward modeling: the likelihood is set to `&quot;regression&quot;` when `False` and</span>
<a id="__codelineno-0-1109" name="__codelineno-0-1109"></a><span class="sd">        `&quot;classification&quot;` when `True`.</span>
<a id="__codelineno-0-1110" name="__codelineno-0-1110"></a>
<a id="__codelineno-0-1111" name="__codelineno-0-1111"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1112" name="__codelineno-0-1112"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1113" name="__codelineno-0-1113"></a><span class="sd">    predictive: torch.Tensor or tuple[torch.Tensor]</span>
<a id="__codelineno-0-1114" name="__codelineno-0-1114"></a><span class="sd">        For `likelihood=&#39;classification&#39;`, a torch.Tensor is returned with</span>
<a id="__codelineno-0-1115" name="__codelineno-0-1115"></a><span class="sd">        a distribution over classes (similar to a Softmax).</span>
<a id="__codelineno-0-1116" name="__codelineno-0-1116"></a><span class="sd">        For `likelihood=&#39;regression&#39;`, a tuple of torch.Tensor is returned</span>
<a id="__codelineno-0-1117" name="__codelineno-0-1117"></a><span class="sd">        with the mean and the predictive variance.</span>
<a id="__codelineno-0-1118" name="__codelineno-0-1118"></a><span class="sd">        For `likelihood=&#39;regression&#39;` and `joint=True`, a tuple of torch.Tensor</span>
<a id="__codelineno-0-1119" name="__codelineno-0-1119"></a><span class="sd">        is returned with the mean and the predictive covariance.</span>
<a id="__codelineno-0-1120" name="__codelineno-0-1120"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1121" name="__codelineno-0-1121"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">pred</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">PredType</span><span class="p">]:</span>
<a id="__codelineno-0-1122" name="__codelineno-0-1122"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only glm and nn supported as prediction types.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1123" name="__codelineno-0-1123"></a>
<a id="__codelineno-0-1124" name="__codelineno-0-1124"></a>    <span class="k">if</span> <span class="n">link_approx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">la</span> <span class="k">for</span> <span class="n">la</span> <span class="ow">in</span> <span class="n">LinkApprox</span><span class="p">]:</span>
<a id="__codelineno-0-1125" name="__codelineno-0-1125"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported link approximation </span><span class="si">{</span><span class="n">link_approx</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1126" name="__codelineno-0-1126"></a>
<a id="__codelineno-0-1127" name="__codelineno-0-1127"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">NN</span> <span class="ow">and</span> <span class="n">link_approx</span> <span class="o">!=</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">MC</span><span class="p">:</span>
<a id="__codelineno-0-1128" name="__codelineno-0-1128"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-1129" name="__codelineno-0-1129"></a>            <span class="s2">&quot;Only mc link approximation is supported for nn prediction type.&quot;</span>
<a id="__codelineno-0-1130" name="__codelineno-0-1130"></a>        <span class="p">)</span>
<a id="__codelineno-0-1131" name="__codelineno-0-1131"></a>
<a id="__codelineno-0-1132" name="__codelineno-0-1132"></a>    <span class="k">if</span> <span class="n">generator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1133" name="__codelineno-0-1133"></a>        <span class="k">if</span> <span class="p">(</span>
<a id="__codelineno-0-1134" name="__codelineno-0-1134"></a>            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">)</span>
<a id="__codelineno-0-1135" name="__codelineno-0-1135"></a>            <span class="ow">or</span> <span class="n">generator</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>
<a id="__codelineno-0-1136" name="__codelineno-0-1136"></a>        <span class="p">):</span>
<a id="__codelineno-0-1137" name="__codelineno-0-1137"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid random generator (check type and device).&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1138" name="__codelineno-0-1138"></a>
<a id="__codelineno-0-1139" name="__codelineno-0-1139"></a>    <span class="n">likelihood</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span>
<a id="__codelineno-0-1140" name="__codelineno-0-1140"></a>    <span class="k">if</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REWARD_MODELING</span><span class="p">:</span>
<a id="__codelineno-0-1141" name="__codelineno-0-1141"></a>        <span class="n">likelihood</span> <span class="o">=</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">CLASSIFICATION</span> <span class="k">if</span> <span class="n">fitting</span> <span class="k">else</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span>
<a id="__codelineno-0-1142" name="__codelineno-0-1142"></a>
<a id="__codelineno-0-1143" name="__codelineno-0-1143"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">:</span>
<a id="__codelineno-0-1144" name="__codelineno-0-1144"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_forward_call</span><span class="p">(</span>
<a id="__codelineno-0-1145" name="__codelineno-0-1145"></a>            <span class="n">x</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">joint</span><span class="p">,</span> <span class="n">link_approx</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span>
<a id="__codelineno-0-1146" name="__codelineno-0-1146"></a>        <span class="p">)</span>
<a id="__codelineno-0-1147" name="__codelineno-0-1147"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1148" name="__codelineno-0-1148"></a>        <span class="k">if</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-1149" name="__codelineno-0-1149"></a>            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_predictive_samples</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
<a id="__codelineno-0-1150" name="__codelineno-0-1150"></a>            <span class="k">return</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">samples</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-1151" name="__codelineno-0-1151"></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># classification; the average is computed online</span>
<a id="__codelineno-0-1152" name="__codelineno-0-1152"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_predictive_classification</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace._glm_forward_call" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">_glm_forward_call</span>


<a href="#laplace.lllaplace.LLLaplace._glm_forward_call" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">_glm_forward_call</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_forward_call(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_forward_call(likelihood)">likelihood</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_forward_call(joint)">joint</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_forward_call(link_approx)">link_approx</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox" href="../enums/#laplace.utils.enums.LinkApprox">LinkApprox</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox.PROBIT" href="../enums/#laplace.utils.enums.LinkApprox.PROBIT">PROBIT</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_forward_call(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_forward_call(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the posterior predictive on input data <code>x</code> for "glm" pred type.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_forward_call(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_forward_call(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p><code>(batch_size, input_shape)</code> if tensor. If MutableMapping, must contain
the said tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_forward_call(likelihood)" class="doc doc-heading doc-heading-parameter">              <b><code>likelihood</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_forward_call(likelihood)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a> in {&#39;classification&#39;, &#39;regression&#39;, &#39;reward_modeling&#39;}</code>)
          –
          <div class="doc-md-description">
            <p>determines the log likelihood Hessian approximation.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_forward_call(link_approx)" class="doc doc-heading doc-heading-parameter">              <b><code>link_approx</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_forward_call(link_approx)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;)</code>, default:
                  <code>&#39;mc&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>how to approximate the classification link function for the <code>'glm'</code>.
For <code>pred_type='nn'</code>, only 'mc' is possible.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_forward_call(joint)" class="doc doc-heading doc-heading-parameter">              <b><code>joint</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_forward_call(joint)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to output a joint predictive distribution in regression with
<code>pred_type='glm'</code>. If set to <code>True</code>, the predictive distribution
has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).
If <code>False</code>, then only outputs the marginal predictive distribution.
Only available for regression and GLM predictive.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_forward_call(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_forward_call(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples for <code>link_approx='mc'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_forward_call(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_forward_call(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized posterior predictive on the outputs.
Only works for <code>pred_type='glm'</code> and <code>link_approx='mc'</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>predictive</code></b> (              <code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<span title="torch.Tensor">Tensor</span>]</code>
)          –
          <div class="doc-md-description">
            <p>For <code>likelihood='classification'</code>, a torch.Tensor is returned with
a distribution over classes (similar to a Softmax).
For <code>likelihood='regression'</code>, a tuple of torch.Tensor is returned
with the mean and the predictive variance.
For <code>likelihood='regression'</code> and <code>joint=True</code>, a tuple of torch.Tensor
is returned with the mean and the predictive covariance.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-598">598</a></span>
<span class="normal"><a href="#__codelineno-0-599">599</a></span>
<span class="normal"><a href="#__codelineno-0-600">600</a></span>
<span class="normal"><a href="#__codelineno-0-601">601</a></span>
<span class="normal"><a href="#__codelineno-0-602">602</a></span>
<span class="normal"><a href="#__codelineno-0-603">603</a></span>
<span class="normal"><a href="#__codelineno-0-604">604</a></span>
<span class="normal"><a href="#__codelineno-0-605">605</a></span>
<span class="normal"><a href="#__codelineno-0-606">606</a></span>
<span class="normal"><a href="#__codelineno-0-607">607</a></span>
<span class="normal"><a href="#__codelineno-0-608">608</a></span>
<span class="normal"><a href="#__codelineno-0-609">609</a></span>
<span class="normal"><a href="#__codelineno-0-610">610</a></span>
<span class="normal"><a href="#__codelineno-0-611">611</a></span>
<span class="normal"><a href="#__codelineno-0-612">612</a></span>
<span class="normal"><a href="#__codelineno-0-613">613</a></span>
<span class="normal"><a href="#__codelineno-0-614">614</a></span>
<span class="normal"><a href="#__codelineno-0-615">615</a></span>
<span class="normal"><a href="#__codelineno-0-616">616</a></span>
<span class="normal"><a href="#__codelineno-0-617">617</a></span>
<span class="normal"><a href="#__codelineno-0-618">618</a></span>
<span class="normal"><a href="#__codelineno-0-619">619</a></span>
<span class="normal"><a href="#__codelineno-0-620">620</a></span>
<span class="normal"><a href="#__codelineno-0-621">621</a></span>
<span class="normal"><a href="#__codelineno-0-622">622</a></span>
<span class="normal"><a href="#__codelineno-0-623">623</a></span>
<span class="normal"><a href="#__codelineno-0-624">624</a></span>
<span class="normal"><a href="#__codelineno-0-625">625</a></span>
<span class="normal"><a href="#__codelineno-0-626">626</a></span>
<span class="normal"><a href="#__codelineno-0-627">627</a></span>
<span class="normal"><a href="#__codelineno-0-628">628</a></span>
<span class="normal"><a href="#__codelineno-0-629">629</a></span>
<span class="normal"><a href="#__codelineno-0-630">630</a></span>
<span class="normal"><a href="#__codelineno-0-631">631</a></span>
<span class="normal"><a href="#__codelineno-0-632">632</a></span>
<span class="normal"><a href="#__codelineno-0-633">633</a></span>
<span class="normal"><a href="#__codelineno-0-634">634</a></span>
<span class="normal"><a href="#__codelineno-0-635">635</a></span>
<span class="normal"><a href="#__codelineno-0-636">636</a></span>
<span class="normal"><a href="#__codelineno-0-637">637</a></span>
<span class="normal"><a href="#__codelineno-0-638">638</a></span>
<span class="normal"><a href="#__codelineno-0-639">639</a></span>
<span class="normal"><a href="#__codelineno-0-640">640</a></span>
<span class="normal"><a href="#__codelineno-0-641">641</a></span>
<span class="normal"><a href="#__codelineno-0-642">642</a></span>
<span class="normal"><a href="#__codelineno-0-643">643</a></span>
<span class="normal"><a href="#__codelineno-0-644">644</a></span>
<span class="normal"><a href="#__codelineno-0-645">645</a></span>
<span class="normal"><a href="#__codelineno-0-646">646</a></span>
<span class="normal"><a href="#__codelineno-0-647">647</a></span>
<span class="normal"><a href="#__codelineno-0-648">648</a></span>
<span class="normal"><a href="#__codelineno-0-649">649</a></span>
<span class="normal"><a href="#__codelineno-0-650">650</a></span>
<span class="normal"><a href="#__codelineno-0-651">651</a></span>
<span class="normal"><a href="#__codelineno-0-652">652</a></span>
<span class="normal"><a href="#__codelineno-0-653">653</a></span>
<span class="normal"><a href="#__codelineno-0-654">654</a></span>
<span class="normal"><a href="#__codelineno-0-655">655</a></span>
<span class="normal"><a href="#__codelineno-0-656">656</a></span>
<span class="normal"><a href="#__codelineno-0-657">657</a></span>
<span class="normal"><a href="#__codelineno-0-658">658</a></span>
<span class="normal"><a href="#__codelineno-0-659">659</a></span>
<span class="normal"><a href="#__codelineno-0-660">660</a></span>
<span class="normal"><a href="#__codelineno-0-661">661</a></span>
<span class="normal"><a href="#__codelineno-0-662">662</a></span>
<span class="normal"><a href="#__codelineno-0-663">663</a></span>
<span class="normal"><a href="#__codelineno-0-664">664</a></span>
<span class="normal"><a href="#__codelineno-0-665">665</a></span>
<span class="normal"><a href="#__codelineno-0-666">666</a></span>
<span class="normal"><a href="#__codelineno-0-667">667</a></span>
<span class="normal"><a href="#__codelineno-0-668">668</a></span>
<span class="normal"><a href="#__codelineno-0-669">669</a></span>
<span class="normal"><a href="#__codelineno-0-670">670</a></span>
<span class="normal"><a href="#__codelineno-0-671">671</a></span>
<span class="normal"><a href="#__codelineno-0-672">672</a></span>
<span class="normal"><a href="#__codelineno-0-673">673</a></span>
<span class="normal"><a href="#__codelineno-0-674">674</a></span>
<span class="normal"><a href="#__codelineno-0-675">675</a></span>
<span class="normal"><a href="#__codelineno-0-676">676</a></span>
<span class="normal"><a href="#__codelineno-0-677">677</a></span>
<span class="normal"><a href="#__codelineno-0-678">678</a></span>
<span class="normal"><a href="#__codelineno-0-679">679</a></span>
<span class="normal"><a href="#__codelineno-0-680">680</a></span>
<span class="normal"><a href="#__codelineno-0-681">681</a></span>
<span class="normal"><a href="#__codelineno-0-682">682</a></span>
<span class="normal"><a href="#__codelineno-0-683">683</a></span>
<span class="normal"><a href="#__codelineno-0-684">684</a></span>
<span class="normal"><a href="#__codelineno-0-685">685</a></span>
<span class="normal"><a href="#__codelineno-0-686">686</a></span>
<span class="normal"><a href="#__codelineno-0-687">687</a></span>
<span class="normal"><a href="#__codelineno-0-688">688</a></span>
<span class="normal"><a href="#__codelineno-0-689">689</a></span>
<span class="normal"><a href="#__codelineno-0-690">690</a></span>
<span class="normal"><a href="#__codelineno-0-691">691</a></span>
<span class="normal"><a href="#__codelineno-0-692">692</a></span>
<span class="normal"><a href="#__codelineno-0-693">693</a></span>
<span class="normal"><a href="#__codelineno-0-694">694</a></span>
<span class="normal"><a href="#__codelineno-0-695">695</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-598" name="__codelineno-0-598"></a><span class="k">def</span> <span class="nf">_glm_forward_call</span><span class="p">(</span>
<a id="__codelineno-0-599" name="__codelineno-0-599"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-600" name="__codelineno-0-600"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">,</span>
<a id="__codelineno-0-601" name="__codelineno-0-601"></a>    <span class="n">likelihood</span><span class="p">:</span> <span class="n">Likelihood</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-602" name="__codelineno-0-602"></a>    <span class="n">joint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-603" name="__codelineno-0-603"></a>    <span class="n">link_approx</span><span class="p">:</span> <span class="n">LinkApprox</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">PROBIT</span><span class="p">,</span>
<a id="__codelineno-0-604" name="__codelineno-0-604"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-605" name="__codelineno-0-605"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-606" name="__codelineno-0-606"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-607" name="__codelineno-0-607"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the posterior predictive on input data `x` for &quot;glm&quot; pred type.</span>
<a id="__codelineno-0-608" name="__codelineno-0-608"></a>
<a id="__codelineno-0-609" name="__codelineno-0-609"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-610" name="__codelineno-0-610"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-611" name="__codelineno-0-611"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-612" name="__codelineno-0-612"></a><span class="sd">        `(batch_size, input_shape)` if tensor. If MutableMapping, must contain</span>
<a id="__codelineno-0-613" name="__codelineno-0-613"></a><span class="sd">        the said tensor.</span>
<a id="__codelineno-0-614" name="__codelineno-0-614"></a>
<a id="__codelineno-0-615" name="__codelineno-0-615"></a><span class="sd">    likelihood : Likelihood or str in {&#39;classification&#39;, &#39;regression&#39;, &#39;reward_modeling&#39;}</span>
<a id="__codelineno-0-616" name="__codelineno-0-616"></a><span class="sd">        determines the log likelihood Hessian approximation.</span>
<a id="__codelineno-0-617" name="__codelineno-0-617"></a>
<a id="__codelineno-0-618" name="__codelineno-0-618"></a><span class="sd">    link_approx : {&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;}</span>
<a id="__codelineno-0-619" name="__codelineno-0-619"></a><span class="sd">        how to approximate the classification link function for the `&#39;glm&#39;`.</span>
<a id="__codelineno-0-620" name="__codelineno-0-620"></a><span class="sd">        For `pred_type=&#39;nn&#39;`, only &#39;mc&#39; is possible.</span>
<a id="__codelineno-0-621" name="__codelineno-0-621"></a>
<a id="__codelineno-0-622" name="__codelineno-0-622"></a><span class="sd">    joint : bool</span>
<a id="__codelineno-0-623" name="__codelineno-0-623"></a><span class="sd">        Whether to output a joint predictive distribution in regression with</span>
<a id="__codelineno-0-624" name="__codelineno-0-624"></a><span class="sd">        `pred_type=&#39;glm&#39;`. If set to `True`, the predictive distribution</span>
<a id="__codelineno-0-625" name="__codelineno-0-625"></a><span class="sd">        has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).</span>
<a id="__codelineno-0-626" name="__codelineno-0-626"></a><span class="sd">        If `False`, then only outputs the marginal predictive distribution.</span>
<a id="__codelineno-0-627" name="__codelineno-0-627"></a><span class="sd">        Only available for regression and GLM predictive.</span>
<a id="__codelineno-0-628" name="__codelineno-0-628"></a>
<a id="__codelineno-0-629" name="__codelineno-0-629"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-630" name="__codelineno-0-630"></a><span class="sd">        number of samples for `link_approx=&#39;mc&#39;`.</span>
<a id="__codelineno-0-631" name="__codelineno-0-631"></a>
<a id="__codelineno-0-632" name="__codelineno-0-632"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-633" name="__codelineno-0-633"></a><span class="sd">        whether to use a diagonalized posterior predictive on the outputs.</span>
<a id="__codelineno-0-634" name="__codelineno-0-634"></a><span class="sd">        Only works for `pred_type=&#39;glm&#39;` and `link_approx=&#39;mc&#39;`.</span>
<a id="__codelineno-0-635" name="__codelineno-0-635"></a>
<a id="__codelineno-0-636" name="__codelineno-0-636"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-637" name="__codelineno-0-637"></a><span class="sd">    -------</span>
<a id="__codelineno-0-638" name="__codelineno-0-638"></a><span class="sd">    predictive: torch.Tensor or tuple[torch.Tensor]</span>
<a id="__codelineno-0-639" name="__codelineno-0-639"></a><span class="sd">        For `likelihood=&#39;classification&#39;`, a torch.Tensor is returned with</span>
<a id="__codelineno-0-640" name="__codelineno-0-640"></a><span class="sd">        a distribution over classes (similar to a Softmax).</span>
<a id="__codelineno-0-641" name="__codelineno-0-641"></a><span class="sd">        For `likelihood=&#39;regression&#39;`, a tuple of torch.Tensor is returned</span>
<a id="__codelineno-0-642" name="__codelineno-0-642"></a><span class="sd">        with the mean and the predictive variance.</span>
<a id="__codelineno-0-643" name="__codelineno-0-643"></a><span class="sd">        For `likelihood=&#39;regression&#39;` and `joint=True`, a tuple of torch.Tensor</span>
<a id="__codelineno-0-644" name="__codelineno-0-644"></a><span class="sd">        is returned with the mean and the predictive covariance.</span>
<a id="__codelineno-0-645" name="__codelineno-0-645"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-646" name="__codelineno-0-646"></a>    <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_distribution</span><span class="p">(</span>
<a id="__codelineno-0-647" name="__codelineno-0-647"></a>        <span class="n">x</span><span class="p">,</span> <span class="n">joint</span><span class="o">=</span><span class="n">joint</span> <span class="ow">and</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span>
<a id="__codelineno-0-648" name="__codelineno-0-648"></a>    <span class="p">)</span>
<a id="__codelineno-0-649" name="__codelineno-0-649"></a>
<a id="__codelineno-0-650" name="__codelineno-0-650"></a>    <span class="k">if</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-651" name="__codelineno-0-651"></a>        <span class="k">if</span> <span class="n">diagonal_output</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">joint</span><span class="p">:</span>
<a id="__codelineno-0-652" name="__codelineno-0-652"></a>            <span class="n">f_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_var</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-653" name="__codelineno-0-653"></a>        <span class="k">return</span> <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span>
<a id="__codelineno-0-654" name="__codelineno-0-654"></a>
<a id="__codelineno-0-655" name="__codelineno-0-655"></a>    <span class="k">if</span> <span class="n">link_approx</span> <span class="o">==</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">MC</span><span class="p">:</span>
<a id="__codelineno-0-656" name="__codelineno-0-656"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-657" name="__codelineno-0-657"></a>            <span class="n">f_mu</span><span class="p">,</span>
<a id="__codelineno-0-658" name="__codelineno-0-658"></a>            <span class="n">f_var</span><span class="p">,</span>
<a id="__codelineno-0-659" name="__codelineno-0-659"></a>            <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span>
<a id="__codelineno-0-660" name="__codelineno-0-660"></a>            <span class="n">diagonal_output</span><span class="o">=</span><span class="n">diagonal_output</span><span class="p">,</span>
<a id="__codelineno-0-661" name="__codelineno-0-661"></a>        <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-662" name="__codelineno-0-662"></a>    <span class="k">elif</span> <span class="n">link_approx</span> <span class="o">==</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">PROBIT</span><span class="p">:</span>
<a id="__codelineno-0-663" name="__codelineno-0-663"></a>        <span class="n">kappa</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">8</span> <span class="o">*</span> <span class="n">f_var</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<a id="__codelineno-0-664" name="__codelineno-0-664"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">kappa</span> <span class="o">*</span> <span class="n">f_mu</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-665" name="__codelineno-0-665"></a>    <span class="k">elif</span> <span class="s2">&quot;bridge&quot;</span> <span class="ow">in</span> <span class="n">link_approx</span><span class="p">:</span>
<a id="__codelineno-0-666" name="__codelineno-0-666"></a>        <span class="c1"># zero mean correction</span>
<a id="__codelineno-0-667" name="__codelineno-0-667"></a>        <span class="n">f_mu</span> <span class="o">-=</span> <span class="p">(</span>
<a id="__codelineno-0-668" name="__codelineno-0-668"></a>            <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-669" name="__codelineno-0-669"></a>            <span class="o">*</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-670" name="__codelineno-0-670"></a>            <span class="o">/</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-671" name="__codelineno-0-671"></a>        <span class="p">)</span>
<a id="__codelineno-0-672" name="__codelineno-0-672"></a>        <span class="n">f_var</span> <span class="o">-=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
<a id="__codelineno-0-673" name="__codelineno-0-673"></a>            <span class="s2">&quot;bi,bj-&gt;bij&quot;</span><span class="p">,</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-674" name="__codelineno-0-674"></a>        <span class="p">)</span> <span class="o">/</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-675" name="__codelineno-0-675"></a>
<a id="__codelineno-0-676" name="__codelineno-0-676"></a>        <span class="c1"># Laplace Bridge</span>
<a id="__codelineno-0-677" name="__codelineno-0-677"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-678" name="__codelineno-0-678"></a>        <span class="n">f_var_diag</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_var</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-679" name="__codelineno-0-679"></a>
<a id="__codelineno-0-680" name="__codelineno-0-680"></a>        <span class="c1"># optional: variance correction</span>
<a id="__codelineno-0-681" name="__codelineno-0-681"></a>        <span class="k">if</span> <span class="n">link_approx</span> <span class="o">==</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">BRIDGE_NORM</span><span class="p">:</span>
<a id="__codelineno-0-682" name="__codelineno-0-682"></a>            <span class="n">f_var_diag_mean</span> <span class="o">=</span> <span class="n">f_var_diag</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-683" name="__codelineno-0-683"></a>            <span class="n">f_var_diag_mean</span> <span class="o">/=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span>
<a id="__codelineno-0-684" name="__codelineno-0-684"></a>                <span class="p">[</span><span class="n">K</span> <span class="o">/</span> <span class="mi">2</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>
<a id="__codelineno-0-685" name="__codelineno-0-685"></a>            <span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
<a id="__codelineno-0-686" name="__codelineno-0-686"></a>            <span class="n">f_mu</span> <span class="o">/=</span> <span class="n">f_var_diag_mean</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-687" name="__codelineno-0-687"></a>            <span class="n">f_var_diag</span> <span class="o">/=</span> <span class="n">f_var_diag_mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-688" name="__codelineno-0-688"></a>
<a id="__codelineno-0-689" name="__codelineno-0-689"></a>        <span class="n">sum_exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">f_mu</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-690" name="__codelineno-0-690"></a>        <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">K</span> <span class="o">+</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">/</span> <span class="n">K</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sum_exp</span><span class="p">)</span> <span class="o">/</span> <span class="n">f_var_diag</span>
<a id="__codelineno-0-691" name="__codelineno-0-691"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">alpha</span> <span class="o">/</span> <span class="n">alpha</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">nan</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<a id="__codelineno-0-692" name="__codelineno-0-692"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-693" name="__codelineno-0-693"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-694" name="__codelineno-0-694"></a>            <span class="s2">&quot;Prediction path invalid. Check the likelihood, pred_type, link_approx combination!&quot;</span>
<a id="__codelineno-0-695" name="__codelineno-0-695"></a>        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace._glm_functional_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">_glm_functional_samples</span>


<a href="#laplace.lllaplace.LLLaplace._glm_functional_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">_glm_functional_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_functional_samples(f_mu)">f_mu</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_functional_samples(f_var)">f_var</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_functional_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_functional_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_functional_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the posterior functional on input data <code>x</code> using "glm" prediction
type.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_functional_samples(f_mu)" class="doc doc-heading doc-heading-parameter">              <b><code>f_mu</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(f_mu)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive mean <code>(batch_size, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_functional_samples(f_var)" class="doc doc-heading doc-heading-parameter">              <b><code>f_var</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(f_var)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive covariances <code>(batch_size, output_shape, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_functional_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_functional_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_functional_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_functional_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-697">697</a></span>
<span class="normal"><a href="#__codelineno-0-698">698</a></span>
<span class="normal"><a href="#__codelineno-0-699">699</a></span>
<span class="normal"><a href="#__codelineno-0-700">700</a></span>
<span class="normal"><a href="#__codelineno-0-701">701</a></span>
<span class="normal"><a href="#__codelineno-0-702">702</a></span>
<span class="normal"><a href="#__codelineno-0-703">703</a></span>
<span class="normal"><a href="#__codelineno-0-704">704</a></span>
<span class="normal"><a href="#__codelineno-0-705">705</a></span>
<span class="normal"><a href="#__codelineno-0-706">706</a></span>
<span class="normal"><a href="#__codelineno-0-707">707</a></span>
<span class="normal"><a href="#__codelineno-0-708">708</a></span>
<span class="normal"><a href="#__codelineno-0-709">709</a></span>
<span class="normal"><a href="#__codelineno-0-710">710</a></span>
<span class="normal"><a href="#__codelineno-0-711">711</a></span>
<span class="normal"><a href="#__codelineno-0-712">712</a></span>
<span class="normal"><a href="#__codelineno-0-713">713</a></span>
<span class="normal"><a href="#__codelineno-0-714">714</a></span>
<span class="normal"><a href="#__codelineno-0-715">715</a></span>
<span class="normal"><a href="#__codelineno-0-716">716</a></span>
<span class="normal"><a href="#__codelineno-0-717">717</a></span>
<span class="normal"><a href="#__codelineno-0-718">718</a></span>
<span class="normal"><a href="#__codelineno-0-719">719</a></span>
<span class="normal"><a href="#__codelineno-0-720">720</a></span>
<span class="normal"><a href="#__codelineno-0-721">721</a></span>
<span class="normal"><a href="#__codelineno-0-722">722</a></span>
<span class="normal"><a href="#__codelineno-0-723">723</a></span>
<span class="normal"><a href="#__codelineno-0-724">724</a></span>
<span class="normal"><a href="#__codelineno-0-725">725</a></span>
<span class="normal"><a href="#__codelineno-0-726">726</a></span>
<span class="normal"><a href="#__codelineno-0-727">727</a></span>
<span class="normal"><a href="#__codelineno-0-728">728</a></span>
<span class="normal"><a href="#__codelineno-0-729">729</a></span>
<span class="normal"><a href="#__codelineno-0-730">730</a></span>
<span class="normal"><a href="#__codelineno-0-731">731</a></span>
<span class="normal"><a href="#__codelineno-0-732">732</a></span>
<span class="normal"><a href="#__codelineno-0-733">733</a></span>
<span class="normal"><a href="#__codelineno-0-734">734</a></span>
<span class="normal"><a href="#__codelineno-0-735">735</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-697" name="__codelineno-0-697"></a><span class="k">def</span> <span class="nf">_glm_functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-698" name="__codelineno-0-698"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-699" name="__codelineno-0-699"></a>    <span class="n">f_mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-700" name="__codelineno-0-700"></a>    <span class="n">f_var</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-701" name="__codelineno-0-701"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-702" name="__codelineno-0-702"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-703" name="__codelineno-0-703"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-704" name="__codelineno-0-704"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-705" name="__codelineno-0-705"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the posterior functional on input data `x` using &quot;glm&quot; prediction</span>
<a id="__codelineno-0-706" name="__codelineno-0-706"></a><span class="sd">    type.</span>
<a id="__codelineno-0-707" name="__codelineno-0-707"></a>
<a id="__codelineno-0-708" name="__codelineno-0-708"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-709" name="__codelineno-0-709"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-710" name="__codelineno-0-710"></a><span class="sd">    f_mu : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-711" name="__codelineno-0-711"></a><span class="sd">        glm predictive mean `(batch_size, output_shape)`</span>
<a id="__codelineno-0-712" name="__codelineno-0-712"></a>
<a id="__codelineno-0-713" name="__codelineno-0-713"></a><span class="sd">    f_var : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-714" name="__codelineno-0-714"></a><span class="sd">        glm predictive covariances `(batch_size, output_shape, output_shape)`</span>
<a id="__codelineno-0-715" name="__codelineno-0-715"></a>
<a id="__codelineno-0-716" name="__codelineno-0-716"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-717" name="__codelineno-0-717"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-718" name="__codelineno-0-718"></a>
<a id="__codelineno-0-719" name="__codelineno-0-719"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-720" name="__codelineno-0-720"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-721" name="__codelineno-0-721"></a>
<a id="__codelineno-0-722" name="__codelineno-0-722"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-723" name="__codelineno-0-723"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-724" name="__codelineno-0-724"></a>
<a id="__codelineno-0-725" name="__codelineno-0-725"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-726" name="__codelineno-0-726"></a><span class="sd">    -------</span>
<a id="__codelineno-0-727" name="__codelineno-0-727"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-728" name="__codelineno-0-728"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-729" name="__codelineno-0-729"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-730" name="__codelineno-0-730"></a>    <span class="k">assert</span> <span class="n">f_var</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">f_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<a id="__codelineno-0-731" name="__codelineno-0-731"></a>
<a id="__codelineno-0-732" name="__codelineno-0-732"></a>    <span class="k">if</span> <span class="n">diagonal_output</span><span class="p">:</span>
<a id="__codelineno-0-733" name="__codelineno-0-733"></a>        <span class="n">f_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_var</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-734" name="__codelineno-0-734"></a>
<a id="__codelineno-0-735" name="__codelineno-0-735"></a>    <span class="k">return</span> <span class="n">normal_samples</span><span class="p">(</span><span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">generator</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace._glm_predictive_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">_glm_predictive_samples</span>


<a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">_glm_predictive_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(f_mu)">f_mu</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(f_var)">f_var</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the posterior predictive on input data <code>x</code> using "glm" prediction
type. I.e., the inverse-link function correponding to the likelihood is applied
on top of the functional sample.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_predictive_samples(f_mu)" class="doc doc-heading doc-heading-parameter">              <b><code>f_mu</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(f_mu)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive mean <code>(batch_size, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_predictive_samples(f_var)" class="doc doc-heading doc-heading-parameter">              <b><code>f_var</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(f_var)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive covariances <code>(batch_size, output_shape, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_predictive_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_predictive_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace._glm_predictive_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.LLLaplace._glm_predictive_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-737">737</a></span>
<span class="normal"><a href="#__codelineno-0-738">738</a></span>
<span class="normal"><a href="#__codelineno-0-739">739</a></span>
<span class="normal"><a href="#__codelineno-0-740">740</a></span>
<span class="normal"><a href="#__codelineno-0-741">741</a></span>
<span class="normal"><a href="#__codelineno-0-742">742</a></span>
<span class="normal"><a href="#__codelineno-0-743">743</a></span>
<span class="normal"><a href="#__codelineno-0-744">744</a></span>
<span class="normal"><a href="#__codelineno-0-745">745</a></span>
<span class="normal"><a href="#__codelineno-0-746">746</a></span>
<span class="normal"><a href="#__codelineno-0-747">747</a></span>
<span class="normal"><a href="#__codelineno-0-748">748</a></span>
<span class="normal"><a href="#__codelineno-0-749">749</a></span>
<span class="normal"><a href="#__codelineno-0-750">750</a></span>
<span class="normal"><a href="#__codelineno-0-751">751</a></span>
<span class="normal"><a href="#__codelineno-0-752">752</a></span>
<span class="normal"><a href="#__codelineno-0-753">753</a></span>
<span class="normal"><a href="#__codelineno-0-754">754</a></span>
<span class="normal"><a href="#__codelineno-0-755">755</a></span>
<span class="normal"><a href="#__codelineno-0-756">756</a></span>
<span class="normal"><a href="#__codelineno-0-757">757</a></span>
<span class="normal"><a href="#__codelineno-0-758">758</a></span>
<span class="normal"><a href="#__codelineno-0-759">759</a></span>
<span class="normal"><a href="#__codelineno-0-760">760</a></span>
<span class="normal"><a href="#__codelineno-0-761">761</a></span>
<span class="normal"><a href="#__codelineno-0-762">762</a></span>
<span class="normal"><a href="#__codelineno-0-763">763</a></span>
<span class="normal"><a href="#__codelineno-0-764">764</a></span>
<span class="normal"><a href="#__codelineno-0-765">765</a></span>
<span class="normal"><a href="#__codelineno-0-766">766</a></span>
<span class="normal"><a href="#__codelineno-0-767">767</a></span>
<span class="normal"><a href="#__codelineno-0-768">768</a></span>
<span class="normal"><a href="#__codelineno-0-769">769</a></span>
<span class="normal"><a href="#__codelineno-0-770">770</a></span>
<span class="normal"><a href="#__codelineno-0-771">771</a></span>
<span class="normal"><a href="#__codelineno-0-772">772</a></span>
<span class="normal"><a href="#__codelineno-0-773">773</a></span>
<span class="normal"><a href="#__codelineno-0-774">774</a></span>
<span class="normal"><a href="#__codelineno-0-775">775</a></span>
<span class="normal"><a href="#__codelineno-0-776">776</a></span>
<span class="normal"><a href="#__codelineno-0-777">777</a></span>
<span class="normal"><a href="#__codelineno-0-778">778</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-737" name="__codelineno-0-737"></a><span class="k">def</span> <span class="nf">_glm_predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-738" name="__codelineno-0-738"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-739" name="__codelineno-0-739"></a>    <span class="n">f_mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-740" name="__codelineno-0-740"></a>    <span class="n">f_var</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-741" name="__codelineno-0-741"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-742" name="__codelineno-0-742"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-743" name="__codelineno-0-743"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-744" name="__codelineno-0-744"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-745" name="__codelineno-0-745"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the posterior predictive on input data `x` using &quot;glm&quot; prediction</span>
<a id="__codelineno-0-746" name="__codelineno-0-746"></a><span class="sd">    type. I.e., the inverse-link function correponding to the likelihood is applied</span>
<a id="__codelineno-0-747" name="__codelineno-0-747"></a><span class="sd">    on top of the functional sample.</span>
<a id="__codelineno-0-748" name="__codelineno-0-748"></a>
<a id="__codelineno-0-749" name="__codelineno-0-749"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-750" name="__codelineno-0-750"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-751" name="__codelineno-0-751"></a><span class="sd">    f_mu : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-752" name="__codelineno-0-752"></a><span class="sd">        glm predictive mean `(batch_size, output_shape)`</span>
<a id="__codelineno-0-753" name="__codelineno-0-753"></a>
<a id="__codelineno-0-754" name="__codelineno-0-754"></a><span class="sd">    f_var : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-755" name="__codelineno-0-755"></a><span class="sd">        glm predictive covariances `(batch_size, output_shape, output_shape)`</span>
<a id="__codelineno-0-756" name="__codelineno-0-756"></a>
<a id="__codelineno-0-757" name="__codelineno-0-757"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-758" name="__codelineno-0-758"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-759" name="__codelineno-0-759"></a>
<a id="__codelineno-0-760" name="__codelineno-0-760"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-761" name="__codelineno-0-761"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-762" name="__codelineno-0-762"></a>
<a id="__codelineno-0-763" name="__codelineno-0-763"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-764" name="__codelineno-0-764"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-765" name="__codelineno-0-765"></a>
<a id="__codelineno-0-766" name="__codelineno-0-766"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-767" name="__codelineno-0-767"></a><span class="sd">    -------</span>
<a id="__codelineno-0-768" name="__codelineno-0-768"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-769" name="__codelineno-0-769"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-770" name="__codelineno-0-770"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-771" name="__codelineno-0-771"></a>    <span class="n">f_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-772" name="__codelineno-0-772"></a>        <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span><span class="p">,</span> <span class="n">generator</span>
<a id="__codelineno-0-773" name="__codelineno-0-773"></a>    <span class="p">)</span>
<a id="__codelineno-0-774" name="__codelineno-0-774"></a>
<a id="__codelineno-0-775" name="__codelineno-0-775"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-776" name="__codelineno-0-776"></a>        <span class="k">return</span> <span class="n">f_samples</span>
<a id="__codelineno-0-777" name="__codelineno-0-777"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-778" name="__codelineno-0-778"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">f_samples</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace.square_norm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">square_norm</span>


<a href="#laplace.lllaplace.LLLaplace.square_norm" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">square_norm</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the square norm under post. Precision with <code>value-self.mean</code> as 𝛥:</p>
<div class="arithmatex">\[
    \Delta^     op P \Delta
\]</div>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
              <code>square_form</code>
          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-983">983</a></span>
<span class="normal"><a href="#__codelineno-0-984">984</a></span>
<span class="normal"><a href="#__codelineno-0-985">985</a></span>
<span class="normal"><a href="#__codelineno-0-986">986</a></span>
<span class="normal"><a href="#__codelineno-0-987">987</a></span>
<span class="normal"><a href="#__codelineno-0-988">988</a></span>
<span class="normal"><a href="#__codelineno-0-989">989</a></span>
<span class="normal"><a href="#__codelineno-0-990">990</a></span>
<span class="normal"><a href="#__codelineno-0-991">991</a></span>
<span class="normal"><a href="#__codelineno-0-992">992</a></span>
<span class="normal"><a href="#__codelineno-0-993">993</a></span>
<span class="normal"><a href="#__codelineno-0-994">994</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-983" name="__codelineno-0-983"></a><span class="k">def</span> <span class="nf">square_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-984" name="__codelineno-0-984"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the square norm under post. Precision with `value-self.mean` as 𝛥:</span>
<a id="__codelineno-0-985" name="__codelineno-0-985"></a>
<a id="__codelineno-0-986" name="__codelineno-0-986"></a><span class="sd">    $$</span>
<a id="__codelineno-0-987" name="__codelineno-0-987"></a><span class="sd">        \\Delta^\top P \\Delta</span>
<a id="__codelineno-0-988" name="__codelineno-0-988"></a><span class="sd">    $$</span>
<a id="__codelineno-0-989" name="__codelineno-0-989"></a>
<a id="__codelineno-0-990" name="__codelineno-0-990"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-991" name="__codelineno-0-991"></a><span class="sd">    -------</span>
<a id="__codelineno-0-992" name="__codelineno-0-992"></a><span class="sd">    square_form</span>
<a id="__codelineno-0-993" name="__codelineno-0-993"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-994" name="__codelineno-0-994"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace.log_prob" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">log_prob</span>


<a href="#laplace.lllaplace.LLLaplace.log_prob" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">log_prob</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.log_prob(value)">value</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.log_prob(normalized)">normalized</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the log probability under the (current) Laplace approximation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.log_prob(value)" class="doc doc-heading doc-heading-parameter">              <b><code>value</code></b>
<a href="#laplace.lllaplace.LLLaplace.log_prob(value)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.log_prob(normalized)" class="doc doc-heading doc-heading-parameter">              <b><code>normalized</code></b>
<a href="#laplace.lllaplace.LLLaplace.log_prob(normalized)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>whether to return log of a properly normalized Gaussian or just the
terms that depend on <code>value</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_prob</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-996"> 996</a></span>
<span class="normal"><a href="#__codelineno-0-997"> 997</a></span>
<span class="normal"><a href="#__codelineno-0-998"> 998</a></span>
<span class="normal"><a href="#__codelineno-0-999"> 999</a></span>
<span class="normal"><a href="#__codelineno-0-1000">1000</a></span>
<span class="normal"><a href="#__codelineno-0-1001">1001</a></span>
<span class="normal"><a href="#__codelineno-0-1002">1002</a></span>
<span class="normal"><a href="#__codelineno-0-1003">1003</a></span>
<span class="normal"><a href="#__codelineno-0-1004">1004</a></span>
<span class="normal"><a href="#__codelineno-0-1005">1005</a></span>
<span class="normal"><a href="#__codelineno-0-1006">1006</a></span>
<span class="normal"><a href="#__codelineno-0-1007">1007</a></span>
<span class="normal"><a href="#__codelineno-0-1008">1008</a></span>
<span class="normal"><a href="#__codelineno-0-1009">1009</a></span>
<span class="normal"><a href="#__codelineno-0-1010">1010</a></span>
<span class="normal"><a href="#__codelineno-0-1011">1011</a></span>
<span class="normal"><a href="#__codelineno-0-1012">1012</a></span>
<span class="normal"><a href="#__codelineno-0-1013">1013</a></span>
<span class="normal"><a href="#__codelineno-0-1014">1014</a></span>
<span class="normal"><a href="#__codelineno-0-1015">1015</a></span>
<span class="normal"><a href="#__codelineno-0-1016">1016</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-996" name="__codelineno-0-996"></a><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">normalized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-997" name="__codelineno-0-997"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the log probability under the (current) Laplace approximation.</span>
<a id="__codelineno-0-998" name="__codelineno-0-998"></a>
<a id="__codelineno-0-999" name="__codelineno-0-999"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1000" name="__codelineno-0-1000"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1001" name="__codelineno-0-1001"></a><span class="sd">    value: torch.Tensor</span>
<a id="__codelineno-0-1002" name="__codelineno-0-1002"></a><span class="sd">    normalized : bool, default=True</span>
<a id="__codelineno-0-1003" name="__codelineno-0-1003"></a><span class="sd">        whether to return log of a properly normalized Gaussian or just the</span>
<a id="__codelineno-0-1004" name="__codelineno-0-1004"></a><span class="sd">        terms that depend on `value`.</span>
<a id="__codelineno-0-1005" name="__codelineno-0-1005"></a>
<a id="__codelineno-0-1006" name="__codelineno-0-1006"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1007" name="__codelineno-0-1007"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1008" name="__codelineno-0-1008"></a><span class="sd">    log_prob : torch.Tensor</span>
<a id="__codelineno-0-1009" name="__codelineno-0-1009"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1010" name="__codelineno-0-1010"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">normalized</span><span class="p">:</span>
<a id="__codelineno-0-1011" name="__codelineno-0-1011"></a>        <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">square_norm</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-0-1012" name="__codelineno-0-1012"></a>    <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-1013" name="__codelineno-0-1013"></a>        <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">n_params</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">pi</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_det_posterior_precision</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-0-1014" name="__codelineno-0-1014"></a>    <span class="p">)</span>
<a id="__codelineno-0-1015" name="__codelineno-0-1015"></a>    <span class="n">log_prob</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">square_norm</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-0-1016" name="__codelineno-0-1016"></a>    <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace.functional_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">functional_samples</span>


<a href="#laplace.lllaplace.LLLaplace.functional_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">functional_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.functional_samples(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.functional_samples(pred_type)">pred_type</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType" href="../enums/#laplace.utils.enums.PredType">PredType</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType.GLM" href="../enums/#laplace.utils.enums.PredType.GLM">GLM</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.functional_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.functional_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.functional_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the function-space posterior on input data <code>x</code>.
Can be used, for example, for Thompson sampling or to compute an arbitrary
expectation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.functional_samples(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.LLLaplace.functional_samples(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>input data <code>(batch_size, input_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.functional_samples(pred_type)" class="doc doc-heading doc-heading-parameter">              <b><code>pred_type</code></b>
<a href="#laplace.lllaplace.LLLaplace.functional_samples(pred_type)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;glm&#39;, &#39;nn&#39;)</code>, default:
                  <code>&#39;glm&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>type of posterior predictive, linearized GLM predictive or neural
network sampling predictive. The GLM predictive is consistent with
the curvature approximations used here.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.functional_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.LLLaplace.functional_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.functional_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.LLLaplace.functional_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.
Only applies when <code>pred_type='glm'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.functional_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.LLLaplace.functional_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1154">1154</a></span>
<span class="normal"><a href="#__codelineno-0-1155">1155</a></span>
<span class="normal"><a href="#__codelineno-0-1156">1156</a></span>
<span class="normal"><a href="#__codelineno-0-1157">1157</a></span>
<span class="normal"><a href="#__codelineno-0-1158">1158</a></span>
<span class="normal"><a href="#__codelineno-0-1159">1159</a></span>
<span class="normal"><a href="#__codelineno-0-1160">1160</a></span>
<span class="normal"><a href="#__codelineno-0-1161">1161</a></span>
<span class="normal"><a href="#__codelineno-0-1162">1162</a></span>
<span class="normal"><a href="#__codelineno-0-1163">1163</a></span>
<span class="normal"><a href="#__codelineno-0-1164">1164</a></span>
<span class="normal"><a href="#__codelineno-0-1165">1165</a></span>
<span class="normal"><a href="#__codelineno-0-1166">1166</a></span>
<span class="normal"><a href="#__codelineno-0-1167">1167</a></span>
<span class="normal"><a href="#__codelineno-0-1168">1168</a></span>
<span class="normal"><a href="#__codelineno-0-1169">1169</a></span>
<span class="normal"><a href="#__codelineno-0-1170">1170</a></span>
<span class="normal"><a href="#__codelineno-0-1171">1171</a></span>
<span class="normal"><a href="#__codelineno-0-1172">1172</a></span>
<span class="normal"><a href="#__codelineno-0-1173">1173</a></span>
<span class="normal"><a href="#__codelineno-0-1174">1174</a></span>
<span class="normal"><a href="#__codelineno-0-1175">1175</a></span>
<span class="normal"><a href="#__codelineno-0-1176">1176</a></span>
<span class="normal"><a href="#__codelineno-0-1177">1177</a></span>
<span class="normal"><a href="#__codelineno-0-1178">1178</a></span>
<span class="normal"><a href="#__codelineno-0-1179">1179</a></span>
<span class="normal"><a href="#__codelineno-0-1180">1180</a></span>
<span class="normal"><a href="#__codelineno-0-1181">1181</a></span>
<span class="normal"><a href="#__codelineno-0-1182">1182</a></span>
<span class="normal"><a href="#__codelineno-0-1183">1183</a></span>
<span class="normal"><a href="#__codelineno-0-1184">1184</a></span>
<span class="normal"><a href="#__codelineno-0-1185">1185</a></span>
<span class="normal"><a href="#__codelineno-0-1186">1186</a></span>
<span class="normal"><a href="#__codelineno-0-1187">1187</a></span>
<span class="normal"><a href="#__codelineno-0-1188">1188</a></span>
<span class="normal"><a href="#__codelineno-0-1189">1189</a></span>
<span class="normal"><a href="#__codelineno-0-1190">1190</a></span>
<span class="normal"><a href="#__codelineno-0-1191">1191</a></span>
<span class="normal"><a href="#__codelineno-0-1192">1192</a></span>
<span class="normal"><a href="#__codelineno-0-1193">1193</a></span>
<span class="normal"><a href="#__codelineno-0-1194">1194</a></span>
<span class="normal"><a href="#__codelineno-0-1195">1195</a></span>
<span class="normal"><a href="#__codelineno-0-1196">1196</a></span>
<span class="normal"><a href="#__codelineno-0-1197">1197</a></span>
<span class="normal"><a href="#__codelineno-0-1198">1198</a></span>
<span class="normal"><a href="#__codelineno-0-1199">1199</a></span>
<span class="normal"><a href="#__codelineno-0-1200">1200</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1154" name="__codelineno-0-1154"></a><span class="k">def</span> <span class="nf">functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-1155" name="__codelineno-0-1155"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1156" name="__codelineno-0-1156"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1157" name="__codelineno-0-1157"></a>    <span class="n">pred_type</span><span class="p">:</span> <span class="n">PredType</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">,</span>
<a id="__codelineno-0-1158" name="__codelineno-0-1158"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-1159" name="__codelineno-0-1159"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1160" name="__codelineno-0-1160"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1161" name="__codelineno-0-1161"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1162" name="__codelineno-0-1162"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the function-space posterior on input data `x`.</span>
<a id="__codelineno-0-1163" name="__codelineno-0-1163"></a><span class="sd">    Can be used, for example, for Thompson sampling or to compute an arbitrary</span>
<a id="__codelineno-0-1164" name="__codelineno-0-1164"></a><span class="sd">    expectation.</span>
<a id="__codelineno-0-1165" name="__codelineno-0-1165"></a>
<a id="__codelineno-0-1166" name="__codelineno-0-1166"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1167" name="__codelineno-0-1167"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1168" name="__codelineno-0-1168"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-1169" name="__codelineno-0-1169"></a><span class="sd">        input data `(batch_size, input_shape)`</span>
<a id="__codelineno-0-1170" name="__codelineno-0-1170"></a>
<a id="__codelineno-0-1171" name="__codelineno-0-1171"></a><span class="sd">    pred_type : {&#39;glm&#39;, &#39;nn&#39;}, default=&#39;glm&#39;</span>
<a id="__codelineno-0-1172" name="__codelineno-0-1172"></a><span class="sd">        type of posterior predictive, linearized GLM predictive or neural</span>
<a id="__codelineno-0-1173" name="__codelineno-0-1173"></a><span class="sd">        network sampling predictive. The GLM predictive is consistent with</span>
<a id="__codelineno-0-1174" name="__codelineno-0-1174"></a><span class="sd">        the curvature approximations used here.</span>
<a id="__codelineno-0-1175" name="__codelineno-0-1175"></a>
<a id="__codelineno-0-1176" name="__codelineno-0-1176"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-1177" name="__codelineno-0-1177"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-1178" name="__codelineno-0-1178"></a>
<a id="__codelineno-0-1179" name="__codelineno-0-1179"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-1180" name="__codelineno-0-1180"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-1181" name="__codelineno-0-1181"></a><span class="sd">        Only applies when `pred_type=&#39;glm&#39;`.</span>
<a id="__codelineno-0-1182" name="__codelineno-0-1182"></a>
<a id="__codelineno-0-1183" name="__codelineno-0-1183"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1184" name="__codelineno-0-1184"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-1185" name="__codelineno-0-1185"></a>
<a id="__codelineno-0-1186" name="__codelineno-0-1186"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1187" name="__codelineno-0-1187"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1188" name="__codelineno-0-1188"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-1189" name="__codelineno-0-1189"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-1190" name="__codelineno-0-1190"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1191" name="__codelineno-0-1191"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">PredType</span><span class="o">.</span><span class="n">__members__</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<a id="__codelineno-0-1192" name="__codelineno-0-1192"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only glm and nn supported as prediction types.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1193" name="__codelineno-0-1193"></a>
<a id="__codelineno-0-1194" name="__codelineno-0-1194"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">:</span>
<a id="__codelineno-0-1195" name="__codelineno-0-1195"></a>        <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_distribution</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-1196" name="__codelineno-0-1196"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-1197" name="__codelineno-0-1197"></a>            <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span><span class="p">,</span> <span class="n">generator</span>
<a id="__codelineno-0-1198" name="__codelineno-0-1198"></a>        <span class="p">)</span>
<a id="__codelineno-0-1199" name="__codelineno-0-1199"></a>    <span class="k">else</span><span class="p">:</span>  <span class="c1"># &#39;nn&#39;</span>
<a id="__codelineno-0-1200" name="__codelineno-0-1200"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_functional_samples</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">generator</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace.predictive_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">predictive_samples</span>


<a href="#laplace.lllaplace.LLLaplace.predictive_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">predictive_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.predictive_samples(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.predictive_samples(pred_type)">pred_type</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType" href="../enums/#laplace.utils.enums.PredType">PredType</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType.GLM" href="../enums/#laplace.utils.enums.PredType.GLM">GLM</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.predictive_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.predictive_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.predictive_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the posterior predictive on input data <code>x</code>. I.e., the respective
inverse-link function (e.g. softmax) is applied on top of the functional
sample.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.predictive_samples(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.LLLaplace.predictive_samples(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>input data <code>(batch_size, input_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.predictive_samples(pred_type)" class="doc doc-heading doc-heading-parameter">              <b><code>pred_type</code></b>
<a href="#laplace.lllaplace.LLLaplace.predictive_samples(pred_type)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;glm&#39;, &#39;nn&#39;)</code>, default:
                  <code>&#39;glm&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>type of posterior predictive, linearized GLM predictive or neural
network sampling predictive. The GLM predictive is consistent with
the curvature approximations used here.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.predictive_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.LLLaplace.predictive_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.predictive_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.LLLaplace.predictive_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.
Only applies when <code>pred_type='glm'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.predictive_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.LLLaplace.predictive_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1202">1202</a></span>
<span class="normal"><a href="#__codelineno-0-1203">1203</a></span>
<span class="normal"><a href="#__codelineno-0-1204">1204</a></span>
<span class="normal"><a href="#__codelineno-0-1205">1205</a></span>
<span class="normal"><a href="#__codelineno-0-1206">1206</a></span>
<span class="normal"><a href="#__codelineno-0-1207">1207</a></span>
<span class="normal"><a href="#__codelineno-0-1208">1208</a></span>
<span class="normal"><a href="#__codelineno-0-1209">1209</a></span>
<span class="normal"><a href="#__codelineno-0-1210">1210</a></span>
<span class="normal"><a href="#__codelineno-0-1211">1211</a></span>
<span class="normal"><a href="#__codelineno-0-1212">1212</a></span>
<span class="normal"><a href="#__codelineno-0-1213">1213</a></span>
<span class="normal"><a href="#__codelineno-0-1214">1214</a></span>
<span class="normal"><a href="#__codelineno-0-1215">1215</a></span>
<span class="normal"><a href="#__codelineno-0-1216">1216</a></span>
<span class="normal"><a href="#__codelineno-0-1217">1217</a></span>
<span class="normal"><a href="#__codelineno-0-1218">1218</a></span>
<span class="normal"><a href="#__codelineno-0-1219">1219</a></span>
<span class="normal"><a href="#__codelineno-0-1220">1220</a></span>
<span class="normal"><a href="#__codelineno-0-1221">1221</a></span>
<span class="normal"><a href="#__codelineno-0-1222">1222</a></span>
<span class="normal"><a href="#__codelineno-0-1223">1223</a></span>
<span class="normal"><a href="#__codelineno-0-1224">1224</a></span>
<span class="normal"><a href="#__codelineno-0-1225">1225</a></span>
<span class="normal"><a href="#__codelineno-0-1226">1226</a></span>
<span class="normal"><a href="#__codelineno-0-1227">1227</a></span>
<span class="normal"><a href="#__codelineno-0-1228">1228</a></span>
<span class="normal"><a href="#__codelineno-0-1229">1229</a></span>
<span class="normal"><a href="#__codelineno-0-1230">1230</a></span>
<span class="normal"><a href="#__codelineno-0-1231">1231</a></span>
<span class="normal"><a href="#__codelineno-0-1232">1232</a></span>
<span class="normal"><a href="#__codelineno-0-1233">1233</a></span>
<span class="normal"><a href="#__codelineno-0-1234">1234</a></span>
<span class="normal"><a href="#__codelineno-0-1235">1235</a></span>
<span class="normal"><a href="#__codelineno-0-1236">1236</a></span>
<span class="normal"><a href="#__codelineno-0-1237">1237</a></span>
<span class="normal"><a href="#__codelineno-0-1238">1238</a></span>
<span class="normal"><a href="#__codelineno-0-1239">1239</a></span>
<span class="normal"><a href="#__codelineno-0-1240">1240</a></span>
<span class="normal"><a href="#__codelineno-0-1241">1241</a></span>
<span class="normal"><a href="#__codelineno-0-1242">1242</a></span>
<span class="normal"><a href="#__codelineno-0-1243">1243</a></span>
<span class="normal"><a href="#__codelineno-0-1244">1244</a></span>
<span class="normal"><a href="#__codelineno-0-1245">1245</a></span>
<span class="normal"><a href="#__codelineno-0-1246">1246</a></span>
<span class="normal"><a href="#__codelineno-0-1247">1247</a></span>
<span class="normal"><a href="#__codelineno-0-1248">1248</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1202" name="__codelineno-0-1202"></a><span class="k">def</span> <span class="nf">predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-1203" name="__codelineno-0-1203"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1204" name="__codelineno-0-1204"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1205" name="__codelineno-0-1205"></a>    <span class="n">pred_type</span><span class="p">:</span> <span class="n">PredType</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">,</span>
<a id="__codelineno-0-1206" name="__codelineno-0-1206"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-1207" name="__codelineno-0-1207"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1208" name="__codelineno-0-1208"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1209" name="__codelineno-0-1209"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1210" name="__codelineno-0-1210"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the posterior predictive on input data `x`. I.e., the respective</span>
<a id="__codelineno-0-1211" name="__codelineno-0-1211"></a><span class="sd">    inverse-link function (e.g. softmax) is applied on top of the functional</span>
<a id="__codelineno-0-1212" name="__codelineno-0-1212"></a><span class="sd">    sample.</span>
<a id="__codelineno-0-1213" name="__codelineno-0-1213"></a>
<a id="__codelineno-0-1214" name="__codelineno-0-1214"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1215" name="__codelineno-0-1215"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1216" name="__codelineno-0-1216"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-1217" name="__codelineno-0-1217"></a><span class="sd">        input data `(batch_size, input_shape)`</span>
<a id="__codelineno-0-1218" name="__codelineno-0-1218"></a>
<a id="__codelineno-0-1219" name="__codelineno-0-1219"></a><span class="sd">    pred_type : {&#39;glm&#39;, &#39;nn&#39;}, default=&#39;glm&#39;</span>
<a id="__codelineno-0-1220" name="__codelineno-0-1220"></a><span class="sd">        type of posterior predictive, linearized GLM predictive or neural</span>
<a id="__codelineno-0-1221" name="__codelineno-0-1221"></a><span class="sd">        network sampling predictive. The GLM predictive is consistent with</span>
<a id="__codelineno-0-1222" name="__codelineno-0-1222"></a><span class="sd">        the curvature approximations used here.</span>
<a id="__codelineno-0-1223" name="__codelineno-0-1223"></a>
<a id="__codelineno-0-1224" name="__codelineno-0-1224"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-1225" name="__codelineno-0-1225"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-1226" name="__codelineno-0-1226"></a>
<a id="__codelineno-0-1227" name="__codelineno-0-1227"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-1228" name="__codelineno-0-1228"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-1229" name="__codelineno-0-1229"></a><span class="sd">        Only applies when `pred_type=&#39;glm&#39;`.</span>
<a id="__codelineno-0-1230" name="__codelineno-0-1230"></a>
<a id="__codelineno-0-1231" name="__codelineno-0-1231"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1232" name="__codelineno-0-1232"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-1233" name="__codelineno-0-1233"></a>
<a id="__codelineno-0-1234" name="__codelineno-0-1234"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1235" name="__codelineno-0-1235"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1236" name="__codelineno-0-1236"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-1237" name="__codelineno-0-1237"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-1238" name="__codelineno-0-1238"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1239" name="__codelineno-0-1239"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">PredType</span><span class="o">.</span><span class="n">__members__</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<a id="__codelineno-0-1240" name="__codelineno-0-1240"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only glm and nn supported as prediction types.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1241" name="__codelineno-0-1241"></a>
<a id="__codelineno-0-1242" name="__codelineno-0-1242"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">:</span>
<a id="__codelineno-0-1243" name="__codelineno-0-1243"></a>        <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_distribution</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-1244" name="__codelineno-0-1244"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-1245" name="__codelineno-0-1245"></a>            <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span><span class="p">,</span> <span class="n">generator</span>
<a id="__codelineno-0-1246" name="__codelineno-0-1246"></a>        <span class="p">)</span>
<a id="__codelineno-0-1247" name="__codelineno-0-1247"></a>    <span class="k">else</span><span class="p">:</span>  <span class="c1"># &#39;nn&#39;</span>
<a id="__codelineno-0-1248" name="__codelineno-0-1248"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_predictive_samples</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">generator</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace.functional_variance" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">functional_variance</span>


<a href="#laplace.lllaplace.LLLaplace.functional_variance" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">functional_variance</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.functional_variance(Js)">Js</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute functional variance for the <code>'glm'</code> predictive:
<code>f_var[i] = Js[i] @ P.inv() @ Js[i].T</code>, which is a output x output
predictive covariance matrix.
Mathematically, we have for a single Jacobian
<span class="arithmatex">\(\mathcal{J} = \nabla_\theta f(x;\theta)\vert_{\theta_{MAP}}\)</span>
the output covariance matrix
<span class="arithmatex">\( \mathcal{J} P^{-1} \mathcal{J}^T \)</span>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.functional_variance(Js)" class="doc doc-heading doc-heading-parameter">              <b><code>Js</code></b>
<a href="#laplace.lllaplace.LLLaplace.functional_variance(Js)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Jacobians of model output wrt parameters
<code>(batch, outputs, parameters)</code></p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>f_var</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>output covariance <code>(batch, outputs, outputs)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1340">1340</a></span>
<span class="normal"><a href="#__codelineno-0-1341">1341</a></span>
<span class="normal"><a href="#__codelineno-0-1342">1342</a></span>
<span class="normal"><a href="#__codelineno-0-1343">1343</a></span>
<span class="normal"><a href="#__codelineno-0-1344">1344</a></span>
<span class="normal"><a href="#__codelineno-0-1345">1345</a></span>
<span class="normal"><a href="#__codelineno-0-1346">1346</a></span>
<span class="normal"><a href="#__codelineno-0-1347">1347</a></span>
<span class="normal"><a href="#__codelineno-0-1348">1348</a></span>
<span class="normal"><a href="#__codelineno-0-1349">1349</a></span>
<span class="normal"><a href="#__codelineno-0-1350">1350</a></span>
<span class="normal"><a href="#__codelineno-0-1351">1351</a></span>
<span class="normal"><a href="#__codelineno-0-1352">1352</a></span>
<span class="normal"><a href="#__codelineno-0-1353">1353</a></span>
<span class="normal"><a href="#__codelineno-0-1354">1354</a></span>
<span class="normal"><a href="#__codelineno-0-1355">1355</a></span>
<span class="normal"><a href="#__codelineno-0-1356">1356</a></span>
<span class="normal"><a href="#__codelineno-0-1357">1357</a></span>
<span class="normal"><a href="#__codelineno-0-1358">1358</a></span>
<span class="normal"><a href="#__codelineno-0-1359">1359</a></span>
<span class="normal"><a href="#__codelineno-0-1360">1360</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1340" name="__codelineno-0-1340"></a><span class="k">def</span> <span class="nf">functional_variance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Js</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1341" name="__codelineno-0-1341"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute functional variance for the `&#39;glm&#39;` predictive:</span>
<a id="__codelineno-0-1342" name="__codelineno-0-1342"></a><span class="sd">    `f_var[i] = Js[i] @ P.inv() @ Js[i].T`, which is a output x output</span>
<a id="__codelineno-0-1343" name="__codelineno-0-1343"></a><span class="sd">    predictive covariance matrix.</span>
<a id="__codelineno-0-1344" name="__codelineno-0-1344"></a><span class="sd">    Mathematically, we have for a single Jacobian</span>
<a id="__codelineno-0-1345" name="__codelineno-0-1345"></a><span class="sd">    \\(\\mathcal{J} = \\nabla_\\theta f(x;\\theta)\\vert_{\\theta_{MAP}}\\)</span>
<a id="__codelineno-0-1346" name="__codelineno-0-1346"></a><span class="sd">    the output covariance matrix</span>
<a id="__codelineno-0-1347" name="__codelineno-0-1347"></a><span class="sd">    \\( \\mathcal{J} P^{-1} \\mathcal{J}^T \\).</span>
<a id="__codelineno-0-1348" name="__codelineno-0-1348"></a>
<a id="__codelineno-0-1349" name="__codelineno-0-1349"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1350" name="__codelineno-0-1350"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1351" name="__codelineno-0-1351"></a><span class="sd">    Js : torch.Tensor</span>
<a id="__codelineno-0-1352" name="__codelineno-0-1352"></a><span class="sd">        Jacobians of model output wrt parameters</span>
<a id="__codelineno-0-1353" name="__codelineno-0-1353"></a><span class="sd">        `(batch, outputs, parameters)`</span>
<a id="__codelineno-0-1354" name="__codelineno-0-1354"></a>
<a id="__codelineno-0-1355" name="__codelineno-0-1355"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1356" name="__codelineno-0-1356"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1357" name="__codelineno-0-1357"></a><span class="sd">    f_var : torch.Tensor</span>
<a id="__codelineno-0-1358" name="__codelineno-0-1358"></a><span class="sd">        output covariance `(batch, outputs, outputs)`</span>
<a id="__codelineno-0-1359" name="__codelineno-0-1359"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1360" name="__codelineno-0-1360"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace.functional_covariance" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">functional_covariance</span>


<a href="#laplace.lllaplace.LLLaplace.functional_covariance" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">functional_covariance</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.functional_covariance(Js)">Js</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute functional covariance for the <code>'glm'</code> predictive:
<code>f_cov = Js @ P.inv() @ Js.T</code>, which is a batch<em>output x batch</em>output
predictive covariance matrix.</p>
<p>This emulates the GP posterior covariance N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).
Useful for joint predictions, such as in batched Bayesian optimization.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.functional_covariance(Js)" class="doc doc-heading doc-heading-parameter">              <b><code>Js</code></b>
<a href="#laplace.lllaplace.LLLaplace.functional_covariance(Js)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Jacobians of model output wrt parameters
<code>(batch*outputs, parameters)</code></p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>f_cov</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>output covariance <code>(batch*outputs, batch*outputs)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1362">1362</a></span>
<span class="normal"><a href="#__codelineno-0-1363">1363</a></span>
<span class="normal"><a href="#__codelineno-0-1364">1364</a></span>
<span class="normal"><a href="#__codelineno-0-1365">1365</a></span>
<span class="normal"><a href="#__codelineno-0-1366">1366</a></span>
<span class="normal"><a href="#__codelineno-0-1367">1367</a></span>
<span class="normal"><a href="#__codelineno-0-1368">1368</a></span>
<span class="normal"><a href="#__codelineno-0-1369">1369</a></span>
<span class="normal"><a href="#__codelineno-0-1370">1370</a></span>
<span class="normal"><a href="#__codelineno-0-1371">1371</a></span>
<span class="normal"><a href="#__codelineno-0-1372">1372</a></span>
<span class="normal"><a href="#__codelineno-0-1373">1373</a></span>
<span class="normal"><a href="#__codelineno-0-1374">1374</a></span>
<span class="normal"><a href="#__codelineno-0-1375">1375</a></span>
<span class="normal"><a href="#__codelineno-0-1376">1376</a></span>
<span class="normal"><a href="#__codelineno-0-1377">1377</a></span>
<span class="normal"><a href="#__codelineno-0-1378">1378</a></span>
<span class="normal"><a href="#__codelineno-0-1379">1379</a></span>
<span class="normal"><a href="#__codelineno-0-1380">1380</a></span>
<span class="normal"><a href="#__codelineno-0-1381">1381</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1362" name="__codelineno-0-1362"></a><span class="k">def</span> <span class="nf">functional_covariance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Js</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1363" name="__codelineno-0-1363"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute functional covariance for the `&#39;glm&#39;` predictive:</span>
<a id="__codelineno-0-1364" name="__codelineno-0-1364"></a><span class="sd">    `f_cov = Js @ P.inv() @ Js.T`, which is a batch*output x batch*output</span>
<a id="__codelineno-0-1365" name="__codelineno-0-1365"></a><span class="sd">    predictive covariance matrix.</span>
<a id="__codelineno-0-1366" name="__codelineno-0-1366"></a>
<a id="__codelineno-0-1367" name="__codelineno-0-1367"></a><span class="sd">    This emulates the GP posterior covariance N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).</span>
<a id="__codelineno-0-1368" name="__codelineno-0-1368"></a><span class="sd">    Useful for joint predictions, such as in batched Bayesian optimization.</span>
<a id="__codelineno-0-1369" name="__codelineno-0-1369"></a>
<a id="__codelineno-0-1370" name="__codelineno-0-1370"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1371" name="__codelineno-0-1371"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1372" name="__codelineno-0-1372"></a><span class="sd">    Js : torch.Tensor</span>
<a id="__codelineno-0-1373" name="__codelineno-0-1373"></a><span class="sd">        Jacobians of model output wrt parameters</span>
<a id="__codelineno-0-1374" name="__codelineno-0-1374"></a><span class="sd">        `(batch*outputs, parameters)`</span>
<a id="__codelineno-0-1375" name="__codelineno-0-1375"></a>
<a id="__codelineno-0-1376" name="__codelineno-0-1376"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1377" name="__codelineno-0-1377"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1378" name="__codelineno-0-1378"></a><span class="sd">    f_cov : torch.Tensor</span>
<a id="__codelineno-0-1379" name="__codelineno-0-1379"></a><span class="sd">        output covariance `(batch*outputs, batch*outputs)`</span>
<a id="__codelineno-0-1380" name="__codelineno-0-1380"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1381" name="__codelineno-0-1381"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace.sample" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">sample</span>


<a href="#laplace.lllaplace.LLLaplace.sample" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">sample</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.sample(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.sample(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the Laplace posterior approximation, i.e.,
<span class="arithmatex">\( \theta \sim \mathcal{N}(\theta_{MAP}, P^{-1})\)</span>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.sample(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.LLLaplace.sample(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.sample(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.LLLaplace.sample(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1383">1383</a></span>
<span class="normal"><a href="#__codelineno-0-1384">1384</a></span>
<span class="normal"><a href="#__codelineno-0-1385">1385</a></span>
<span class="normal"><a href="#__codelineno-0-1386">1386</a></span>
<span class="normal"><a href="#__codelineno-0-1387">1387</a></span>
<span class="normal"><a href="#__codelineno-0-1388">1388</a></span>
<span class="normal"><a href="#__codelineno-0-1389">1389</a></span>
<span class="normal"><a href="#__codelineno-0-1390">1390</a></span>
<span class="normal"><a href="#__codelineno-0-1391">1391</a></span>
<span class="normal"><a href="#__codelineno-0-1392">1392</a></span>
<span class="normal"><a href="#__codelineno-0-1393">1393</a></span>
<span class="normal"><a href="#__codelineno-0-1394">1394</a></span>
<span class="normal"><a href="#__codelineno-0-1395">1395</a></span>
<span class="normal"><a href="#__codelineno-0-1396">1396</a></span>
<span class="normal"><a href="#__codelineno-0-1397">1397</a></span>
<span class="normal"><a href="#__codelineno-0-1398">1398</a></span>
<span class="normal"><a href="#__codelineno-0-1399">1399</a></span>
<span class="normal"><a href="#__codelineno-0-1400">1400</a></span>
<span class="normal"><a href="#__codelineno-0-1401">1401</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1383" name="__codelineno-0-1383"></a><span class="k">def</span> <span class="nf">sample</span><span class="p">(</span>
<a id="__codelineno-0-1384" name="__codelineno-0-1384"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-1385" name="__codelineno-0-1385"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1386" name="__codelineno-0-1386"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the Laplace posterior approximation, i.e.,</span>
<a id="__codelineno-0-1387" name="__codelineno-0-1387"></a><span class="sd">    \\( \\theta \\sim \\mathcal{N}(\\theta_{MAP}, P^{-1})\\).</span>
<a id="__codelineno-0-1388" name="__codelineno-0-1388"></a>
<a id="__codelineno-0-1389" name="__codelineno-0-1389"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1390" name="__codelineno-0-1390"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1391" name="__codelineno-0-1391"></a><span class="sd">    n_samples : int, default=100</span>
<a id="__codelineno-0-1392" name="__codelineno-0-1392"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-1393" name="__codelineno-0-1393"></a>
<a id="__codelineno-0-1394" name="__codelineno-0-1394"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1395" name="__codelineno-0-1395"></a><span class="sd">        random number generator to control the samples</span>
<a id="__codelineno-0-1396" name="__codelineno-0-1396"></a>
<a id="__codelineno-0-1397" name="__codelineno-0-1397"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1398" name="__codelineno-0-1398"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1399" name="__codelineno-0-1399"></a><span class="sd">    samples: torch.Tensor</span>
<a id="__codelineno-0-1400" name="__codelineno-0-1400"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1401" name="__codelineno-0-1401"></a>    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace.fit" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">fit</span>


<a href="#laplace.lllaplace.LLLaplace.fit" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">fit</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.fit(train_loader)">train_loader</a></span><span class="p">:</span> <span class="n"><span title="torch.utils.data.DataLoader">DataLoader</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.fit(override)">override</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.fit(progress_bar)">progress_bar</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Fit the local Laplace approximation at the parameters of the model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.fit(train_loader)" class="doc doc-heading doc-heading-parameter">              <b><code>train_loader</code></b>
<a href="#laplace.lllaplace.LLLaplace.fit(train_loader)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.data.utils.DataLoader">DataLoader</span></code>)
          –
          <div class="doc-md-description">
            <p>each iterate is a training batch, either <code>(X, y)</code> tensors or a dict-like
object containing keys as expressed by <code>self.dict_key_x</code> and
<code>self.dict_key_y</code>. <code>train_loader.dataset</code> needs to be set to access
<span class="arithmatex">\(N\)</span>, size of the data set.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.fit(override)" class="doc doc-heading doc-heading-parameter">              <b><code>override</code></b>
<a href="#laplace.lllaplace.LLLaplace.fit(override)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>whether to initialize H, loss, and n_data again; setting to False is useful for
online learning settings to accumulate a sequential posterior approximation.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.fit(progress_bar)" class="doc doc-heading doc-heading-parameter">              <b><code>progress_bar</code></b>
<a href="#laplace.lllaplace.LLLaplace.fit(progress_bar)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/lllaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>    <span class="n">progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Fit the local Laplace approximation at the parameters of the model.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">    train_loader : torch.data.utils.DataLoader</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">        each iterate is a training batch, either `(X, y)` tensors or a dict-like</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">        object containing keys as expressed by `self.dict_key_x` and</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">        `self.dict_key_y`. `train_loader.dataset` needs to be set to access</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a><span class="sd">        \\(N\\), size of the data set.</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a><span class="sd">    override : bool, default=True</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">        whether to initialize H, loss, and n_data again; setting to False is useful for</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a><span class="sd">        online learning settings to accumulate a sequential posterior approximation.</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">    progress_bar: bool, default=False</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">override</span><span class="p">:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>            <span class="s2">&quot;Last-layer Laplace approximations do not support `override=False`.&quot;</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="n">MutableMapping</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>            <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="p">)</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_find_last_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>        <span class="n">params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">parameters_to_vector</span><span class="p">(</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>        <span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>        <span class="c1"># here, check the already set prior precision again</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior_precision</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior_mean</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_init_H</span><span class="p">()</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="n">override</span><span class="p">)</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">parameters_to_vector</span><span class="p">(</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>    <span class="p">)</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_backprop</span><span class="p">:</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.LLLaplace.functional_variance_fast" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">functional_variance_fast</span>


<a href="#laplace.lllaplace.LLLaplace.functional_variance_fast" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">functional_variance_fast</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.LLLaplace.functional_variance_fast(X)">X</a></span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Should be overriden if there exists a trick to make this fast!</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.LLLaplace.functional_variance_fast(X)" class="doc doc-heading doc-heading-parameter">              <b><code>X</code></b>
<a href="#laplace.lllaplace.LLLaplace.functional_variance_fast(X)" class="headerlink" title="Permanent link">#</a></h4>          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>f_var_diag</code></b> (              <code>torch.Tensor of shape (batch_size, num_outputs)</code>
)          –
          <div class="doc-md-description">
            <p>Corresponding to the diagonal of the covariance matrix of the outputs</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/lllaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-239" name="__codelineno-0-239"></a><span class="k">def</span> <span class="nf">functional_variance_fast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a><span class="sd">    Should be overriden if there exists a trick to make this fast!</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a><span class="sd">    X: torch.Tensor of shape (batch_size, input_dim)</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a><span class="sd">    -------</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a><span class="sd">    f_var_diag: torch.Tensor of shape (batch_size, num_outputs)</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a><span class="sd">        Corresponding to the diagonal of the covariance matrix of the outputs</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>    <span class="n">Js</span><span class="p">,</span> <span class="n">f_mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">last_layer_jacobians</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_backprop</span><span class="p">)</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>    <span class="n">f_cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">functional_variance</span><span class="p">(</span><span class="n">Js</span><span class="p">)</span>  <span class="c1"># No trick possible for Full Laplace</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>    <span class="n">f_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_cov</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>    <span class="k">return</span> <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="laplace.lllaplace.DiagLLLaplace" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">DiagLLLaplace</span>


<a href="#laplace.lllaplace.DiagLLLaplace" class="headerlink" title="Permanent link">#</a></h2>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">DiagLLLaplace</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n"><span title="torch.nn.Module">Module</span></span><span class="p">,</span> <span class="n">likelihood</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n">sigma_noise</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">prior_precision</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">temperature</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">enable_backprop</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">feature_reduction</span><span class="p">:</span> <span class="n"><span title="laplace.utils.feature_extractor.FeatureReduction">FeatureReduction</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dict_key_x</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="n">dict_key_y</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="s1">&#39;labels&#39;</span><span class="p">,</span> <span class="n">backend</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#type">type</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="laplace.curvature.curvature.CurvatureInterface" href="../curvatures/#laplace.curvature.CurvatureInterface">CurvatureInterface</a></span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">last_layer_name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">backend_kwargs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">asdl_fisher_kwargs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace" href="#laplace.lllaplace.LLLaplace">LLLaplace</a></code>, <code><a class="autorefs autorefs-internal" title="laplace.baselaplace.DiagLaplace" href="../parametriclaplace/#laplace.baselaplace.DiagLaplace">DiagLaplace</a></code></p>


        <p>Last-layer Laplace approximation with diagonal log likelihood Hessian approximation
and hence posterior precision.
Mathematically, we have <span class="arithmatex">\(P \approx \textrm{diag}(P)\)</span>.
See <code>DiagLaplace</code>, <code>LLLaplace</code>, and <code>BaseLaplace</code> for the full interface.</p>









<p><span class="doc-section-title">Methods:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.fit" href="#laplace.lllaplace.DiagLLLaplace.fit">fit</a></code></b>
            –
            <div class="doc-md-description">
              <p>Fit the local Laplace approximation at the parameters of the model.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood" href="#laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood">log_marginal_likelihood</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the Laplace approximation to the log marginal likelihood subject</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.__call__" href="#laplace.lllaplace.DiagLLLaplace.__call__">__call__</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the posterior predictive on input data <code>x</code>.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.log_prob" href="#laplace.lllaplace.DiagLLLaplace.log_prob">log_prob</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the log probability under the (current) Laplace approximation.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.functional_samples" href="#laplace.lllaplace.DiagLLLaplace.functional_samples">functional_samples</a></code></b>
            –
            <div class="doc-md-description">
              <p>Sample from the function-space posterior on input data <code>x</code>.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.predictive_samples" href="#laplace.lllaplace.DiagLLLaplace.predictive_samples">predictive_samples</a></code></b>
            –
            <div class="doc-md-description">
              <p>Sample from the posterior predictive on input data <code>x</code>. I.e., the respective</p>
            </div>
          </li>
    </ul>




<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.log_likelihood" href="#laplace.lllaplace.DiagLLLaplace.log_likelihood">log_likelihood</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute log likelihood on the training data after <code>.fit()</code> has been called.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.prior_precision_diag" href="#laplace.lllaplace.DiagLLLaplace.prior_precision_diag">prior_precision_diag</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Obtain the diagonal prior precision <span class="arithmatex">\(p_0\)</span> constructed from either</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.scatter" href="#laplace.lllaplace.DiagLLLaplace.scatter">scatter</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Computes the <em>scatter</em>, a term of the log marginal likelihood that</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.log_det_prior_precision" href="#laplace.lllaplace.DiagLLLaplace.log_det_prior_precision">log_det_prior_precision</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute log determinant of the prior precision</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.log_det_ratio" href="#laplace.lllaplace.DiagLLLaplace.log_det_ratio">log_det_ratio</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute the log determinant ratio, a part of the log marginal likelihood.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.posterior_precision" href="#laplace.lllaplace.DiagLLLaplace.posterior_precision">posterior_precision</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Diagonal posterior precision <span class="arithmatex">\(p\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.posterior_scale" href="#laplace.lllaplace.DiagLLLaplace.posterior_scale">posterior_scale</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Diagonal posterior scale <span class="arithmatex">\(\sqrt{p^{-1}}\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.DiagLLLaplace.posterior_variance" href="#laplace.lllaplace.DiagLLLaplace.posterior_variance">posterior_variance</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Diagonal posterior variance <span class="arithmatex">\(p^{-1}\)</span>.</p>
          </div>
        </li>
    </ul>

                  <details class="quote">
                    <summary>Source code in <code>laplace/lllaplace.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>    <span class="n">likelihood</span><span class="p">:</span> <span class="n">Likelihood</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="n">sigma_noise</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>    <span class="n">prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="n">enable_backprop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="n">feature_reduction</span><span class="p">:</span> <span class="n">FeatureReduction</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="n">dict_key_x</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="n">dict_key_y</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="n">backend</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">CurvatureInterface</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="n">last_layer_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="n">backend_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="n">asdl_fisher_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="p">):</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="k">if</span> <span class="n">asdl_fisher_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Last-layer Laplace does not support asdl_fisher_kwargs.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">H</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>        <span class="n">model</span><span class="p">,</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>        <span class="n">likelihood</span><span class="p">,</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>        <span class="n">sigma_noise</span><span class="o">=</span><span class="n">sigma_noise</span><span class="p">,</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>        <span class="n">prior_precision</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>        <span class="n">prior_mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="n">enable_backprop</span><span class="o">=</span><span class="n">enable_backprop</span><span class="p">,</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="n">dict_key_x</span><span class="o">=</span><span class="n">dict_key_x</span><span class="p">,</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>        <span class="n">dict_key_y</span><span class="o">=</span><span class="n">dict_key_y</span><span class="p">,</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>        <span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="n">backend_kwargs</span><span class="o">=</span><span class="n">backend_kwargs</span><span class="p">,</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>    <span class="p">)</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">FeatureExtractor</span><span class="p">(</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>        <span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="n">last_layer_name</span><span class="o">=</span><span class="n">last_layer_name</span><span class="p">,</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="n">enable_backprop</span><span class="o">=</span><span class="n">enable_backprop</span><span class="p">,</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>        <span class="n">feature_reduction</span><span class="o">=</span><span class="n">feature_reduction</span><span class="p">,</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>    <span class="p">)</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>        <span class="c1"># ignore checks of prior mean setter temporarily, check on .fit()</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">prior_precision</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">prior_mean</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>            <span class="n">parameters_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">prior_precision</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">prior_mean</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_init_H</span><span class="p">()</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_backend_kwargs</span><span class="p">[</span><span class="s2">&quot;last_layer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_last_layer_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="n">last_layer_name</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.DiagLLLaplace.log_likelihood" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_likelihood</span>


<a href="#laplace.lllaplace.DiagLLLaplace.log_likelihood" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_likelihood</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute log likelihood on the training data after <code>.fit()</code> has been called.
The log likelihood is computed on-demand based on the loss and, for example,
the observation noise which makes it differentiable in the latter for
iterative updates.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_likelihood</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.DiagLLLaplace.prior_precision_diag" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">prior_precision_diag</span>


<a href="#laplace.lllaplace.DiagLLLaplace.prior_precision_diag" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">prior_precision_diag</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Obtain the diagonal prior precision <span class="arithmatex">\(p_0\)</span> constructed from either
a scalar or diagonal prior precision.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>prior_precision_diag</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.DiagLLLaplace.scatter" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">scatter</span>


<a href="#laplace.lllaplace.DiagLLLaplace.scatter" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">scatter</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the <em>scatter</em>, a term of the log marginal likelihood that
corresponds to L-2 regularization:
<code>scatter</code> = <span class="arithmatex">\((\theta_{MAP} - \mu_0)^{T} P_0 (\theta_{MAP} - \mu_0) \)</span>.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>scatter</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.DiagLLLaplace.log_det_prior_precision" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_det_prior_precision</span>


<a href="#laplace.lllaplace.DiagLLLaplace.log_det_prior_precision" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_det_prior_precision</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute log determinant of the prior precision
<span class="arithmatex">\(\log \det P_0\)</span></p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_det</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.DiagLLLaplace.log_det_ratio" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_det_ratio</span>


<a href="#laplace.lllaplace.DiagLLLaplace.log_det_ratio" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_det_ratio</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the log determinant ratio, a part of the log marginal likelihood.</p>
<div class="arithmatex">\[
    \log \frac{\det P}{\det P_0} = \log \det P - \log \det P_0
\]</div>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_det_ratio</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.DiagLLLaplace.posterior_precision" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">posterior_precision</span>


<a href="#laplace.lllaplace.DiagLLLaplace.posterior_precision" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">posterior_precision</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Diagonal posterior precision <span class="arithmatex">\(p\)</span>.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>precision</code></b> (              <code><span title="torch.tensor">tensor</span></code>
)          –
          <div class="doc-md-description">
            <p><code>(parameters)</code></p>
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.DiagLLLaplace.posterior_scale" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">posterior_scale</span>


<a href="#laplace.lllaplace.DiagLLLaplace.posterior_scale" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">posterior_scale</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Diagonal posterior scale <span class="arithmatex">\(\sqrt{p^{-1}}\)</span>.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>precision</code></b> (              <code><span title="torch.tensor">tensor</span></code>
)          –
          <div class="doc-md-description">
            <p><code>(parameters)</code></p>
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.DiagLLLaplace.posterior_variance" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">posterior_variance</span>


<a href="#laplace.lllaplace.DiagLLLaplace.posterior_variance" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">posterior_variance</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Diagonal posterior variance <span class="arithmatex">\(p^{-1}\)</span>.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>precision</code></b> (              <code><span title="torch.tensor">tensor</span></code>
)          –
          <div class="doc-md-description">
            <p><code>(parameters)</code></p>
          </div>
        </li>
    </ul>
    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.DiagLLLaplace.fit" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">fit</span>


<a href="#laplace.lllaplace.DiagLLLaplace.fit" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">fit</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.fit(train_loader)">train_loader</a></span><span class="p">:</span> <span class="n"><span title="torch.utils.data.DataLoader">DataLoader</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.fit(override)">override</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.fit(progress_bar)">progress_bar</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Fit the local Laplace approximation at the parameters of the model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.fit(train_loader)" class="doc doc-heading doc-heading-parameter">              <b><code>train_loader</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.fit(train_loader)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.data.utils.DataLoader">DataLoader</span></code>)
          –
          <div class="doc-md-description">
            <p>each iterate is a training batch, either <code>(X, y)</code> tensors or a dict-like
object containing keys as expressed by <code>self.dict_key_x</code> and
<code>self.dict_key_y</code>. <code>train_loader.dataset</code> needs to be set to access
<span class="arithmatex">\(N\)</span>, size of the data set.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.fit(override)" class="doc doc-heading doc-heading-parameter">              <b><code>override</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.fit(override)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>whether to initialize H, loss, and n_data again; setting to False is useful for
online learning settings to accumulate a sequential posterior approximation.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.fit(progress_bar)" class="doc doc-heading doc-heading-parameter">              <b><code>progress_bar</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.fit(progress_bar)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/lllaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>    <span class="n">progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Fit the local Laplace approximation at the parameters of the model.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">    train_loader : torch.data.utils.DataLoader</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">        each iterate is a training batch, either `(X, y)` tensors or a dict-like</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">        object containing keys as expressed by `self.dict_key_x` and</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">        `self.dict_key_y`. `train_loader.dataset` needs to be set to access</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a><span class="sd">        \\(N\\), size of the data set.</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a><span class="sd">    override : bool, default=True</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">        whether to initialize H, loss, and n_data again; setting to False is useful for</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a><span class="sd">        online learning settings to accumulate a sequential posterior approximation.</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">    progress_bar: bool, default=False</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">override</span><span class="p">:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>            <span class="s2">&quot;Last-layer Laplace approximations do not support `override=False`.&quot;</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="n">MutableMapping</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>            <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="p">)</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_find_last_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>        <span class="n">params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">parameters_to_vector</span><span class="p">(</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>        <span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>        <span class="c1"># here, check the already set prior precision again</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior_precision</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior_mean</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_init_H</span><span class="p">()</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="n">override</span><span class="p">)</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">parameters_to_vector</span><span class="p">(</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>    <span class="p">)</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_backprop</span><span class="p">:</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">log_marginal_likelihood</span>


<a href="#laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">log_marginal_likelihood</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood(prior_precision)">prior_precision</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood(sigma_noise)">sigma_noise</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the Laplace approximation to the log marginal likelihood subject
to specific Hessian approximations that subclasses implement.
Requires that the Laplace approximation has been fit before.
The resulting torch.Tensor is differentiable in <code>prior_precision</code> and
<code>sigma_noise</code> if these have gradients enabled.
By passing <code>prior_precision</code> or <code>sigma_noise</code>, the current value is
overwritten. This is useful for iterating on the log marginal likelihood.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood(prior_precision)" class="doc doc-heading doc-heading-parameter">              <b><code>prior_precision</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood(prior_precision)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>prior precision if should be changed from current <code>prior_precision</code> value</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood(sigma_noise)" class="doc doc-heading doc-heading-parameter">              <b><code>sigma_noise</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.log_marginal_likelihood(sigma_noise)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>observation noise standard deviation if should be changed</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_marglik</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1018">1018</a></span>
<span class="normal"><a href="#__codelineno-0-1019">1019</a></span>
<span class="normal"><a href="#__codelineno-0-1020">1020</a></span>
<span class="normal"><a href="#__codelineno-0-1021">1021</a></span>
<span class="normal"><a href="#__codelineno-0-1022">1022</a></span>
<span class="normal"><a href="#__codelineno-0-1023">1023</a></span>
<span class="normal"><a href="#__codelineno-0-1024">1024</a></span>
<span class="normal"><a href="#__codelineno-0-1025">1025</a></span>
<span class="normal"><a href="#__codelineno-0-1026">1026</a></span>
<span class="normal"><a href="#__codelineno-0-1027">1027</a></span>
<span class="normal"><a href="#__codelineno-0-1028">1028</a></span>
<span class="normal"><a href="#__codelineno-0-1029">1029</a></span>
<span class="normal"><a href="#__codelineno-0-1030">1030</a></span>
<span class="normal"><a href="#__codelineno-0-1031">1031</a></span>
<span class="normal"><a href="#__codelineno-0-1032">1032</a></span>
<span class="normal"><a href="#__codelineno-0-1033">1033</a></span>
<span class="normal"><a href="#__codelineno-0-1034">1034</a></span>
<span class="normal"><a href="#__codelineno-0-1035">1035</a></span>
<span class="normal"><a href="#__codelineno-0-1036">1036</a></span>
<span class="normal"><a href="#__codelineno-0-1037">1037</a></span>
<span class="normal"><a href="#__codelineno-0-1038">1038</a></span>
<span class="normal"><a href="#__codelineno-0-1039">1039</a></span>
<span class="normal"><a href="#__codelineno-0-1040">1040</a></span>
<span class="normal"><a href="#__codelineno-0-1041">1041</a></span>
<span class="normal"><a href="#__codelineno-0-1042">1042</a></span>
<span class="normal"><a href="#__codelineno-0-1043">1043</a></span>
<span class="normal"><a href="#__codelineno-0-1044">1044</a></span>
<span class="normal"><a href="#__codelineno-0-1045">1045</a></span>
<span class="normal"><a href="#__codelineno-0-1046">1046</a></span>
<span class="normal"><a href="#__codelineno-0-1047">1047</a></span>
<span class="normal"><a href="#__codelineno-0-1048">1048</a></span>
<span class="normal"><a href="#__codelineno-0-1049">1049</a></span>
<span class="normal"><a href="#__codelineno-0-1050">1050</a></span>
<span class="normal"><a href="#__codelineno-0-1051">1051</a></span>
<span class="normal"><a href="#__codelineno-0-1052">1052</a></span>
<span class="normal"><a href="#__codelineno-0-1053">1053</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1018" name="__codelineno-0-1018"></a><span class="k">def</span> <span class="nf">log_marginal_likelihood</span><span class="p">(</span>
<a id="__codelineno-0-1019" name="__codelineno-0-1019"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1020" name="__codelineno-0-1020"></a>    <span class="n">prior_precision</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1021" name="__codelineno-0-1021"></a>    <span class="n">sigma_noise</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1022" name="__codelineno-0-1022"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1023" name="__codelineno-0-1023"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the Laplace approximation to the log marginal likelihood subject</span>
<a id="__codelineno-0-1024" name="__codelineno-0-1024"></a><span class="sd">    to specific Hessian approximations that subclasses implement.</span>
<a id="__codelineno-0-1025" name="__codelineno-0-1025"></a><span class="sd">    Requires that the Laplace approximation has been fit before.</span>
<a id="__codelineno-0-1026" name="__codelineno-0-1026"></a><span class="sd">    The resulting torch.Tensor is differentiable in `prior_precision` and</span>
<a id="__codelineno-0-1027" name="__codelineno-0-1027"></a><span class="sd">    `sigma_noise` if these have gradients enabled.</span>
<a id="__codelineno-0-1028" name="__codelineno-0-1028"></a><span class="sd">    By passing `prior_precision` or `sigma_noise`, the current value is</span>
<a id="__codelineno-0-1029" name="__codelineno-0-1029"></a><span class="sd">    overwritten. This is useful for iterating on the log marginal likelihood.</span>
<a id="__codelineno-0-1030" name="__codelineno-0-1030"></a>
<a id="__codelineno-0-1031" name="__codelineno-0-1031"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1032" name="__codelineno-0-1032"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1033" name="__codelineno-0-1033"></a><span class="sd">    prior_precision : torch.Tensor, optional</span>
<a id="__codelineno-0-1034" name="__codelineno-0-1034"></a><span class="sd">        prior precision if should be changed from current `prior_precision` value</span>
<a id="__codelineno-0-1035" name="__codelineno-0-1035"></a><span class="sd">    sigma_noise : torch.Tensor, optional</span>
<a id="__codelineno-0-1036" name="__codelineno-0-1036"></a><span class="sd">        observation noise standard deviation if should be changed</span>
<a id="__codelineno-0-1037" name="__codelineno-0-1037"></a>
<a id="__codelineno-0-1038" name="__codelineno-0-1038"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1039" name="__codelineno-0-1039"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1040" name="__codelineno-0-1040"></a><span class="sd">    log_marglik : torch.Tensor</span>
<a id="__codelineno-0-1041" name="__codelineno-0-1041"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1042" name="__codelineno-0-1042"></a>    <span class="c1"># update prior precision (useful when iterating on marglik)</span>
<a id="__codelineno-0-1043" name="__codelineno-0-1043"></a>    <span class="k">if</span> <span class="n">prior_precision</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1044" name="__codelineno-0-1044"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_precision</span> <span class="o">=</span> <span class="n">prior_precision</span>
<a id="__codelineno-0-1045" name="__codelineno-0-1045"></a>
<a id="__codelineno-0-1046" name="__codelineno-0-1046"></a>    <span class="c1"># update sigma_noise (useful when iterating on marglik)</span>
<a id="__codelineno-0-1047" name="__codelineno-0-1047"></a>    <span class="k">if</span> <span class="n">sigma_noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1048" name="__codelineno-0-1048"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="o">!=</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-1049" name="__codelineno-0-1049"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Can only change sigma_noise for regression.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1050" name="__codelineno-0-1050"></a>
<a id="__codelineno-0-1051" name="__codelineno-0-1051"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_noise</span> <span class="o">=</span> <span class="n">sigma_noise</span>
<a id="__codelineno-0-1052" name="__codelineno-0-1052"></a>
<a id="__codelineno-0-1053" name="__codelineno-0-1053"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_det_ratio</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scatter</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.DiagLLLaplace.__call__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">__call__</span>


<a href="#laplace.lllaplace.DiagLLLaplace.__call__" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="fm">__call__</span><span class="p">(</span><span class="nf"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.__call__(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.__call__(pred_type)">pred_type</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType" href="../enums/#laplace.utils.enums.PredType">PredType</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType.GLM" href="../enums/#laplace.utils.enums.PredType.GLM">GLM</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.__call__(joint)">joint</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.__call__(link_approx)">link_approx</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox" href="../enums/#laplace.utils.enums.LinkApprox">LinkApprox</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox.PROBIT" href="../enums/#laplace.utils.enums.LinkApprox.PROBIT">PROBIT</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.__call__(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.__call__(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.__call__(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.__call__(fitting)">fitting</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">**model_kwargs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the posterior predictive on input data <code>x</code>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.__call__(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.__call__(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p><code>(batch_size, input_shape)</code> if tensor. If MutableMapping, must contain
the said tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.__call__(pred_type)" class="doc doc-heading doc-heading-parameter">              <b><code>pred_type</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.__call__(pred_type)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;glm&#39;, &#39;nn&#39;)</code>, default:
                  <code>&#39;glm&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>type of posterior predictive, linearized GLM predictive or neural
network sampling predictive. The GLM predictive is consistent with
the curvature approximations used here. When Laplace is done only
on subset of parameters (i.e. some grad are disabled),
only <code>nn</code> predictive is supported.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.__call__(link_approx)" class="doc doc-heading doc-heading-parameter">              <b><code>link_approx</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.__call__(link_approx)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;)</code>, default:
                  <code>&#39;mc&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>how to approximate the classification link function for the <code>'glm'</code>.
For <code>pred_type='nn'</code>, only 'mc' is possible.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.__call__(joint)" class="doc doc-heading doc-heading-parameter">              <b><code>joint</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.__call__(joint)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to output a joint predictive distribution in regression with
<code>pred_type='glm'</code>. If set to <code>True</code>, the predictive distribution
has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).
If <code>False</code>, then only outputs the marginal predictive distribution.
Only available for regression and GLM predictive.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.__call__(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.__call__(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples for <code>link_approx='mc'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.__call__(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.__call__(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized posterior predictive on the outputs.
Only works for <code>pred_type='glm'</code> when <code>joint=False</code> in regression.
In the case of last-layer Laplace with a diagonal or Kron Hessian,
setting this to <code>True</code> makes computation much(!) faster for large
number of outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.__call__(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.__call__(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.__call__(fitting)" class="doc doc-heading doc-heading-parameter">              <b><code>fitting</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.__call__(fitting)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether or not this predictive call is done during fitting. Only useful for
reward modeling: the likelihood is set to <code>"regression"</code> when <code>False</code> and
<code>"classification"</code> when <code>True</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>predictive</code></b> (              <code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<span title="torch.Tensor">Tensor</span>]</code>
)          –
          <div class="doc-md-description">
            <p>For <code>likelihood='classification'</code>, a torch.Tensor is returned with
a distribution over classes (similar to a Softmax).
For <code>likelihood='regression'</code>, a tuple of torch.Tensor is returned
with the mean and the predictive variance.
For <code>likelihood='regression'</code> and <code>joint=True</code>, a tuple of torch.Tensor
is returned with the mean and the predictive covariance.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1055">1055</a></span>
<span class="normal"><a href="#__codelineno-0-1056">1056</a></span>
<span class="normal"><a href="#__codelineno-0-1057">1057</a></span>
<span class="normal"><a href="#__codelineno-0-1058">1058</a></span>
<span class="normal"><a href="#__codelineno-0-1059">1059</a></span>
<span class="normal"><a href="#__codelineno-0-1060">1060</a></span>
<span class="normal"><a href="#__codelineno-0-1061">1061</a></span>
<span class="normal"><a href="#__codelineno-0-1062">1062</a></span>
<span class="normal"><a href="#__codelineno-0-1063">1063</a></span>
<span class="normal"><a href="#__codelineno-0-1064">1064</a></span>
<span class="normal"><a href="#__codelineno-0-1065">1065</a></span>
<span class="normal"><a href="#__codelineno-0-1066">1066</a></span>
<span class="normal"><a href="#__codelineno-0-1067">1067</a></span>
<span class="normal"><a href="#__codelineno-0-1068">1068</a></span>
<span class="normal"><a href="#__codelineno-0-1069">1069</a></span>
<span class="normal"><a href="#__codelineno-0-1070">1070</a></span>
<span class="normal"><a href="#__codelineno-0-1071">1071</a></span>
<span class="normal"><a href="#__codelineno-0-1072">1072</a></span>
<span class="normal"><a href="#__codelineno-0-1073">1073</a></span>
<span class="normal"><a href="#__codelineno-0-1074">1074</a></span>
<span class="normal"><a href="#__codelineno-0-1075">1075</a></span>
<span class="normal"><a href="#__codelineno-0-1076">1076</a></span>
<span class="normal"><a href="#__codelineno-0-1077">1077</a></span>
<span class="normal"><a href="#__codelineno-0-1078">1078</a></span>
<span class="normal"><a href="#__codelineno-0-1079">1079</a></span>
<span class="normal"><a href="#__codelineno-0-1080">1080</a></span>
<span class="normal"><a href="#__codelineno-0-1081">1081</a></span>
<span class="normal"><a href="#__codelineno-0-1082">1082</a></span>
<span class="normal"><a href="#__codelineno-0-1083">1083</a></span>
<span class="normal"><a href="#__codelineno-0-1084">1084</a></span>
<span class="normal"><a href="#__codelineno-0-1085">1085</a></span>
<span class="normal"><a href="#__codelineno-0-1086">1086</a></span>
<span class="normal"><a href="#__codelineno-0-1087">1087</a></span>
<span class="normal"><a href="#__codelineno-0-1088">1088</a></span>
<span class="normal"><a href="#__codelineno-0-1089">1089</a></span>
<span class="normal"><a href="#__codelineno-0-1090">1090</a></span>
<span class="normal"><a href="#__codelineno-0-1091">1091</a></span>
<span class="normal"><a href="#__codelineno-0-1092">1092</a></span>
<span class="normal"><a href="#__codelineno-0-1093">1093</a></span>
<span class="normal"><a href="#__codelineno-0-1094">1094</a></span>
<span class="normal"><a href="#__codelineno-0-1095">1095</a></span>
<span class="normal"><a href="#__codelineno-0-1096">1096</a></span>
<span class="normal"><a href="#__codelineno-0-1097">1097</a></span>
<span class="normal"><a href="#__codelineno-0-1098">1098</a></span>
<span class="normal"><a href="#__codelineno-0-1099">1099</a></span>
<span class="normal"><a href="#__codelineno-0-1100">1100</a></span>
<span class="normal"><a href="#__codelineno-0-1101">1101</a></span>
<span class="normal"><a href="#__codelineno-0-1102">1102</a></span>
<span class="normal"><a href="#__codelineno-0-1103">1103</a></span>
<span class="normal"><a href="#__codelineno-0-1104">1104</a></span>
<span class="normal"><a href="#__codelineno-0-1105">1105</a></span>
<span class="normal"><a href="#__codelineno-0-1106">1106</a></span>
<span class="normal"><a href="#__codelineno-0-1107">1107</a></span>
<span class="normal"><a href="#__codelineno-0-1108">1108</a></span>
<span class="normal"><a href="#__codelineno-0-1109">1109</a></span>
<span class="normal"><a href="#__codelineno-0-1110">1110</a></span>
<span class="normal"><a href="#__codelineno-0-1111">1111</a></span>
<span class="normal"><a href="#__codelineno-0-1112">1112</a></span>
<span class="normal"><a href="#__codelineno-0-1113">1113</a></span>
<span class="normal"><a href="#__codelineno-0-1114">1114</a></span>
<span class="normal"><a href="#__codelineno-0-1115">1115</a></span>
<span class="normal"><a href="#__codelineno-0-1116">1116</a></span>
<span class="normal"><a href="#__codelineno-0-1117">1117</a></span>
<span class="normal"><a href="#__codelineno-0-1118">1118</a></span>
<span class="normal"><a href="#__codelineno-0-1119">1119</a></span>
<span class="normal"><a href="#__codelineno-0-1120">1120</a></span>
<span class="normal"><a href="#__codelineno-0-1121">1121</a></span>
<span class="normal"><a href="#__codelineno-0-1122">1122</a></span>
<span class="normal"><a href="#__codelineno-0-1123">1123</a></span>
<span class="normal"><a href="#__codelineno-0-1124">1124</a></span>
<span class="normal"><a href="#__codelineno-0-1125">1125</a></span>
<span class="normal"><a href="#__codelineno-0-1126">1126</a></span>
<span class="normal"><a href="#__codelineno-0-1127">1127</a></span>
<span class="normal"><a href="#__codelineno-0-1128">1128</a></span>
<span class="normal"><a href="#__codelineno-0-1129">1129</a></span>
<span class="normal"><a href="#__codelineno-0-1130">1130</a></span>
<span class="normal"><a href="#__codelineno-0-1131">1131</a></span>
<span class="normal"><a href="#__codelineno-0-1132">1132</a></span>
<span class="normal"><a href="#__codelineno-0-1133">1133</a></span>
<span class="normal"><a href="#__codelineno-0-1134">1134</a></span>
<span class="normal"><a href="#__codelineno-0-1135">1135</a></span>
<span class="normal"><a href="#__codelineno-0-1136">1136</a></span>
<span class="normal"><a href="#__codelineno-0-1137">1137</a></span>
<span class="normal"><a href="#__codelineno-0-1138">1138</a></span>
<span class="normal"><a href="#__codelineno-0-1139">1139</a></span>
<span class="normal"><a href="#__codelineno-0-1140">1140</a></span>
<span class="normal"><a href="#__codelineno-0-1141">1141</a></span>
<span class="normal"><a href="#__codelineno-0-1142">1142</a></span>
<span class="normal"><a href="#__codelineno-0-1143">1143</a></span>
<span class="normal"><a href="#__codelineno-0-1144">1144</a></span>
<span class="normal"><a href="#__codelineno-0-1145">1145</a></span>
<span class="normal"><a href="#__codelineno-0-1146">1146</a></span>
<span class="normal"><a href="#__codelineno-0-1147">1147</a></span>
<span class="normal"><a href="#__codelineno-0-1148">1148</a></span>
<span class="normal"><a href="#__codelineno-0-1149">1149</a></span>
<span class="normal"><a href="#__codelineno-0-1150">1150</a></span>
<span class="normal"><a href="#__codelineno-0-1151">1151</a></span>
<span class="normal"><a href="#__codelineno-0-1152">1152</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1055" name="__codelineno-0-1055"></a><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
<a id="__codelineno-0-1056" name="__codelineno-0-1056"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1057" name="__codelineno-0-1057"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1058" name="__codelineno-0-1058"></a>    <span class="n">pred_type</span><span class="p">:</span> <span class="n">PredType</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">,</span>
<a id="__codelineno-0-1059" name="__codelineno-0-1059"></a>    <span class="n">joint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1060" name="__codelineno-0-1060"></a>    <span class="n">link_approx</span><span class="p">:</span> <span class="n">LinkApprox</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">PROBIT</span><span class="p">,</span>
<a id="__codelineno-0-1061" name="__codelineno-0-1061"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-1062" name="__codelineno-0-1062"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1063" name="__codelineno-0-1063"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1064" name="__codelineno-0-1064"></a>    <span class="n">fitting</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1065" name="__codelineno-0-1065"></a>    <span class="o">**</span><span class="n">model_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1066" name="__codelineno-0-1066"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-1067" name="__codelineno-0-1067"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the posterior predictive on input data `x`.</span>
<a id="__codelineno-0-1068" name="__codelineno-0-1068"></a>
<a id="__codelineno-0-1069" name="__codelineno-0-1069"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1070" name="__codelineno-0-1070"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1071" name="__codelineno-0-1071"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-1072" name="__codelineno-0-1072"></a><span class="sd">        `(batch_size, input_shape)` if tensor. If MutableMapping, must contain</span>
<a id="__codelineno-0-1073" name="__codelineno-0-1073"></a><span class="sd">        the said tensor.</span>
<a id="__codelineno-0-1074" name="__codelineno-0-1074"></a>
<a id="__codelineno-0-1075" name="__codelineno-0-1075"></a><span class="sd">    pred_type : {&#39;glm&#39;, &#39;nn&#39;}, default=&#39;glm&#39;</span>
<a id="__codelineno-0-1076" name="__codelineno-0-1076"></a><span class="sd">        type of posterior predictive, linearized GLM predictive or neural</span>
<a id="__codelineno-0-1077" name="__codelineno-0-1077"></a><span class="sd">        network sampling predictive. The GLM predictive is consistent with</span>
<a id="__codelineno-0-1078" name="__codelineno-0-1078"></a><span class="sd">        the curvature approximations used here. When Laplace is done only</span>
<a id="__codelineno-0-1079" name="__codelineno-0-1079"></a><span class="sd">        on subset of parameters (i.e. some grad are disabled),</span>
<a id="__codelineno-0-1080" name="__codelineno-0-1080"></a><span class="sd">        only `nn` predictive is supported.</span>
<a id="__codelineno-0-1081" name="__codelineno-0-1081"></a>
<a id="__codelineno-0-1082" name="__codelineno-0-1082"></a><span class="sd">    link_approx : {&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;}</span>
<a id="__codelineno-0-1083" name="__codelineno-0-1083"></a><span class="sd">        how to approximate the classification link function for the `&#39;glm&#39;`.</span>
<a id="__codelineno-0-1084" name="__codelineno-0-1084"></a><span class="sd">        For `pred_type=&#39;nn&#39;`, only &#39;mc&#39; is possible.</span>
<a id="__codelineno-0-1085" name="__codelineno-0-1085"></a>
<a id="__codelineno-0-1086" name="__codelineno-0-1086"></a><span class="sd">    joint : bool</span>
<a id="__codelineno-0-1087" name="__codelineno-0-1087"></a><span class="sd">        Whether to output a joint predictive distribution in regression with</span>
<a id="__codelineno-0-1088" name="__codelineno-0-1088"></a><span class="sd">        `pred_type=&#39;glm&#39;`. If set to `True`, the predictive distribution</span>
<a id="__codelineno-0-1089" name="__codelineno-0-1089"></a><span class="sd">        has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).</span>
<a id="__codelineno-0-1090" name="__codelineno-0-1090"></a><span class="sd">        If `False`, then only outputs the marginal predictive distribution.</span>
<a id="__codelineno-0-1091" name="__codelineno-0-1091"></a><span class="sd">        Only available for regression and GLM predictive.</span>
<a id="__codelineno-0-1092" name="__codelineno-0-1092"></a>
<a id="__codelineno-0-1093" name="__codelineno-0-1093"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-1094" name="__codelineno-0-1094"></a><span class="sd">        number of samples for `link_approx=&#39;mc&#39;`.</span>
<a id="__codelineno-0-1095" name="__codelineno-0-1095"></a>
<a id="__codelineno-0-1096" name="__codelineno-0-1096"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-1097" name="__codelineno-0-1097"></a><span class="sd">        whether to use a diagonalized posterior predictive on the outputs.</span>
<a id="__codelineno-0-1098" name="__codelineno-0-1098"></a><span class="sd">        Only works for `pred_type=&#39;glm&#39;` when `joint=False` in regression.</span>
<a id="__codelineno-0-1099" name="__codelineno-0-1099"></a><span class="sd">        In the case of last-layer Laplace with a diagonal or Kron Hessian,</span>
<a id="__codelineno-0-1100" name="__codelineno-0-1100"></a><span class="sd">        setting this to `True` makes computation much(!) faster for large</span>
<a id="__codelineno-0-1101" name="__codelineno-0-1101"></a><span class="sd">        number of outputs.</span>
<a id="__codelineno-0-1102" name="__codelineno-0-1102"></a>
<a id="__codelineno-0-1103" name="__codelineno-0-1103"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1104" name="__codelineno-0-1104"></a><span class="sd">        random number generator to control the samples (if sampling used).</span>
<a id="__codelineno-0-1105" name="__codelineno-0-1105"></a>
<a id="__codelineno-0-1106" name="__codelineno-0-1106"></a><span class="sd">    fitting : bool, default=False</span>
<a id="__codelineno-0-1107" name="__codelineno-0-1107"></a><span class="sd">        whether or not this predictive call is done during fitting. Only useful for</span>
<a id="__codelineno-0-1108" name="__codelineno-0-1108"></a><span class="sd">        reward modeling: the likelihood is set to `&quot;regression&quot;` when `False` and</span>
<a id="__codelineno-0-1109" name="__codelineno-0-1109"></a><span class="sd">        `&quot;classification&quot;` when `True`.</span>
<a id="__codelineno-0-1110" name="__codelineno-0-1110"></a>
<a id="__codelineno-0-1111" name="__codelineno-0-1111"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1112" name="__codelineno-0-1112"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1113" name="__codelineno-0-1113"></a><span class="sd">    predictive: torch.Tensor or tuple[torch.Tensor]</span>
<a id="__codelineno-0-1114" name="__codelineno-0-1114"></a><span class="sd">        For `likelihood=&#39;classification&#39;`, a torch.Tensor is returned with</span>
<a id="__codelineno-0-1115" name="__codelineno-0-1115"></a><span class="sd">        a distribution over classes (similar to a Softmax).</span>
<a id="__codelineno-0-1116" name="__codelineno-0-1116"></a><span class="sd">        For `likelihood=&#39;regression&#39;`, a tuple of torch.Tensor is returned</span>
<a id="__codelineno-0-1117" name="__codelineno-0-1117"></a><span class="sd">        with the mean and the predictive variance.</span>
<a id="__codelineno-0-1118" name="__codelineno-0-1118"></a><span class="sd">        For `likelihood=&#39;regression&#39;` and `joint=True`, a tuple of torch.Tensor</span>
<a id="__codelineno-0-1119" name="__codelineno-0-1119"></a><span class="sd">        is returned with the mean and the predictive covariance.</span>
<a id="__codelineno-0-1120" name="__codelineno-0-1120"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1121" name="__codelineno-0-1121"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">pred</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">PredType</span><span class="p">]:</span>
<a id="__codelineno-0-1122" name="__codelineno-0-1122"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only glm and nn supported as prediction types.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1123" name="__codelineno-0-1123"></a>
<a id="__codelineno-0-1124" name="__codelineno-0-1124"></a>    <span class="k">if</span> <span class="n">link_approx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">la</span> <span class="k">for</span> <span class="n">la</span> <span class="ow">in</span> <span class="n">LinkApprox</span><span class="p">]:</span>
<a id="__codelineno-0-1125" name="__codelineno-0-1125"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported link approximation </span><span class="si">{</span><span class="n">link_approx</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1126" name="__codelineno-0-1126"></a>
<a id="__codelineno-0-1127" name="__codelineno-0-1127"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">NN</span> <span class="ow">and</span> <span class="n">link_approx</span> <span class="o">!=</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">MC</span><span class="p">:</span>
<a id="__codelineno-0-1128" name="__codelineno-0-1128"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-1129" name="__codelineno-0-1129"></a>            <span class="s2">&quot;Only mc link approximation is supported for nn prediction type.&quot;</span>
<a id="__codelineno-0-1130" name="__codelineno-0-1130"></a>        <span class="p">)</span>
<a id="__codelineno-0-1131" name="__codelineno-0-1131"></a>
<a id="__codelineno-0-1132" name="__codelineno-0-1132"></a>    <span class="k">if</span> <span class="n">generator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1133" name="__codelineno-0-1133"></a>        <span class="k">if</span> <span class="p">(</span>
<a id="__codelineno-0-1134" name="__codelineno-0-1134"></a>            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">)</span>
<a id="__codelineno-0-1135" name="__codelineno-0-1135"></a>            <span class="ow">or</span> <span class="n">generator</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>
<a id="__codelineno-0-1136" name="__codelineno-0-1136"></a>        <span class="p">):</span>
<a id="__codelineno-0-1137" name="__codelineno-0-1137"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid random generator (check type and device).&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1138" name="__codelineno-0-1138"></a>
<a id="__codelineno-0-1139" name="__codelineno-0-1139"></a>    <span class="n">likelihood</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span>
<a id="__codelineno-0-1140" name="__codelineno-0-1140"></a>    <span class="k">if</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REWARD_MODELING</span><span class="p">:</span>
<a id="__codelineno-0-1141" name="__codelineno-0-1141"></a>        <span class="n">likelihood</span> <span class="o">=</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">CLASSIFICATION</span> <span class="k">if</span> <span class="n">fitting</span> <span class="k">else</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span>
<a id="__codelineno-0-1142" name="__codelineno-0-1142"></a>
<a id="__codelineno-0-1143" name="__codelineno-0-1143"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">:</span>
<a id="__codelineno-0-1144" name="__codelineno-0-1144"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_forward_call</span><span class="p">(</span>
<a id="__codelineno-0-1145" name="__codelineno-0-1145"></a>            <span class="n">x</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">joint</span><span class="p">,</span> <span class="n">link_approx</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span>
<a id="__codelineno-0-1146" name="__codelineno-0-1146"></a>        <span class="p">)</span>
<a id="__codelineno-0-1147" name="__codelineno-0-1147"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1148" name="__codelineno-0-1148"></a>        <span class="k">if</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-1149" name="__codelineno-0-1149"></a>            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_predictive_samples</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
<a id="__codelineno-0-1150" name="__codelineno-0-1150"></a>            <span class="k">return</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">samples</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-1151" name="__codelineno-0-1151"></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># classification; the average is computed online</span>
<a id="__codelineno-0-1152" name="__codelineno-0-1152"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_predictive_classification</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.DiagLLLaplace._glm_forward_call" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">_glm_forward_call</span>


<a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">_glm_forward_call</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(likelihood)">likelihood</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(joint)">joint</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(link_approx)">link_approx</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox" href="../enums/#laplace.utils.enums.LinkApprox">LinkApprox</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox.PROBIT" href="../enums/#laplace.utils.enums.LinkApprox.PROBIT">PROBIT</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the posterior predictive on input data <code>x</code> for "glm" pred type.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_forward_call(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p><code>(batch_size, input_shape)</code> if tensor. If MutableMapping, must contain
the said tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_forward_call(likelihood)" class="doc doc-heading doc-heading-parameter">              <b><code>likelihood</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(likelihood)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a> in {&#39;classification&#39;, &#39;regression&#39;, &#39;reward_modeling&#39;}</code>)
          –
          <div class="doc-md-description">
            <p>determines the log likelihood Hessian approximation.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_forward_call(link_approx)" class="doc doc-heading doc-heading-parameter">              <b><code>link_approx</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(link_approx)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;)</code>, default:
                  <code>&#39;mc&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>how to approximate the classification link function for the <code>'glm'</code>.
For <code>pred_type='nn'</code>, only 'mc' is possible.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_forward_call(joint)" class="doc doc-heading doc-heading-parameter">              <b><code>joint</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(joint)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to output a joint predictive distribution in regression with
<code>pred_type='glm'</code>. If set to <code>True</code>, the predictive distribution
has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).
If <code>False</code>, then only outputs the marginal predictive distribution.
Only available for regression and GLM predictive.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_forward_call(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples for <code>link_approx='mc'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_forward_call(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_forward_call(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized posterior predictive on the outputs.
Only works for <code>pred_type='glm'</code> and <code>link_approx='mc'</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>predictive</code></b> (              <code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<span title="torch.Tensor">Tensor</span>]</code>
)          –
          <div class="doc-md-description">
            <p>For <code>likelihood='classification'</code>, a torch.Tensor is returned with
a distribution over classes (similar to a Softmax).
For <code>likelihood='regression'</code>, a tuple of torch.Tensor is returned
with the mean and the predictive variance.
For <code>likelihood='regression'</code> and <code>joint=True</code>, a tuple of torch.Tensor
is returned with the mean and the predictive covariance.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-598">598</a></span>
<span class="normal"><a href="#__codelineno-0-599">599</a></span>
<span class="normal"><a href="#__codelineno-0-600">600</a></span>
<span class="normal"><a href="#__codelineno-0-601">601</a></span>
<span class="normal"><a href="#__codelineno-0-602">602</a></span>
<span class="normal"><a href="#__codelineno-0-603">603</a></span>
<span class="normal"><a href="#__codelineno-0-604">604</a></span>
<span class="normal"><a href="#__codelineno-0-605">605</a></span>
<span class="normal"><a href="#__codelineno-0-606">606</a></span>
<span class="normal"><a href="#__codelineno-0-607">607</a></span>
<span class="normal"><a href="#__codelineno-0-608">608</a></span>
<span class="normal"><a href="#__codelineno-0-609">609</a></span>
<span class="normal"><a href="#__codelineno-0-610">610</a></span>
<span class="normal"><a href="#__codelineno-0-611">611</a></span>
<span class="normal"><a href="#__codelineno-0-612">612</a></span>
<span class="normal"><a href="#__codelineno-0-613">613</a></span>
<span class="normal"><a href="#__codelineno-0-614">614</a></span>
<span class="normal"><a href="#__codelineno-0-615">615</a></span>
<span class="normal"><a href="#__codelineno-0-616">616</a></span>
<span class="normal"><a href="#__codelineno-0-617">617</a></span>
<span class="normal"><a href="#__codelineno-0-618">618</a></span>
<span class="normal"><a href="#__codelineno-0-619">619</a></span>
<span class="normal"><a href="#__codelineno-0-620">620</a></span>
<span class="normal"><a href="#__codelineno-0-621">621</a></span>
<span class="normal"><a href="#__codelineno-0-622">622</a></span>
<span class="normal"><a href="#__codelineno-0-623">623</a></span>
<span class="normal"><a href="#__codelineno-0-624">624</a></span>
<span class="normal"><a href="#__codelineno-0-625">625</a></span>
<span class="normal"><a href="#__codelineno-0-626">626</a></span>
<span class="normal"><a href="#__codelineno-0-627">627</a></span>
<span class="normal"><a href="#__codelineno-0-628">628</a></span>
<span class="normal"><a href="#__codelineno-0-629">629</a></span>
<span class="normal"><a href="#__codelineno-0-630">630</a></span>
<span class="normal"><a href="#__codelineno-0-631">631</a></span>
<span class="normal"><a href="#__codelineno-0-632">632</a></span>
<span class="normal"><a href="#__codelineno-0-633">633</a></span>
<span class="normal"><a href="#__codelineno-0-634">634</a></span>
<span class="normal"><a href="#__codelineno-0-635">635</a></span>
<span class="normal"><a href="#__codelineno-0-636">636</a></span>
<span class="normal"><a href="#__codelineno-0-637">637</a></span>
<span class="normal"><a href="#__codelineno-0-638">638</a></span>
<span class="normal"><a href="#__codelineno-0-639">639</a></span>
<span class="normal"><a href="#__codelineno-0-640">640</a></span>
<span class="normal"><a href="#__codelineno-0-641">641</a></span>
<span class="normal"><a href="#__codelineno-0-642">642</a></span>
<span class="normal"><a href="#__codelineno-0-643">643</a></span>
<span class="normal"><a href="#__codelineno-0-644">644</a></span>
<span class="normal"><a href="#__codelineno-0-645">645</a></span>
<span class="normal"><a href="#__codelineno-0-646">646</a></span>
<span class="normal"><a href="#__codelineno-0-647">647</a></span>
<span class="normal"><a href="#__codelineno-0-648">648</a></span>
<span class="normal"><a href="#__codelineno-0-649">649</a></span>
<span class="normal"><a href="#__codelineno-0-650">650</a></span>
<span class="normal"><a href="#__codelineno-0-651">651</a></span>
<span class="normal"><a href="#__codelineno-0-652">652</a></span>
<span class="normal"><a href="#__codelineno-0-653">653</a></span>
<span class="normal"><a href="#__codelineno-0-654">654</a></span>
<span class="normal"><a href="#__codelineno-0-655">655</a></span>
<span class="normal"><a href="#__codelineno-0-656">656</a></span>
<span class="normal"><a href="#__codelineno-0-657">657</a></span>
<span class="normal"><a href="#__codelineno-0-658">658</a></span>
<span class="normal"><a href="#__codelineno-0-659">659</a></span>
<span class="normal"><a href="#__codelineno-0-660">660</a></span>
<span class="normal"><a href="#__codelineno-0-661">661</a></span>
<span class="normal"><a href="#__codelineno-0-662">662</a></span>
<span class="normal"><a href="#__codelineno-0-663">663</a></span>
<span class="normal"><a href="#__codelineno-0-664">664</a></span>
<span class="normal"><a href="#__codelineno-0-665">665</a></span>
<span class="normal"><a href="#__codelineno-0-666">666</a></span>
<span class="normal"><a href="#__codelineno-0-667">667</a></span>
<span class="normal"><a href="#__codelineno-0-668">668</a></span>
<span class="normal"><a href="#__codelineno-0-669">669</a></span>
<span class="normal"><a href="#__codelineno-0-670">670</a></span>
<span class="normal"><a href="#__codelineno-0-671">671</a></span>
<span class="normal"><a href="#__codelineno-0-672">672</a></span>
<span class="normal"><a href="#__codelineno-0-673">673</a></span>
<span class="normal"><a href="#__codelineno-0-674">674</a></span>
<span class="normal"><a href="#__codelineno-0-675">675</a></span>
<span class="normal"><a href="#__codelineno-0-676">676</a></span>
<span class="normal"><a href="#__codelineno-0-677">677</a></span>
<span class="normal"><a href="#__codelineno-0-678">678</a></span>
<span class="normal"><a href="#__codelineno-0-679">679</a></span>
<span class="normal"><a href="#__codelineno-0-680">680</a></span>
<span class="normal"><a href="#__codelineno-0-681">681</a></span>
<span class="normal"><a href="#__codelineno-0-682">682</a></span>
<span class="normal"><a href="#__codelineno-0-683">683</a></span>
<span class="normal"><a href="#__codelineno-0-684">684</a></span>
<span class="normal"><a href="#__codelineno-0-685">685</a></span>
<span class="normal"><a href="#__codelineno-0-686">686</a></span>
<span class="normal"><a href="#__codelineno-0-687">687</a></span>
<span class="normal"><a href="#__codelineno-0-688">688</a></span>
<span class="normal"><a href="#__codelineno-0-689">689</a></span>
<span class="normal"><a href="#__codelineno-0-690">690</a></span>
<span class="normal"><a href="#__codelineno-0-691">691</a></span>
<span class="normal"><a href="#__codelineno-0-692">692</a></span>
<span class="normal"><a href="#__codelineno-0-693">693</a></span>
<span class="normal"><a href="#__codelineno-0-694">694</a></span>
<span class="normal"><a href="#__codelineno-0-695">695</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-598" name="__codelineno-0-598"></a><span class="k">def</span> <span class="nf">_glm_forward_call</span><span class="p">(</span>
<a id="__codelineno-0-599" name="__codelineno-0-599"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-600" name="__codelineno-0-600"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">,</span>
<a id="__codelineno-0-601" name="__codelineno-0-601"></a>    <span class="n">likelihood</span><span class="p">:</span> <span class="n">Likelihood</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-602" name="__codelineno-0-602"></a>    <span class="n">joint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-603" name="__codelineno-0-603"></a>    <span class="n">link_approx</span><span class="p">:</span> <span class="n">LinkApprox</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">PROBIT</span><span class="p">,</span>
<a id="__codelineno-0-604" name="__codelineno-0-604"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-605" name="__codelineno-0-605"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-606" name="__codelineno-0-606"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-607" name="__codelineno-0-607"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the posterior predictive on input data `x` for &quot;glm&quot; pred type.</span>
<a id="__codelineno-0-608" name="__codelineno-0-608"></a>
<a id="__codelineno-0-609" name="__codelineno-0-609"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-610" name="__codelineno-0-610"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-611" name="__codelineno-0-611"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-612" name="__codelineno-0-612"></a><span class="sd">        `(batch_size, input_shape)` if tensor. If MutableMapping, must contain</span>
<a id="__codelineno-0-613" name="__codelineno-0-613"></a><span class="sd">        the said tensor.</span>
<a id="__codelineno-0-614" name="__codelineno-0-614"></a>
<a id="__codelineno-0-615" name="__codelineno-0-615"></a><span class="sd">    likelihood : Likelihood or str in {&#39;classification&#39;, &#39;regression&#39;, &#39;reward_modeling&#39;}</span>
<a id="__codelineno-0-616" name="__codelineno-0-616"></a><span class="sd">        determines the log likelihood Hessian approximation.</span>
<a id="__codelineno-0-617" name="__codelineno-0-617"></a>
<a id="__codelineno-0-618" name="__codelineno-0-618"></a><span class="sd">    link_approx : {&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;}</span>
<a id="__codelineno-0-619" name="__codelineno-0-619"></a><span class="sd">        how to approximate the classification link function for the `&#39;glm&#39;`.</span>
<a id="__codelineno-0-620" name="__codelineno-0-620"></a><span class="sd">        For `pred_type=&#39;nn&#39;`, only &#39;mc&#39; is possible.</span>
<a id="__codelineno-0-621" name="__codelineno-0-621"></a>
<a id="__codelineno-0-622" name="__codelineno-0-622"></a><span class="sd">    joint : bool</span>
<a id="__codelineno-0-623" name="__codelineno-0-623"></a><span class="sd">        Whether to output a joint predictive distribution in regression with</span>
<a id="__codelineno-0-624" name="__codelineno-0-624"></a><span class="sd">        `pred_type=&#39;glm&#39;`. If set to `True`, the predictive distribution</span>
<a id="__codelineno-0-625" name="__codelineno-0-625"></a><span class="sd">        has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).</span>
<a id="__codelineno-0-626" name="__codelineno-0-626"></a><span class="sd">        If `False`, then only outputs the marginal predictive distribution.</span>
<a id="__codelineno-0-627" name="__codelineno-0-627"></a><span class="sd">        Only available for regression and GLM predictive.</span>
<a id="__codelineno-0-628" name="__codelineno-0-628"></a>
<a id="__codelineno-0-629" name="__codelineno-0-629"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-630" name="__codelineno-0-630"></a><span class="sd">        number of samples for `link_approx=&#39;mc&#39;`.</span>
<a id="__codelineno-0-631" name="__codelineno-0-631"></a>
<a id="__codelineno-0-632" name="__codelineno-0-632"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-633" name="__codelineno-0-633"></a><span class="sd">        whether to use a diagonalized posterior predictive on the outputs.</span>
<a id="__codelineno-0-634" name="__codelineno-0-634"></a><span class="sd">        Only works for `pred_type=&#39;glm&#39;` and `link_approx=&#39;mc&#39;`.</span>
<a id="__codelineno-0-635" name="__codelineno-0-635"></a>
<a id="__codelineno-0-636" name="__codelineno-0-636"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-637" name="__codelineno-0-637"></a><span class="sd">    -------</span>
<a id="__codelineno-0-638" name="__codelineno-0-638"></a><span class="sd">    predictive: torch.Tensor or tuple[torch.Tensor]</span>
<a id="__codelineno-0-639" name="__codelineno-0-639"></a><span class="sd">        For `likelihood=&#39;classification&#39;`, a torch.Tensor is returned with</span>
<a id="__codelineno-0-640" name="__codelineno-0-640"></a><span class="sd">        a distribution over classes (similar to a Softmax).</span>
<a id="__codelineno-0-641" name="__codelineno-0-641"></a><span class="sd">        For `likelihood=&#39;regression&#39;`, a tuple of torch.Tensor is returned</span>
<a id="__codelineno-0-642" name="__codelineno-0-642"></a><span class="sd">        with the mean and the predictive variance.</span>
<a id="__codelineno-0-643" name="__codelineno-0-643"></a><span class="sd">        For `likelihood=&#39;regression&#39;` and `joint=True`, a tuple of torch.Tensor</span>
<a id="__codelineno-0-644" name="__codelineno-0-644"></a><span class="sd">        is returned with the mean and the predictive covariance.</span>
<a id="__codelineno-0-645" name="__codelineno-0-645"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-646" name="__codelineno-0-646"></a>    <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_distribution</span><span class="p">(</span>
<a id="__codelineno-0-647" name="__codelineno-0-647"></a>        <span class="n">x</span><span class="p">,</span> <span class="n">joint</span><span class="o">=</span><span class="n">joint</span> <span class="ow">and</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span>
<a id="__codelineno-0-648" name="__codelineno-0-648"></a>    <span class="p">)</span>
<a id="__codelineno-0-649" name="__codelineno-0-649"></a>
<a id="__codelineno-0-650" name="__codelineno-0-650"></a>    <span class="k">if</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-651" name="__codelineno-0-651"></a>        <span class="k">if</span> <span class="n">diagonal_output</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">joint</span><span class="p">:</span>
<a id="__codelineno-0-652" name="__codelineno-0-652"></a>            <span class="n">f_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_var</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-653" name="__codelineno-0-653"></a>        <span class="k">return</span> <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span>
<a id="__codelineno-0-654" name="__codelineno-0-654"></a>
<a id="__codelineno-0-655" name="__codelineno-0-655"></a>    <span class="k">if</span> <span class="n">link_approx</span> <span class="o">==</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">MC</span><span class="p">:</span>
<a id="__codelineno-0-656" name="__codelineno-0-656"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-657" name="__codelineno-0-657"></a>            <span class="n">f_mu</span><span class="p">,</span>
<a id="__codelineno-0-658" name="__codelineno-0-658"></a>            <span class="n">f_var</span><span class="p">,</span>
<a id="__codelineno-0-659" name="__codelineno-0-659"></a>            <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span>
<a id="__codelineno-0-660" name="__codelineno-0-660"></a>            <span class="n">diagonal_output</span><span class="o">=</span><span class="n">diagonal_output</span><span class="p">,</span>
<a id="__codelineno-0-661" name="__codelineno-0-661"></a>        <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-662" name="__codelineno-0-662"></a>    <span class="k">elif</span> <span class="n">link_approx</span> <span class="o">==</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">PROBIT</span><span class="p">:</span>
<a id="__codelineno-0-663" name="__codelineno-0-663"></a>        <span class="n">kappa</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">8</span> <span class="o">*</span> <span class="n">f_var</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<a id="__codelineno-0-664" name="__codelineno-0-664"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">kappa</span> <span class="o">*</span> <span class="n">f_mu</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-665" name="__codelineno-0-665"></a>    <span class="k">elif</span> <span class="s2">&quot;bridge&quot;</span> <span class="ow">in</span> <span class="n">link_approx</span><span class="p">:</span>
<a id="__codelineno-0-666" name="__codelineno-0-666"></a>        <span class="c1"># zero mean correction</span>
<a id="__codelineno-0-667" name="__codelineno-0-667"></a>        <span class="n">f_mu</span> <span class="o">-=</span> <span class="p">(</span>
<a id="__codelineno-0-668" name="__codelineno-0-668"></a>            <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-669" name="__codelineno-0-669"></a>            <span class="o">*</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-670" name="__codelineno-0-670"></a>            <span class="o">/</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-671" name="__codelineno-0-671"></a>        <span class="p">)</span>
<a id="__codelineno-0-672" name="__codelineno-0-672"></a>        <span class="n">f_var</span> <span class="o">-=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
<a id="__codelineno-0-673" name="__codelineno-0-673"></a>            <span class="s2">&quot;bi,bj-&gt;bij&quot;</span><span class="p">,</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-674" name="__codelineno-0-674"></a>        <span class="p">)</span> <span class="o">/</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-675" name="__codelineno-0-675"></a>
<a id="__codelineno-0-676" name="__codelineno-0-676"></a>        <span class="c1"># Laplace Bridge</span>
<a id="__codelineno-0-677" name="__codelineno-0-677"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-678" name="__codelineno-0-678"></a>        <span class="n">f_var_diag</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_var</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-679" name="__codelineno-0-679"></a>
<a id="__codelineno-0-680" name="__codelineno-0-680"></a>        <span class="c1"># optional: variance correction</span>
<a id="__codelineno-0-681" name="__codelineno-0-681"></a>        <span class="k">if</span> <span class="n">link_approx</span> <span class="o">==</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">BRIDGE_NORM</span><span class="p">:</span>
<a id="__codelineno-0-682" name="__codelineno-0-682"></a>            <span class="n">f_var_diag_mean</span> <span class="o">=</span> <span class="n">f_var_diag</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-683" name="__codelineno-0-683"></a>            <span class="n">f_var_diag_mean</span> <span class="o">/=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span>
<a id="__codelineno-0-684" name="__codelineno-0-684"></a>                <span class="p">[</span><span class="n">K</span> <span class="o">/</span> <span class="mi">2</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>
<a id="__codelineno-0-685" name="__codelineno-0-685"></a>            <span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
<a id="__codelineno-0-686" name="__codelineno-0-686"></a>            <span class="n">f_mu</span> <span class="o">/=</span> <span class="n">f_var_diag_mean</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-687" name="__codelineno-0-687"></a>            <span class="n">f_var_diag</span> <span class="o">/=</span> <span class="n">f_var_diag_mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-688" name="__codelineno-0-688"></a>
<a id="__codelineno-0-689" name="__codelineno-0-689"></a>        <span class="n">sum_exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">f_mu</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-690" name="__codelineno-0-690"></a>        <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">K</span> <span class="o">+</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">/</span> <span class="n">K</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sum_exp</span><span class="p">)</span> <span class="o">/</span> <span class="n">f_var_diag</span>
<a id="__codelineno-0-691" name="__codelineno-0-691"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">alpha</span> <span class="o">/</span> <span class="n">alpha</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">nan</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<a id="__codelineno-0-692" name="__codelineno-0-692"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-693" name="__codelineno-0-693"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-694" name="__codelineno-0-694"></a>            <span class="s2">&quot;Prediction path invalid. Check the likelihood, pred_type, link_approx combination!&quot;</span>
<a id="__codelineno-0-695" name="__codelineno-0-695"></a>        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.DiagLLLaplace._glm_functional_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">_glm_functional_samples</span>


<a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">_glm_functional_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(f_mu)">f_mu</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(f_var)">f_var</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the posterior functional on input data <code>x</code> using "glm" prediction
type.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_functional_samples(f_mu)" class="doc doc-heading doc-heading-parameter">              <b><code>f_mu</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(f_mu)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive mean <code>(batch_size, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_functional_samples(f_var)" class="doc doc-heading doc-heading-parameter">              <b><code>f_var</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(f_var)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive covariances <code>(batch_size, output_shape, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_functional_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_functional_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_functional_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_functional_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-697">697</a></span>
<span class="normal"><a href="#__codelineno-0-698">698</a></span>
<span class="normal"><a href="#__codelineno-0-699">699</a></span>
<span class="normal"><a href="#__codelineno-0-700">700</a></span>
<span class="normal"><a href="#__codelineno-0-701">701</a></span>
<span class="normal"><a href="#__codelineno-0-702">702</a></span>
<span class="normal"><a href="#__codelineno-0-703">703</a></span>
<span class="normal"><a href="#__codelineno-0-704">704</a></span>
<span class="normal"><a href="#__codelineno-0-705">705</a></span>
<span class="normal"><a href="#__codelineno-0-706">706</a></span>
<span class="normal"><a href="#__codelineno-0-707">707</a></span>
<span class="normal"><a href="#__codelineno-0-708">708</a></span>
<span class="normal"><a href="#__codelineno-0-709">709</a></span>
<span class="normal"><a href="#__codelineno-0-710">710</a></span>
<span class="normal"><a href="#__codelineno-0-711">711</a></span>
<span class="normal"><a href="#__codelineno-0-712">712</a></span>
<span class="normal"><a href="#__codelineno-0-713">713</a></span>
<span class="normal"><a href="#__codelineno-0-714">714</a></span>
<span class="normal"><a href="#__codelineno-0-715">715</a></span>
<span class="normal"><a href="#__codelineno-0-716">716</a></span>
<span class="normal"><a href="#__codelineno-0-717">717</a></span>
<span class="normal"><a href="#__codelineno-0-718">718</a></span>
<span class="normal"><a href="#__codelineno-0-719">719</a></span>
<span class="normal"><a href="#__codelineno-0-720">720</a></span>
<span class="normal"><a href="#__codelineno-0-721">721</a></span>
<span class="normal"><a href="#__codelineno-0-722">722</a></span>
<span class="normal"><a href="#__codelineno-0-723">723</a></span>
<span class="normal"><a href="#__codelineno-0-724">724</a></span>
<span class="normal"><a href="#__codelineno-0-725">725</a></span>
<span class="normal"><a href="#__codelineno-0-726">726</a></span>
<span class="normal"><a href="#__codelineno-0-727">727</a></span>
<span class="normal"><a href="#__codelineno-0-728">728</a></span>
<span class="normal"><a href="#__codelineno-0-729">729</a></span>
<span class="normal"><a href="#__codelineno-0-730">730</a></span>
<span class="normal"><a href="#__codelineno-0-731">731</a></span>
<span class="normal"><a href="#__codelineno-0-732">732</a></span>
<span class="normal"><a href="#__codelineno-0-733">733</a></span>
<span class="normal"><a href="#__codelineno-0-734">734</a></span>
<span class="normal"><a href="#__codelineno-0-735">735</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-697" name="__codelineno-0-697"></a><span class="k">def</span> <span class="nf">_glm_functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-698" name="__codelineno-0-698"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-699" name="__codelineno-0-699"></a>    <span class="n">f_mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-700" name="__codelineno-0-700"></a>    <span class="n">f_var</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-701" name="__codelineno-0-701"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-702" name="__codelineno-0-702"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-703" name="__codelineno-0-703"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-704" name="__codelineno-0-704"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-705" name="__codelineno-0-705"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the posterior functional on input data `x` using &quot;glm&quot; prediction</span>
<a id="__codelineno-0-706" name="__codelineno-0-706"></a><span class="sd">    type.</span>
<a id="__codelineno-0-707" name="__codelineno-0-707"></a>
<a id="__codelineno-0-708" name="__codelineno-0-708"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-709" name="__codelineno-0-709"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-710" name="__codelineno-0-710"></a><span class="sd">    f_mu : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-711" name="__codelineno-0-711"></a><span class="sd">        glm predictive mean `(batch_size, output_shape)`</span>
<a id="__codelineno-0-712" name="__codelineno-0-712"></a>
<a id="__codelineno-0-713" name="__codelineno-0-713"></a><span class="sd">    f_var : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-714" name="__codelineno-0-714"></a><span class="sd">        glm predictive covariances `(batch_size, output_shape, output_shape)`</span>
<a id="__codelineno-0-715" name="__codelineno-0-715"></a>
<a id="__codelineno-0-716" name="__codelineno-0-716"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-717" name="__codelineno-0-717"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-718" name="__codelineno-0-718"></a>
<a id="__codelineno-0-719" name="__codelineno-0-719"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-720" name="__codelineno-0-720"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-721" name="__codelineno-0-721"></a>
<a id="__codelineno-0-722" name="__codelineno-0-722"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-723" name="__codelineno-0-723"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-724" name="__codelineno-0-724"></a>
<a id="__codelineno-0-725" name="__codelineno-0-725"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-726" name="__codelineno-0-726"></a><span class="sd">    -------</span>
<a id="__codelineno-0-727" name="__codelineno-0-727"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-728" name="__codelineno-0-728"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-729" name="__codelineno-0-729"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-730" name="__codelineno-0-730"></a>    <span class="k">assert</span> <span class="n">f_var</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">f_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<a id="__codelineno-0-731" name="__codelineno-0-731"></a>
<a id="__codelineno-0-732" name="__codelineno-0-732"></a>    <span class="k">if</span> <span class="n">diagonal_output</span><span class="p">:</span>
<a id="__codelineno-0-733" name="__codelineno-0-733"></a>        <span class="n">f_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_var</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-734" name="__codelineno-0-734"></a>
<a id="__codelineno-0-735" name="__codelineno-0-735"></a>    <span class="k">return</span> <span class="n">normal_samples</span><span class="p">(</span><span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">generator</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.DiagLLLaplace._glm_predictive_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">_glm_predictive_samples</span>


<a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">_glm_predictive_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(f_mu)">f_mu</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(f_var)">f_var</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the posterior predictive on input data <code>x</code> using "glm" prediction
type. I.e., the inverse-link function correponding to the likelihood is applied
on top of the functional sample.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(f_mu)" class="doc doc-heading doc-heading-parameter">              <b><code>f_mu</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(f_mu)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive mean <code>(batch_size, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(f_var)" class="doc doc-heading doc-heading-parameter">              <b><code>f_var</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(f_var)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive covariances <code>(batch_size, output_shape, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace._glm_predictive_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-737">737</a></span>
<span class="normal"><a href="#__codelineno-0-738">738</a></span>
<span class="normal"><a href="#__codelineno-0-739">739</a></span>
<span class="normal"><a href="#__codelineno-0-740">740</a></span>
<span class="normal"><a href="#__codelineno-0-741">741</a></span>
<span class="normal"><a href="#__codelineno-0-742">742</a></span>
<span class="normal"><a href="#__codelineno-0-743">743</a></span>
<span class="normal"><a href="#__codelineno-0-744">744</a></span>
<span class="normal"><a href="#__codelineno-0-745">745</a></span>
<span class="normal"><a href="#__codelineno-0-746">746</a></span>
<span class="normal"><a href="#__codelineno-0-747">747</a></span>
<span class="normal"><a href="#__codelineno-0-748">748</a></span>
<span class="normal"><a href="#__codelineno-0-749">749</a></span>
<span class="normal"><a href="#__codelineno-0-750">750</a></span>
<span class="normal"><a href="#__codelineno-0-751">751</a></span>
<span class="normal"><a href="#__codelineno-0-752">752</a></span>
<span class="normal"><a href="#__codelineno-0-753">753</a></span>
<span class="normal"><a href="#__codelineno-0-754">754</a></span>
<span class="normal"><a href="#__codelineno-0-755">755</a></span>
<span class="normal"><a href="#__codelineno-0-756">756</a></span>
<span class="normal"><a href="#__codelineno-0-757">757</a></span>
<span class="normal"><a href="#__codelineno-0-758">758</a></span>
<span class="normal"><a href="#__codelineno-0-759">759</a></span>
<span class="normal"><a href="#__codelineno-0-760">760</a></span>
<span class="normal"><a href="#__codelineno-0-761">761</a></span>
<span class="normal"><a href="#__codelineno-0-762">762</a></span>
<span class="normal"><a href="#__codelineno-0-763">763</a></span>
<span class="normal"><a href="#__codelineno-0-764">764</a></span>
<span class="normal"><a href="#__codelineno-0-765">765</a></span>
<span class="normal"><a href="#__codelineno-0-766">766</a></span>
<span class="normal"><a href="#__codelineno-0-767">767</a></span>
<span class="normal"><a href="#__codelineno-0-768">768</a></span>
<span class="normal"><a href="#__codelineno-0-769">769</a></span>
<span class="normal"><a href="#__codelineno-0-770">770</a></span>
<span class="normal"><a href="#__codelineno-0-771">771</a></span>
<span class="normal"><a href="#__codelineno-0-772">772</a></span>
<span class="normal"><a href="#__codelineno-0-773">773</a></span>
<span class="normal"><a href="#__codelineno-0-774">774</a></span>
<span class="normal"><a href="#__codelineno-0-775">775</a></span>
<span class="normal"><a href="#__codelineno-0-776">776</a></span>
<span class="normal"><a href="#__codelineno-0-777">777</a></span>
<span class="normal"><a href="#__codelineno-0-778">778</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-737" name="__codelineno-0-737"></a><span class="k">def</span> <span class="nf">_glm_predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-738" name="__codelineno-0-738"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-739" name="__codelineno-0-739"></a>    <span class="n">f_mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-740" name="__codelineno-0-740"></a>    <span class="n">f_var</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-741" name="__codelineno-0-741"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-742" name="__codelineno-0-742"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-743" name="__codelineno-0-743"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-744" name="__codelineno-0-744"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-745" name="__codelineno-0-745"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the posterior predictive on input data `x` using &quot;glm&quot; prediction</span>
<a id="__codelineno-0-746" name="__codelineno-0-746"></a><span class="sd">    type. I.e., the inverse-link function correponding to the likelihood is applied</span>
<a id="__codelineno-0-747" name="__codelineno-0-747"></a><span class="sd">    on top of the functional sample.</span>
<a id="__codelineno-0-748" name="__codelineno-0-748"></a>
<a id="__codelineno-0-749" name="__codelineno-0-749"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-750" name="__codelineno-0-750"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-751" name="__codelineno-0-751"></a><span class="sd">    f_mu : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-752" name="__codelineno-0-752"></a><span class="sd">        glm predictive mean `(batch_size, output_shape)`</span>
<a id="__codelineno-0-753" name="__codelineno-0-753"></a>
<a id="__codelineno-0-754" name="__codelineno-0-754"></a><span class="sd">    f_var : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-755" name="__codelineno-0-755"></a><span class="sd">        glm predictive covariances `(batch_size, output_shape, output_shape)`</span>
<a id="__codelineno-0-756" name="__codelineno-0-756"></a>
<a id="__codelineno-0-757" name="__codelineno-0-757"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-758" name="__codelineno-0-758"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-759" name="__codelineno-0-759"></a>
<a id="__codelineno-0-760" name="__codelineno-0-760"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-761" name="__codelineno-0-761"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-762" name="__codelineno-0-762"></a>
<a id="__codelineno-0-763" name="__codelineno-0-763"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-764" name="__codelineno-0-764"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-765" name="__codelineno-0-765"></a>
<a id="__codelineno-0-766" name="__codelineno-0-766"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-767" name="__codelineno-0-767"></a><span class="sd">    -------</span>
<a id="__codelineno-0-768" name="__codelineno-0-768"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-769" name="__codelineno-0-769"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-770" name="__codelineno-0-770"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-771" name="__codelineno-0-771"></a>    <span class="n">f_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-772" name="__codelineno-0-772"></a>        <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span><span class="p">,</span> <span class="n">generator</span>
<a id="__codelineno-0-773" name="__codelineno-0-773"></a>    <span class="p">)</span>
<a id="__codelineno-0-774" name="__codelineno-0-774"></a>
<a id="__codelineno-0-775" name="__codelineno-0-775"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-776" name="__codelineno-0-776"></a>        <span class="k">return</span> <span class="n">f_samples</span>
<a id="__codelineno-0-777" name="__codelineno-0-777"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-778" name="__codelineno-0-778"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">f_samples</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.DiagLLLaplace.log_prob" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">log_prob</span>


<a href="#laplace.lllaplace.DiagLLLaplace.log_prob" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">log_prob</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.log_prob(value)">value</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.log_prob(normalized)">normalized</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the log probability under the (current) Laplace approximation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.log_prob(value)" class="doc doc-heading doc-heading-parameter">              <b><code>value</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.log_prob(value)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.log_prob(normalized)" class="doc doc-heading doc-heading-parameter">              <b><code>normalized</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.log_prob(normalized)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>whether to return log of a properly normalized Gaussian or just the
terms that depend on <code>value</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_prob</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-996"> 996</a></span>
<span class="normal"><a href="#__codelineno-0-997"> 997</a></span>
<span class="normal"><a href="#__codelineno-0-998"> 998</a></span>
<span class="normal"><a href="#__codelineno-0-999"> 999</a></span>
<span class="normal"><a href="#__codelineno-0-1000">1000</a></span>
<span class="normal"><a href="#__codelineno-0-1001">1001</a></span>
<span class="normal"><a href="#__codelineno-0-1002">1002</a></span>
<span class="normal"><a href="#__codelineno-0-1003">1003</a></span>
<span class="normal"><a href="#__codelineno-0-1004">1004</a></span>
<span class="normal"><a href="#__codelineno-0-1005">1005</a></span>
<span class="normal"><a href="#__codelineno-0-1006">1006</a></span>
<span class="normal"><a href="#__codelineno-0-1007">1007</a></span>
<span class="normal"><a href="#__codelineno-0-1008">1008</a></span>
<span class="normal"><a href="#__codelineno-0-1009">1009</a></span>
<span class="normal"><a href="#__codelineno-0-1010">1010</a></span>
<span class="normal"><a href="#__codelineno-0-1011">1011</a></span>
<span class="normal"><a href="#__codelineno-0-1012">1012</a></span>
<span class="normal"><a href="#__codelineno-0-1013">1013</a></span>
<span class="normal"><a href="#__codelineno-0-1014">1014</a></span>
<span class="normal"><a href="#__codelineno-0-1015">1015</a></span>
<span class="normal"><a href="#__codelineno-0-1016">1016</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-996" name="__codelineno-0-996"></a><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">normalized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-997" name="__codelineno-0-997"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the log probability under the (current) Laplace approximation.</span>
<a id="__codelineno-0-998" name="__codelineno-0-998"></a>
<a id="__codelineno-0-999" name="__codelineno-0-999"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1000" name="__codelineno-0-1000"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1001" name="__codelineno-0-1001"></a><span class="sd">    value: torch.Tensor</span>
<a id="__codelineno-0-1002" name="__codelineno-0-1002"></a><span class="sd">    normalized : bool, default=True</span>
<a id="__codelineno-0-1003" name="__codelineno-0-1003"></a><span class="sd">        whether to return log of a properly normalized Gaussian or just the</span>
<a id="__codelineno-0-1004" name="__codelineno-0-1004"></a><span class="sd">        terms that depend on `value`.</span>
<a id="__codelineno-0-1005" name="__codelineno-0-1005"></a>
<a id="__codelineno-0-1006" name="__codelineno-0-1006"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1007" name="__codelineno-0-1007"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1008" name="__codelineno-0-1008"></a><span class="sd">    log_prob : torch.Tensor</span>
<a id="__codelineno-0-1009" name="__codelineno-0-1009"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1010" name="__codelineno-0-1010"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">normalized</span><span class="p">:</span>
<a id="__codelineno-0-1011" name="__codelineno-0-1011"></a>        <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">square_norm</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-0-1012" name="__codelineno-0-1012"></a>    <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-1013" name="__codelineno-0-1013"></a>        <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">n_params</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">pi</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_det_posterior_precision</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-0-1014" name="__codelineno-0-1014"></a>    <span class="p">)</span>
<a id="__codelineno-0-1015" name="__codelineno-0-1015"></a>    <span class="n">log_prob</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">square_norm</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-0-1016" name="__codelineno-0-1016"></a>    <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.DiagLLLaplace.functional_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">functional_samples</span>


<a href="#laplace.lllaplace.DiagLLLaplace.functional_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">functional_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.functional_samples(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.functional_samples(pred_type)">pred_type</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType" href="../enums/#laplace.utils.enums.PredType">PredType</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType.GLM" href="../enums/#laplace.utils.enums.PredType.GLM">GLM</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.functional_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.functional_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.functional_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the function-space posterior on input data <code>x</code>.
Can be used, for example, for Thompson sampling or to compute an arbitrary
expectation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.functional_samples(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>input data <code>(batch_size, input_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.functional_samples(pred_type)" class="doc doc-heading doc-heading-parameter">              <b><code>pred_type</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(pred_type)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;glm&#39;, &#39;nn&#39;)</code>, default:
                  <code>&#39;glm&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>type of posterior predictive, linearized GLM predictive or neural
network sampling predictive. The GLM predictive is consistent with
the curvature approximations used here.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.functional_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.functional_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.
Only applies when <code>pred_type='glm'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.functional_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.functional_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1154">1154</a></span>
<span class="normal"><a href="#__codelineno-0-1155">1155</a></span>
<span class="normal"><a href="#__codelineno-0-1156">1156</a></span>
<span class="normal"><a href="#__codelineno-0-1157">1157</a></span>
<span class="normal"><a href="#__codelineno-0-1158">1158</a></span>
<span class="normal"><a href="#__codelineno-0-1159">1159</a></span>
<span class="normal"><a href="#__codelineno-0-1160">1160</a></span>
<span class="normal"><a href="#__codelineno-0-1161">1161</a></span>
<span class="normal"><a href="#__codelineno-0-1162">1162</a></span>
<span class="normal"><a href="#__codelineno-0-1163">1163</a></span>
<span class="normal"><a href="#__codelineno-0-1164">1164</a></span>
<span class="normal"><a href="#__codelineno-0-1165">1165</a></span>
<span class="normal"><a href="#__codelineno-0-1166">1166</a></span>
<span class="normal"><a href="#__codelineno-0-1167">1167</a></span>
<span class="normal"><a href="#__codelineno-0-1168">1168</a></span>
<span class="normal"><a href="#__codelineno-0-1169">1169</a></span>
<span class="normal"><a href="#__codelineno-0-1170">1170</a></span>
<span class="normal"><a href="#__codelineno-0-1171">1171</a></span>
<span class="normal"><a href="#__codelineno-0-1172">1172</a></span>
<span class="normal"><a href="#__codelineno-0-1173">1173</a></span>
<span class="normal"><a href="#__codelineno-0-1174">1174</a></span>
<span class="normal"><a href="#__codelineno-0-1175">1175</a></span>
<span class="normal"><a href="#__codelineno-0-1176">1176</a></span>
<span class="normal"><a href="#__codelineno-0-1177">1177</a></span>
<span class="normal"><a href="#__codelineno-0-1178">1178</a></span>
<span class="normal"><a href="#__codelineno-0-1179">1179</a></span>
<span class="normal"><a href="#__codelineno-0-1180">1180</a></span>
<span class="normal"><a href="#__codelineno-0-1181">1181</a></span>
<span class="normal"><a href="#__codelineno-0-1182">1182</a></span>
<span class="normal"><a href="#__codelineno-0-1183">1183</a></span>
<span class="normal"><a href="#__codelineno-0-1184">1184</a></span>
<span class="normal"><a href="#__codelineno-0-1185">1185</a></span>
<span class="normal"><a href="#__codelineno-0-1186">1186</a></span>
<span class="normal"><a href="#__codelineno-0-1187">1187</a></span>
<span class="normal"><a href="#__codelineno-0-1188">1188</a></span>
<span class="normal"><a href="#__codelineno-0-1189">1189</a></span>
<span class="normal"><a href="#__codelineno-0-1190">1190</a></span>
<span class="normal"><a href="#__codelineno-0-1191">1191</a></span>
<span class="normal"><a href="#__codelineno-0-1192">1192</a></span>
<span class="normal"><a href="#__codelineno-0-1193">1193</a></span>
<span class="normal"><a href="#__codelineno-0-1194">1194</a></span>
<span class="normal"><a href="#__codelineno-0-1195">1195</a></span>
<span class="normal"><a href="#__codelineno-0-1196">1196</a></span>
<span class="normal"><a href="#__codelineno-0-1197">1197</a></span>
<span class="normal"><a href="#__codelineno-0-1198">1198</a></span>
<span class="normal"><a href="#__codelineno-0-1199">1199</a></span>
<span class="normal"><a href="#__codelineno-0-1200">1200</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1154" name="__codelineno-0-1154"></a><span class="k">def</span> <span class="nf">functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-1155" name="__codelineno-0-1155"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1156" name="__codelineno-0-1156"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1157" name="__codelineno-0-1157"></a>    <span class="n">pred_type</span><span class="p">:</span> <span class="n">PredType</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">,</span>
<a id="__codelineno-0-1158" name="__codelineno-0-1158"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-1159" name="__codelineno-0-1159"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1160" name="__codelineno-0-1160"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1161" name="__codelineno-0-1161"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1162" name="__codelineno-0-1162"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the function-space posterior on input data `x`.</span>
<a id="__codelineno-0-1163" name="__codelineno-0-1163"></a><span class="sd">    Can be used, for example, for Thompson sampling or to compute an arbitrary</span>
<a id="__codelineno-0-1164" name="__codelineno-0-1164"></a><span class="sd">    expectation.</span>
<a id="__codelineno-0-1165" name="__codelineno-0-1165"></a>
<a id="__codelineno-0-1166" name="__codelineno-0-1166"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1167" name="__codelineno-0-1167"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1168" name="__codelineno-0-1168"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-1169" name="__codelineno-0-1169"></a><span class="sd">        input data `(batch_size, input_shape)`</span>
<a id="__codelineno-0-1170" name="__codelineno-0-1170"></a>
<a id="__codelineno-0-1171" name="__codelineno-0-1171"></a><span class="sd">    pred_type : {&#39;glm&#39;, &#39;nn&#39;}, default=&#39;glm&#39;</span>
<a id="__codelineno-0-1172" name="__codelineno-0-1172"></a><span class="sd">        type of posterior predictive, linearized GLM predictive or neural</span>
<a id="__codelineno-0-1173" name="__codelineno-0-1173"></a><span class="sd">        network sampling predictive. The GLM predictive is consistent with</span>
<a id="__codelineno-0-1174" name="__codelineno-0-1174"></a><span class="sd">        the curvature approximations used here.</span>
<a id="__codelineno-0-1175" name="__codelineno-0-1175"></a>
<a id="__codelineno-0-1176" name="__codelineno-0-1176"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-1177" name="__codelineno-0-1177"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-1178" name="__codelineno-0-1178"></a>
<a id="__codelineno-0-1179" name="__codelineno-0-1179"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-1180" name="__codelineno-0-1180"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-1181" name="__codelineno-0-1181"></a><span class="sd">        Only applies when `pred_type=&#39;glm&#39;`.</span>
<a id="__codelineno-0-1182" name="__codelineno-0-1182"></a>
<a id="__codelineno-0-1183" name="__codelineno-0-1183"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1184" name="__codelineno-0-1184"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-1185" name="__codelineno-0-1185"></a>
<a id="__codelineno-0-1186" name="__codelineno-0-1186"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1187" name="__codelineno-0-1187"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1188" name="__codelineno-0-1188"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-1189" name="__codelineno-0-1189"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-1190" name="__codelineno-0-1190"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1191" name="__codelineno-0-1191"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">PredType</span><span class="o">.</span><span class="n">__members__</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<a id="__codelineno-0-1192" name="__codelineno-0-1192"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only glm and nn supported as prediction types.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1193" name="__codelineno-0-1193"></a>
<a id="__codelineno-0-1194" name="__codelineno-0-1194"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">:</span>
<a id="__codelineno-0-1195" name="__codelineno-0-1195"></a>        <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_distribution</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-1196" name="__codelineno-0-1196"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-1197" name="__codelineno-0-1197"></a>            <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span><span class="p">,</span> <span class="n">generator</span>
<a id="__codelineno-0-1198" name="__codelineno-0-1198"></a>        <span class="p">)</span>
<a id="__codelineno-0-1199" name="__codelineno-0-1199"></a>    <span class="k">else</span><span class="p">:</span>  <span class="c1"># &#39;nn&#39;</span>
<a id="__codelineno-0-1200" name="__codelineno-0-1200"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_functional_samples</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">generator</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.DiagLLLaplace.predictive_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">predictive_samples</span>


<a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">predictive_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(pred_type)">pred_type</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType" href="../enums/#laplace.utils.enums.PredType">PredType</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType.GLM" href="../enums/#laplace.utils.enums.PredType.GLM">GLM</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the posterior predictive on input data <code>x</code>. I.e., the respective
inverse-link function (e.g. softmax) is applied on top of the functional
sample.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.predictive_samples(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>input data <code>(batch_size, input_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.predictive_samples(pred_type)" class="doc doc-heading doc-heading-parameter">              <b><code>pred_type</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(pred_type)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;glm&#39;, &#39;nn&#39;)</code>, default:
                  <code>&#39;glm&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>type of posterior predictive, linearized GLM predictive or neural
network sampling predictive. The GLM predictive is consistent with
the curvature approximations used here.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.predictive_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.predictive_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.
Only applies when <code>pred_type='glm'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.DiagLLLaplace.predictive_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.DiagLLLaplace.predictive_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1202">1202</a></span>
<span class="normal"><a href="#__codelineno-0-1203">1203</a></span>
<span class="normal"><a href="#__codelineno-0-1204">1204</a></span>
<span class="normal"><a href="#__codelineno-0-1205">1205</a></span>
<span class="normal"><a href="#__codelineno-0-1206">1206</a></span>
<span class="normal"><a href="#__codelineno-0-1207">1207</a></span>
<span class="normal"><a href="#__codelineno-0-1208">1208</a></span>
<span class="normal"><a href="#__codelineno-0-1209">1209</a></span>
<span class="normal"><a href="#__codelineno-0-1210">1210</a></span>
<span class="normal"><a href="#__codelineno-0-1211">1211</a></span>
<span class="normal"><a href="#__codelineno-0-1212">1212</a></span>
<span class="normal"><a href="#__codelineno-0-1213">1213</a></span>
<span class="normal"><a href="#__codelineno-0-1214">1214</a></span>
<span class="normal"><a href="#__codelineno-0-1215">1215</a></span>
<span class="normal"><a href="#__codelineno-0-1216">1216</a></span>
<span class="normal"><a href="#__codelineno-0-1217">1217</a></span>
<span class="normal"><a href="#__codelineno-0-1218">1218</a></span>
<span class="normal"><a href="#__codelineno-0-1219">1219</a></span>
<span class="normal"><a href="#__codelineno-0-1220">1220</a></span>
<span class="normal"><a href="#__codelineno-0-1221">1221</a></span>
<span class="normal"><a href="#__codelineno-0-1222">1222</a></span>
<span class="normal"><a href="#__codelineno-0-1223">1223</a></span>
<span class="normal"><a href="#__codelineno-0-1224">1224</a></span>
<span class="normal"><a href="#__codelineno-0-1225">1225</a></span>
<span class="normal"><a href="#__codelineno-0-1226">1226</a></span>
<span class="normal"><a href="#__codelineno-0-1227">1227</a></span>
<span class="normal"><a href="#__codelineno-0-1228">1228</a></span>
<span class="normal"><a href="#__codelineno-0-1229">1229</a></span>
<span class="normal"><a href="#__codelineno-0-1230">1230</a></span>
<span class="normal"><a href="#__codelineno-0-1231">1231</a></span>
<span class="normal"><a href="#__codelineno-0-1232">1232</a></span>
<span class="normal"><a href="#__codelineno-0-1233">1233</a></span>
<span class="normal"><a href="#__codelineno-0-1234">1234</a></span>
<span class="normal"><a href="#__codelineno-0-1235">1235</a></span>
<span class="normal"><a href="#__codelineno-0-1236">1236</a></span>
<span class="normal"><a href="#__codelineno-0-1237">1237</a></span>
<span class="normal"><a href="#__codelineno-0-1238">1238</a></span>
<span class="normal"><a href="#__codelineno-0-1239">1239</a></span>
<span class="normal"><a href="#__codelineno-0-1240">1240</a></span>
<span class="normal"><a href="#__codelineno-0-1241">1241</a></span>
<span class="normal"><a href="#__codelineno-0-1242">1242</a></span>
<span class="normal"><a href="#__codelineno-0-1243">1243</a></span>
<span class="normal"><a href="#__codelineno-0-1244">1244</a></span>
<span class="normal"><a href="#__codelineno-0-1245">1245</a></span>
<span class="normal"><a href="#__codelineno-0-1246">1246</a></span>
<span class="normal"><a href="#__codelineno-0-1247">1247</a></span>
<span class="normal"><a href="#__codelineno-0-1248">1248</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1202" name="__codelineno-0-1202"></a><span class="k">def</span> <span class="nf">predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-1203" name="__codelineno-0-1203"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1204" name="__codelineno-0-1204"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1205" name="__codelineno-0-1205"></a>    <span class="n">pred_type</span><span class="p">:</span> <span class="n">PredType</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">,</span>
<a id="__codelineno-0-1206" name="__codelineno-0-1206"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-1207" name="__codelineno-0-1207"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1208" name="__codelineno-0-1208"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1209" name="__codelineno-0-1209"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1210" name="__codelineno-0-1210"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the posterior predictive on input data `x`. I.e., the respective</span>
<a id="__codelineno-0-1211" name="__codelineno-0-1211"></a><span class="sd">    inverse-link function (e.g. softmax) is applied on top of the functional</span>
<a id="__codelineno-0-1212" name="__codelineno-0-1212"></a><span class="sd">    sample.</span>
<a id="__codelineno-0-1213" name="__codelineno-0-1213"></a>
<a id="__codelineno-0-1214" name="__codelineno-0-1214"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1215" name="__codelineno-0-1215"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1216" name="__codelineno-0-1216"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-1217" name="__codelineno-0-1217"></a><span class="sd">        input data `(batch_size, input_shape)`</span>
<a id="__codelineno-0-1218" name="__codelineno-0-1218"></a>
<a id="__codelineno-0-1219" name="__codelineno-0-1219"></a><span class="sd">    pred_type : {&#39;glm&#39;, &#39;nn&#39;}, default=&#39;glm&#39;</span>
<a id="__codelineno-0-1220" name="__codelineno-0-1220"></a><span class="sd">        type of posterior predictive, linearized GLM predictive or neural</span>
<a id="__codelineno-0-1221" name="__codelineno-0-1221"></a><span class="sd">        network sampling predictive. The GLM predictive is consistent with</span>
<a id="__codelineno-0-1222" name="__codelineno-0-1222"></a><span class="sd">        the curvature approximations used here.</span>
<a id="__codelineno-0-1223" name="__codelineno-0-1223"></a>
<a id="__codelineno-0-1224" name="__codelineno-0-1224"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-1225" name="__codelineno-0-1225"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-1226" name="__codelineno-0-1226"></a>
<a id="__codelineno-0-1227" name="__codelineno-0-1227"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-1228" name="__codelineno-0-1228"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-1229" name="__codelineno-0-1229"></a><span class="sd">        Only applies when `pred_type=&#39;glm&#39;`.</span>
<a id="__codelineno-0-1230" name="__codelineno-0-1230"></a>
<a id="__codelineno-0-1231" name="__codelineno-0-1231"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1232" name="__codelineno-0-1232"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-1233" name="__codelineno-0-1233"></a>
<a id="__codelineno-0-1234" name="__codelineno-0-1234"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1235" name="__codelineno-0-1235"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1236" name="__codelineno-0-1236"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-1237" name="__codelineno-0-1237"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-1238" name="__codelineno-0-1238"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1239" name="__codelineno-0-1239"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">PredType</span><span class="o">.</span><span class="n">__members__</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<a id="__codelineno-0-1240" name="__codelineno-0-1240"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only glm and nn supported as prediction types.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1241" name="__codelineno-0-1241"></a>
<a id="__codelineno-0-1242" name="__codelineno-0-1242"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">:</span>
<a id="__codelineno-0-1243" name="__codelineno-0-1243"></a>        <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_distribution</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-1244" name="__codelineno-0-1244"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-1245" name="__codelineno-0-1245"></a>            <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span><span class="p">,</span> <span class="n">generator</span>
<a id="__codelineno-0-1246" name="__codelineno-0-1246"></a>        <span class="p">)</span>
<a id="__codelineno-0-1247" name="__codelineno-0-1247"></a>    <span class="k">else</span><span class="p">:</span>  <span class="c1"># &#39;nn&#39;</span>
<a id="__codelineno-0-1248" name="__codelineno-0-1248"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_predictive_samples</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">generator</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="laplace.lllaplace.KronLLLaplace" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">KronLLLaplace</span>


<a href="#laplace.lllaplace.KronLLLaplace" class="headerlink" title="Permanent link">#</a></h2>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">KronLLLaplace</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n"><span title="torch.nn.Module">Module</span></span><span class="p">,</span> <span class="n">likelihood</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n">sigma_noise</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">prior_precision</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">temperature</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">enable_backprop</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">feature_reduction</span><span class="p">:</span> <span class="n"><span title="laplace.utils.feature_extractor.FeatureReduction">FeatureReduction</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dict_key_x</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="n">dict_key_y</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="s1">&#39;labels&#39;</span><span class="p">,</span> <span class="n">backend</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#type">type</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="laplace.curvature.curvature.CurvatureInterface" href="../curvatures/#laplace.curvature.CurvatureInterface">CurvatureInterface</a></span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">last_layer_name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">damping</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">backend_kwargs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">asdl_fisher_kwargs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace" href="#laplace.lllaplace.LLLaplace">LLLaplace</a></code>, <code><a class="autorefs autorefs-internal" title="laplace.baselaplace.KronLaplace" href="../parametriclaplace/#laplace.baselaplace.KronLaplace">KronLaplace</a></code></p>


        <p>Last-layer Laplace approximation with Kronecker factored log likelihood Hessian approximation
and hence posterior precision.
Mathematically, we have for the last parameter group, i.e., torch.nn.Linear,
that \P\approx Q \otimes H.
See <code>KronLaplace</code>, <code>LLLaplace</code>, and <code>BaseLaplace</code> for the full interface and see
<code>laplace.utils.matrix.Kron</code> and <code>laplace.utils.matrix.KronDecomposed</code> for the structure of
the Kronecker factors. <code>Kron</code> is used to aggregate factors by summing up and
<code>KronDecomposed</code> is used to add the prior, a Hessian factor (e.g. temperature),
and computing posterior covariances, marginal likelihood, etc.
Use of <code>damping</code> is possible by initializing or setting <code>damping=True</code>.</p>









<p><span class="doc-section-title">Methods:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace.fit" href="#laplace.lllaplace.KronLLLaplace.fit">fit</a></code></b>
            –
            <div class="doc-md-description">
              <p>Fit the local Laplace approximation at the parameters of the model.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace.log_marginal_likelihood" href="#laplace.lllaplace.KronLLLaplace.log_marginal_likelihood">log_marginal_likelihood</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the Laplace approximation to the log marginal likelihood subject</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace.__call__" href="#laplace.lllaplace.KronLLLaplace.__call__">__call__</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the posterior predictive on input data <code>x</code>.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace.log_prob" href="#laplace.lllaplace.KronLLLaplace.log_prob">log_prob</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the log probability under the (current) Laplace approximation.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace.functional_samples" href="#laplace.lllaplace.KronLLLaplace.functional_samples">functional_samples</a></code></b>
            –
            <div class="doc-md-description">
              <p>Sample from the function-space posterior on input data <code>x</code>.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace.predictive_samples" href="#laplace.lllaplace.KronLLLaplace.predictive_samples">predictive_samples</a></code></b>
            –
            <div class="doc-md-description">
              <p>Sample from the posterior predictive on input data <code>x</code>. I.e., the respective</p>
            </div>
          </li>
    </ul>




<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace.log_likelihood" href="#laplace.lllaplace.KronLLLaplace.log_likelihood">log_likelihood</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute log likelihood on the training data after <code>.fit()</code> has been called.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace.prior_precision_diag" href="#laplace.lllaplace.KronLLLaplace.prior_precision_diag">prior_precision_diag</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Obtain the diagonal prior precision <span class="arithmatex">\(p_0\)</span> constructed from either</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace.scatter" href="#laplace.lllaplace.KronLLLaplace.scatter">scatter</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Computes the <em>scatter</em>, a term of the log marginal likelihood that</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace.log_det_prior_precision" href="#laplace.lllaplace.KronLLLaplace.log_det_prior_precision">log_det_prior_precision</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute log determinant of the prior precision</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace.log_det_ratio" href="#laplace.lllaplace.KronLLLaplace.log_det_ratio">log_det_ratio</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute the log determinant ratio, a part of the log marginal likelihood.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.KronLLLaplace.posterior_precision" href="#laplace.lllaplace.KronLLLaplace.posterior_precision">posterior_precision</a></code></b>
              (<code><a class="autorefs autorefs-internal" title="laplace.utils.matrix.KronDecomposed" href="../utils/#laplace.utils.KronDecomposed">KronDecomposed</a></code>)
          –
          <div class="doc-md-description">
            <p>Kronecker factored Posterior precision <span class="arithmatex">\(P\)</span>.</p>
          </div>
        </li>
    </ul>

                  <details class="quote">
                    <summary>Source code in <code>laplace/lllaplace.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-399">399</a></span>
<span class="normal"><a href="#__codelineno-0-400">400</a></span>
<span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span>
<span class="normal"><a href="#__codelineno-0-404">404</a></span>
<span class="normal"><a href="#__codelineno-0-405">405</a></span>
<span class="normal"><a href="#__codelineno-0-406">406</a></span>
<span class="normal"><a href="#__codelineno-0-407">407</a></span>
<span class="normal"><a href="#__codelineno-0-408">408</a></span>
<span class="normal"><a href="#__codelineno-0-409">409</a></span>
<span class="normal"><a href="#__codelineno-0-410">410</a></span>
<span class="normal"><a href="#__codelineno-0-411">411</a></span>
<span class="normal"><a href="#__codelineno-0-412">412</a></span>
<span class="normal"><a href="#__codelineno-0-413">413</a></span>
<span class="normal"><a href="#__codelineno-0-414">414</a></span>
<span class="normal"><a href="#__codelineno-0-415">415</a></span>
<span class="normal"><a href="#__codelineno-0-416">416</a></span>
<span class="normal"><a href="#__codelineno-0-417">417</a></span>
<span class="normal"><a href="#__codelineno-0-418">418</a></span>
<span class="normal"><a href="#__codelineno-0-419">419</a></span>
<span class="normal"><a href="#__codelineno-0-420">420</a></span>
<span class="normal"><a href="#__codelineno-0-421">421</a></span>
<span class="normal"><a href="#__codelineno-0-422">422</a></span>
<span class="normal"><a href="#__codelineno-0-423">423</a></span>
<span class="normal"><a href="#__codelineno-0-424">424</a></span>
<span class="normal"><a href="#__codelineno-0-425">425</a></span>
<span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span>
<span class="normal"><a href="#__codelineno-0-432">432</a></span>
<span class="normal"><a href="#__codelineno-0-433">433</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-399" name="__codelineno-0-399"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-400" name="__codelineno-0-400"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-401" name="__codelineno-0-401"></a>    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
<a id="__codelineno-0-402" name="__codelineno-0-402"></a>    <span class="n">likelihood</span><span class="p">:</span> <span class="n">Likelihood</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-403" name="__codelineno-0-403"></a>    <span class="n">sigma_noise</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-404" name="__codelineno-0-404"></a>    <span class="n">prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-405" name="__codelineno-0-405"></a>    <span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-406" name="__codelineno-0-406"></a>    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-407" name="__codelineno-0-407"></a>    <span class="n">enable_backprop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-408" name="__codelineno-0-408"></a>    <span class="n">feature_reduction</span><span class="p">:</span> <span class="n">FeatureReduction</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-409" name="__codelineno-0-409"></a>    <span class="n">dict_key_x</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
<a id="__codelineno-0-410" name="__codelineno-0-410"></a>    <span class="n">dict_key_y</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span>
<a id="__codelineno-0-411" name="__codelineno-0-411"></a>    <span class="n">backend</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">CurvatureInterface</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-412" name="__codelineno-0-412"></a>    <span class="n">last_layer_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-413" name="__codelineno-0-413"></a>    <span class="n">damping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-414" name="__codelineno-0-414"></a>    <span class="n">backend_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-415" name="__codelineno-0-415"></a>    <span class="n">asdl_fisher_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-416" name="__codelineno-0-416"></a><span class="p">):</span>
<a id="__codelineno-0-417" name="__codelineno-0-417"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">damping</span> <span class="o">=</span> <span class="n">damping</span>
<a id="__codelineno-0-418" name="__codelineno-0-418"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-419" name="__codelineno-0-419"></a>        <span class="n">model</span><span class="p">,</span>
<a id="__codelineno-0-420" name="__codelineno-0-420"></a>        <span class="n">likelihood</span><span class="p">,</span>
<a id="__codelineno-0-421" name="__codelineno-0-421"></a>        <span class="n">sigma_noise</span><span class="p">,</span>
<a id="__codelineno-0-422" name="__codelineno-0-422"></a>        <span class="n">prior_precision</span><span class="p">,</span>
<a id="__codelineno-0-423" name="__codelineno-0-423"></a>        <span class="n">prior_mean</span><span class="p">,</span>
<a id="__codelineno-0-424" name="__codelineno-0-424"></a>        <span class="n">temperature</span><span class="p">,</span>
<a id="__codelineno-0-425" name="__codelineno-0-425"></a>        <span class="n">enable_backprop</span><span class="p">,</span>
<a id="__codelineno-0-426" name="__codelineno-0-426"></a>        <span class="n">feature_reduction</span><span class="p">,</span>
<a id="__codelineno-0-427" name="__codelineno-0-427"></a>        <span class="n">dict_key_x</span><span class="p">,</span>
<a id="__codelineno-0-428" name="__codelineno-0-428"></a>        <span class="n">dict_key_y</span><span class="p">,</span>
<a id="__codelineno-0-429" name="__codelineno-0-429"></a>        <span class="n">backend</span><span class="p">,</span>
<a id="__codelineno-0-430" name="__codelineno-0-430"></a>        <span class="n">last_layer_name</span><span class="p">,</span>
<a id="__codelineno-0-431" name="__codelineno-0-431"></a>        <span class="n">backend_kwargs</span><span class="p">,</span>
<a id="__codelineno-0-432" name="__codelineno-0-432"></a>        <span class="n">asdl_fisher_kwargs</span><span class="p">,</span>
<a id="__codelineno-0-433" name="__codelineno-0-433"></a>    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.KronLLLaplace.log_likelihood" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_likelihood</span>


<a href="#laplace.lllaplace.KronLLLaplace.log_likelihood" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_likelihood</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute log likelihood on the training data after <code>.fit()</code> has been called.
The log likelihood is computed on-demand based on the loss and, for example,
the observation noise which makes it differentiable in the latter for
iterative updates.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_likelihood</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.KronLLLaplace.prior_precision_diag" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">prior_precision_diag</span>


<a href="#laplace.lllaplace.KronLLLaplace.prior_precision_diag" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">prior_precision_diag</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Obtain the diagonal prior precision <span class="arithmatex">\(p_0\)</span> constructed from either
a scalar or diagonal prior precision.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>prior_precision_diag</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.KronLLLaplace.scatter" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">scatter</span>


<a href="#laplace.lllaplace.KronLLLaplace.scatter" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">scatter</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the <em>scatter</em>, a term of the log marginal likelihood that
corresponds to L-2 regularization:
<code>scatter</code> = <span class="arithmatex">\((\theta_{MAP} - \mu_0)^{T} P_0 (\theta_{MAP} - \mu_0) \)</span>.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>scatter</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.KronLLLaplace.log_det_prior_precision" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_det_prior_precision</span>


<a href="#laplace.lllaplace.KronLLLaplace.log_det_prior_precision" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_det_prior_precision</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute log determinant of the prior precision
<span class="arithmatex">\(\log \det P_0\)</span></p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_det</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.KronLLLaplace.log_det_ratio" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_det_ratio</span>


<a href="#laplace.lllaplace.KronLLLaplace.log_det_ratio" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_det_ratio</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the log determinant ratio, a part of the log marginal likelihood.</p>
<div class="arithmatex">\[
    \log \frac{\det P}{\det P_0} = \log \det P - \log \det P_0
\]</div>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_det_ratio</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.KronLLLaplace.posterior_precision" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">posterior_precision</span>


<a href="#laplace.lllaplace.KronLLLaplace.posterior_precision" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">posterior_precision</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.matrix.KronDecomposed" href="../utils/#laplace.utils.KronDecomposed">KronDecomposed</a></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Kronecker factored Posterior precision <span class="arithmatex">\(P\)</span>.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>precision</code></b> (              <code>`laplace.utils.matrix.KronDecomposed`</code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.KronLLLaplace.fit" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">fit</span>


<a href="#laplace.lllaplace.KronLLLaplace.fit" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">fit</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.fit(train_loader)">train_loader</a></span><span class="p">:</span> <span class="n"><span title="torch.utils.data.DataLoader">DataLoader</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.fit(override)">override</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.fit(progress_bar)">progress_bar</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Fit the local Laplace approximation at the parameters of the model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.fit(train_loader)" class="doc doc-heading doc-heading-parameter">              <b><code>train_loader</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.fit(train_loader)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.data.utils.DataLoader">DataLoader</span></code>)
          –
          <div class="doc-md-description">
            <p>each iterate is a training batch, either <code>(X, y)</code> tensors or a dict-like
object containing keys as expressed by <code>self.dict_key_x</code> and
<code>self.dict_key_y</code>. <code>train_loader.dataset</code> needs to be set to access
<span class="arithmatex">\(N\)</span>, size of the data set.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.fit(override)" class="doc doc-heading doc-heading-parameter">              <b><code>override</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.fit(override)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>whether to initialize H, loss, and n_data again; setting to False is useful for
online learning settings to accumulate a sequential posterior approximation.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.fit(progress_bar)" class="doc doc-heading doc-heading-parameter">              <b><code>progress_bar</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.fit(progress_bar)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/lllaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>    <span class="n">progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Fit the local Laplace approximation at the parameters of the model.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">    train_loader : torch.data.utils.DataLoader</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">        each iterate is a training batch, either `(X, y)` tensors or a dict-like</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">        object containing keys as expressed by `self.dict_key_x` and</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">        `self.dict_key_y`. `train_loader.dataset` needs to be set to access</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a><span class="sd">        \\(N\\), size of the data set.</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a><span class="sd">    override : bool, default=True</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">        whether to initialize H, loss, and n_data again; setting to False is useful for</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a><span class="sd">        online learning settings to accumulate a sequential posterior approximation.</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">    progress_bar: bool, default=False</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">override</span><span class="p">:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>            <span class="s2">&quot;Last-layer Laplace approximations do not support `override=False`.&quot;</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="n">MutableMapping</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>            <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="p">)</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_find_last_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>        <span class="n">params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">parameters_to_vector</span><span class="p">(</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>        <span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>        <span class="c1"># here, check the already set prior precision again</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior_precision</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior_mean</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_init_H</span><span class="p">()</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="n">override</span><span class="p">)</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">parameters_to_vector</span><span class="p">(</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>    <span class="p">)</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_backprop</span><span class="p">:</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.KronLLLaplace.log_marginal_likelihood" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">log_marginal_likelihood</span>


<a href="#laplace.lllaplace.KronLLLaplace.log_marginal_likelihood" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">log_marginal_likelihood</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.log_marginal_likelihood(prior_precision)">prior_precision</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.log_marginal_likelihood(sigma_noise)">sigma_noise</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the Laplace approximation to the log marginal likelihood subject
to specific Hessian approximations that subclasses implement.
Requires that the Laplace approximation has been fit before.
The resulting torch.Tensor is differentiable in <code>prior_precision</code> and
<code>sigma_noise</code> if these have gradients enabled.
By passing <code>prior_precision</code> or <code>sigma_noise</code>, the current value is
overwritten. This is useful for iterating on the log marginal likelihood.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.log_marginal_likelihood(prior_precision)" class="doc doc-heading doc-heading-parameter">              <b><code>prior_precision</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.log_marginal_likelihood(prior_precision)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>prior precision if should be changed from current <code>prior_precision</code> value</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.log_marginal_likelihood(sigma_noise)" class="doc doc-heading doc-heading-parameter">              <b><code>sigma_noise</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.log_marginal_likelihood(sigma_noise)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>observation noise standard deviation if should be changed</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_marglik</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1018">1018</a></span>
<span class="normal"><a href="#__codelineno-0-1019">1019</a></span>
<span class="normal"><a href="#__codelineno-0-1020">1020</a></span>
<span class="normal"><a href="#__codelineno-0-1021">1021</a></span>
<span class="normal"><a href="#__codelineno-0-1022">1022</a></span>
<span class="normal"><a href="#__codelineno-0-1023">1023</a></span>
<span class="normal"><a href="#__codelineno-0-1024">1024</a></span>
<span class="normal"><a href="#__codelineno-0-1025">1025</a></span>
<span class="normal"><a href="#__codelineno-0-1026">1026</a></span>
<span class="normal"><a href="#__codelineno-0-1027">1027</a></span>
<span class="normal"><a href="#__codelineno-0-1028">1028</a></span>
<span class="normal"><a href="#__codelineno-0-1029">1029</a></span>
<span class="normal"><a href="#__codelineno-0-1030">1030</a></span>
<span class="normal"><a href="#__codelineno-0-1031">1031</a></span>
<span class="normal"><a href="#__codelineno-0-1032">1032</a></span>
<span class="normal"><a href="#__codelineno-0-1033">1033</a></span>
<span class="normal"><a href="#__codelineno-0-1034">1034</a></span>
<span class="normal"><a href="#__codelineno-0-1035">1035</a></span>
<span class="normal"><a href="#__codelineno-0-1036">1036</a></span>
<span class="normal"><a href="#__codelineno-0-1037">1037</a></span>
<span class="normal"><a href="#__codelineno-0-1038">1038</a></span>
<span class="normal"><a href="#__codelineno-0-1039">1039</a></span>
<span class="normal"><a href="#__codelineno-0-1040">1040</a></span>
<span class="normal"><a href="#__codelineno-0-1041">1041</a></span>
<span class="normal"><a href="#__codelineno-0-1042">1042</a></span>
<span class="normal"><a href="#__codelineno-0-1043">1043</a></span>
<span class="normal"><a href="#__codelineno-0-1044">1044</a></span>
<span class="normal"><a href="#__codelineno-0-1045">1045</a></span>
<span class="normal"><a href="#__codelineno-0-1046">1046</a></span>
<span class="normal"><a href="#__codelineno-0-1047">1047</a></span>
<span class="normal"><a href="#__codelineno-0-1048">1048</a></span>
<span class="normal"><a href="#__codelineno-0-1049">1049</a></span>
<span class="normal"><a href="#__codelineno-0-1050">1050</a></span>
<span class="normal"><a href="#__codelineno-0-1051">1051</a></span>
<span class="normal"><a href="#__codelineno-0-1052">1052</a></span>
<span class="normal"><a href="#__codelineno-0-1053">1053</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1018" name="__codelineno-0-1018"></a><span class="k">def</span> <span class="nf">log_marginal_likelihood</span><span class="p">(</span>
<a id="__codelineno-0-1019" name="__codelineno-0-1019"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1020" name="__codelineno-0-1020"></a>    <span class="n">prior_precision</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1021" name="__codelineno-0-1021"></a>    <span class="n">sigma_noise</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1022" name="__codelineno-0-1022"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1023" name="__codelineno-0-1023"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the Laplace approximation to the log marginal likelihood subject</span>
<a id="__codelineno-0-1024" name="__codelineno-0-1024"></a><span class="sd">    to specific Hessian approximations that subclasses implement.</span>
<a id="__codelineno-0-1025" name="__codelineno-0-1025"></a><span class="sd">    Requires that the Laplace approximation has been fit before.</span>
<a id="__codelineno-0-1026" name="__codelineno-0-1026"></a><span class="sd">    The resulting torch.Tensor is differentiable in `prior_precision` and</span>
<a id="__codelineno-0-1027" name="__codelineno-0-1027"></a><span class="sd">    `sigma_noise` if these have gradients enabled.</span>
<a id="__codelineno-0-1028" name="__codelineno-0-1028"></a><span class="sd">    By passing `prior_precision` or `sigma_noise`, the current value is</span>
<a id="__codelineno-0-1029" name="__codelineno-0-1029"></a><span class="sd">    overwritten. This is useful for iterating on the log marginal likelihood.</span>
<a id="__codelineno-0-1030" name="__codelineno-0-1030"></a>
<a id="__codelineno-0-1031" name="__codelineno-0-1031"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1032" name="__codelineno-0-1032"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1033" name="__codelineno-0-1033"></a><span class="sd">    prior_precision : torch.Tensor, optional</span>
<a id="__codelineno-0-1034" name="__codelineno-0-1034"></a><span class="sd">        prior precision if should be changed from current `prior_precision` value</span>
<a id="__codelineno-0-1035" name="__codelineno-0-1035"></a><span class="sd">    sigma_noise : torch.Tensor, optional</span>
<a id="__codelineno-0-1036" name="__codelineno-0-1036"></a><span class="sd">        observation noise standard deviation if should be changed</span>
<a id="__codelineno-0-1037" name="__codelineno-0-1037"></a>
<a id="__codelineno-0-1038" name="__codelineno-0-1038"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1039" name="__codelineno-0-1039"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1040" name="__codelineno-0-1040"></a><span class="sd">    log_marglik : torch.Tensor</span>
<a id="__codelineno-0-1041" name="__codelineno-0-1041"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1042" name="__codelineno-0-1042"></a>    <span class="c1"># update prior precision (useful when iterating on marglik)</span>
<a id="__codelineno-0-1043" name="__codelineno-0-1043"></a>    <span class="k">if</span> <span class="n">prior_precision</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1044" name="__codelineno-0-1044"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_precision</span> <span class="o">=</span> <span class="n">prior_precision</span>
<a id="__codelineno-0-1045" name="__codelineno-0-1045"></a>
<a id="__codelineno-0-1046" name="__codelineno-0-1046"></a>    <span class="c1"># update sigma_noise (useful when iterating on marglik)</span>
<a id="__codelineno-0-1047" name="__codelineno-0-1047"></a>    <span class="k">if</span> <span class="n">sigma_noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1048" name="__codelineno-0-1048"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="o">!=</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-1049" name="__codelineno-0-1049"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Can only change sigma_noise for regression.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1050" name="__codelineno-0-1050"></a>
<a id="__codelineno-0-1051" name="__codelineno-0-1051"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_noise</span> <span class="o">=</span> <span class="n">sigma_noise</span>
<a id="__codelineno-0-1052" name="__codelineno-0-1052"></a>
<a id="__codelineno-0-1053" name="__codelineno-0-1053"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_det_ratio</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scatter</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.KronLLLaplace.__call__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">__call__</span>


<a href="#laplace.lllaplace.KronLLLaplace.__call__" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="fm">__call__</span><span class="p">(</span><span class="nf"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.__call__(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.__call__(pred_type)">pred_type</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType" href="../enums/#laplace.utils.enums.PredType">PredType</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType.GLM" href="../enums/#laplace.utils.enums.PredType.GLM">GLM</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.__call__(joint)">joint</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.__call__(link_approx)">link_approx</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox" href="../enums/#laplace.utils.enums.LinkApprox">LinkApprox</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox.PROBIT" href="../enums/#laplace.utils.enums.LinkApprox.PROBIT">PROBIT</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.__call__(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.__call__(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.__call__(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.__call__(fitting)">fitting</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">**model_kwargs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the posterior predictive on input data <code>x</code>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.__call__(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.__call__(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p><code>(batch_size, input_shape)</code> if tensor. If MutableMapping, must contain
the said tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.__call__(pred_type)" class="doc doc-heading doc-heading-parameter">              <b><code>pred_type</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.__call__(pred_type)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;glm&#39;, &#39;nn&#39;)</code>, default:
                  <code>&#39;glm&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>type of posterior predictive, linearized GLM predictive or neural
network sampling predictive. The GLM predictive is consistent with
the curvature approximations used here. When Laplace is done only
on subset of parameters (i.e. some grad are disabled),
only <code>nn</code> predictive is supported.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.__call__(link_approx)" class="doc doc-heading doc-heading-parameter">              <b><code>link_approx</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.__call__(link_approx)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;)</code>, default:
                  <code>&#39;mc&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>how to approximate the classification link function for the <code>'glm'</code>.
For <code>pred_type='nn'</code>, only 'mc' is possible.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.__call__(joint)" class="doc doc-heading doc-heading-parameter">              <b><code>joint</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.__call__(joint)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to output a joint predictive distribution in regression with
<code>pred_type='glm'</code>. If set to <code>True</code>, the predictive distribution
has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).
If <code>False</code>, then only outputs the marginal predictive distribution.
Only available for regression and GLM predictive.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.__call__(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.__call__(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples for <code>link_approx='mc'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.__call__(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.__call__(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized posterior predictive on the outputs.
Only works for <code>pred_type='glm'</code> when <code>joint=False</code> in regression.
In the case of last-layer Laplace with a diagonal or Kron Hessian,
setting this to <code>True</code> makes computation much(!) faster for large
number of outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.__call__(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.__call__(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.__call__(fitting)" class="doc doc-heading doc-heading-parameter">              <b><code>fitting</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.__call__(fitting)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether or not this predictive call is done during fitting. Only useful for
reward modeling: the likelihood is set to <code>"regression"</code> when <code>False</code> and
<code>"classification"</code> when <code>True</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>predictive</code></b> (              <code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<span title="torch.Tensor">Tensor</span>]</code>
)          –
          <div class="doc-md-description">
            <p>For <code>likelihood='classification'</code>, a torch.Tensor is returned with
a distribution over classes (similar to a Softmax).
For <code>likelihood='regression'</code>, a tuple of torch.Tensor is returned
with the mean and the predictive variance.
For <code>likelihood='regression'</code> and <code>joint=True</code>, a tuple of torch.Tensor
is returned with the mean and the predictive covariance.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1055">1055</a></span>
<span class="normal"><a href="#__codelineno-0-1056">1056</a></span>
<span class="normal"><a href="#__codelineno-0-1057">1057</a></span>
<span class="normal"><a href="#__codelineno-0-1058">1058</a></span>
<span class="normal"><a href="#__codelineno-0-1059">1059</a></span>
<span class="normal"><a href="#__codelineno-0-1060">1060</a></span>
<span class="normal"><a href="#__codelineno-0-1061">1061</a></span>
<span class="normal"><a href="#__codelineno-0-1062">1062</a></span>
<span class="normal"><a href="#__codelineno-0-1063">1063</a></span>
<span class="normal"><a href="#__codelineno-0-1064">1064</a></span>
<span class="normal"><a href="#__codelineno-0-1065">1065</a></span>
<span class="normal"><a href="#__codelineno-0-1066">1066</a></span>
<span class="normal"><a href="#__codelineno-0-1067">1067</a></span>
<span class="normal"><a href="#__codelineno-0-1068">1068</a></span>
<span class="normal"><a href="#__codelineno-0-1069">1069</a></span>
<span class="normal"><a href="#__codelineno-0-1070">1070</a></span>
<span class="normal"><a href="#__codelineno-0-1071">1071</a></span>
<span class="normal"><a href="#__codelineno-0-1072">1072</a></span>
<span class="normal"><a href="#__codelineno-0-1073">1073</a></span>
<span class="normal"><a href="#__codelineno-0-1074">1074</a></span>
<span class="normal"><a href="#__codelineno-0-1075">1075</a></span>
<span class="normal"><a href="#__codelineno-0-1076">1076</a></span>
<span class="normal"><a href="#__codelineno-0-1077">1077</a></span>
<span class="normal"><a href="#__codelineno-0-1078">1078</a></span>
<span class="normal"><a href="#__codelineno-0-1079">1079</a></span>
<span class="normal"><a href="#__codelineno-0-1080">1080</a></span>
<span class="normal"><a href="#__codelineno-0-1081">1081</a></span>
<span class="normal"><a href="#__codelineno-0-1082">1082</a></span>
<span class="normal"><a href="#__codelineno-0-1083">1083</a></span>
<span class="normal"><a href="#__codelineno-0-1084">1084</a></span>
<span class="normal"><a href="#__codelineno-0-1085">1085</a></span>
<span class="normal"><a href="#__codelineno-0-1086">1086</a></span>
<span class="normal"><a href="#__codelineno-0-1087">1087</a></span>
<span class="normal"><a href="#__codelineno-0-1088">1088</a></span>
<span class="normal"><a href="#__codelineno-0-1089">1089</a></span>
<span class="normal"><a href="#__codelineno-0-1090">1090</a></span>
<span class="normal"><a href="#__codelineno-0-1091">1091</a></span>
<span class="normal"><a href="#__codelineno-0-1092">1092</a></span>
<span class="normal"><a href="#__codelineno-0-1093">1093</a></span>
<span class="normal"><a href="#__codelineno-0-1094">1094</a></span>
<span class="normal"><a href="#__codelineno-0-1095">1095</a></span>
<span class="normal"><a href="#__codelineno-0-1096">1096</a></span>
<span class="normal"><a href="#__codelineno-0-1097">1097</a></span>
<span class="normal"><a href="#__codelineno-0-1098">1098</a></span>
<span class="normal"><a href="#__codelineno-0-1099">1099</a></span>
<span class="normal"><a href="#__codelineno-0-1100">1100</a></span>
<span class="normal"><a href="#__codelineno-0-1101">1101</a></span>
<span class="normal"><a href="#__codelineno-0-1102">1102</a></span>
<span class="normal"><a href="#__codelineno-0-1103">1103</a></span>
<span class="normal"><a href="#__codelineno-0-1104">1104</a></span>
<span class="normal"><a href="#__codelineno-0-1105">1105</a></span>
<span class="normal"><a href="#__codelineno-0-1106">1106</a></span>
<span class="normal"><a href="#__codelineno-0-1107">1107</a></span>
<span class="normal"><a href="#__codelineno-0-1108">1108</a></span>
<span class="normal"><a href="#__codelineno-0-1109">1109</a></span>
<span class="normal"><a href="#__codelineno-0-1110">1110</a></span>
<span class="normal"><a href="#__codelineno-0-1111">1111</a></span>
<span class="normal"><a href="#__codelineno-0-1112">1112</a></span>
<span class="normal"><a href="#__codelineno-0-1113">1113</a></span>
<span class="normal"><a href="#__codelineno-0-1114">1114</a></span>
<span class="normal"><a href="#__codelineno-0-1115">1115</a></span>
<span class="normal"><a href="#__codelineno-0-1116">1116</a></span>
<span class="normal"><a href="#__codelineno-0-1117">1117</a></span>
<span class="normal"><a href="#__codelineno-0-1118">1118</a></span>
<span class="normal"><a href="#__codelineno-0-1119">1119</a></span>
<span class="normal"><a href="#__codelineno-0-1120">1120</a></span>
<span class="normal"><a href="#__codelineno-0-1121">1121</a></span>
<span class="normal"><a href="#__codelineno-0-1122">1122</a></span>
<span class="normal"><a href="#__codelineno-0-1123">1123</a></span>
<span class="normal"><a href="#__codelineno-0-1124">1124</a></span>
<span class="normal"><a href="#__codelineno-0-1125">1125</a></span>
<span class="normal"><a href="#__codelineno-0-1126">1126</a></span>
<span class="normal"><a href="#__codelineno-0-1127">1127</a></span>
<span class="normal"><a href="#__codelineno-0-1128">1128</a></span>
<span class="normal"><a href="#__codelineno-0-1129">1129</a></span>
<span class="normal"><a href="#__codelineno-0-1130">1130</a></span>
<span class="normal"><a href="#__codelineno-0-1131">1131</a></span>
<span class="normal"><a href="#__codelineno-0-1132">1132</a></span>
<span class="normal"><a href="#__codelineno-0-1133">1133</a></span>
<span class="normal"><a href="#__codelineno-0-1134">1134</a></span>
<span class="normal"><a href="#__codelineno-0-1135">1135</a></span>
<span class="normal"><a href="#__codelineno-0-1136">1136</a></span>
<span class="normal"><a href="#__codelineno-0-1137">1137</a></span>
<span class="normal"><a href="#__codelineno-0-1138">1138</a></span>
<span class="normal"><a href="#__codelineno-0-1139">1139</a></span>
<span class="normal"><a href="#__codelineno-0-1140">1140</a></span>
<span class="normal"><a href="#__codelineno-0-1141">1141</a></span>
<span class="normal"><a href="#__codelineno-0-1142">1142</a></span>
<span class="normal"><a href="#__codelineno-0-1143">1143</a></span>
<span class="normal"><a href="#__codelineno-0-1144">1144</a></span>
<span class="normal"><a href="#__codelineno-0-1145">1145</a></span>
<span class="normal"><a href="#__codelineno-0-1146">1146</a></span>
<span class="normal"><a href="#__codelineno-0-1147">1147</a></span>
<span class="normal"><a href="#__codelineno-0-1148">1148</a></span>
<span class="normal"><a href="#__codelineno-0-1149">1149</a></span>
<span class="normal"><a href="#__codelineno-0-1150">1150</a></span>
<span class="normal"><a href="#__codelineno-0-1151">1151</a></span>
<span class="normal"><a href="#__codelineno-0-1152">1152</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1055" name="__codelineno-0-1055"></a><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
<a id="__codelineno-0-1056" name="__codelineno-0-1056"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1057" name="__codelineno-0-1057"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1058" name="__codelineno-0-1058"></a>    <span class="n">pred_type</span><span class="p">:</span> <span class="n">PredType</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">,</span>
<a id="__codelineno-0-1059" name="__codelineno-0-1059"></a>    <span class="n">joint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1060" name="__codelineno-0-1060"></a>    <span class="n">link_approx</span><span class="p">:</span> <span class="n">LinkApprox</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">PROBIT</span><span class="p">,</span>
<a id="__codelineno-0-1061" name="__codelineno-0-1061"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-1062" name="__codelineno-0-1062"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1063" name="__codelineno-0-1063"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1064" name="__codelineno-0-1064"></a>    <span class="n">fitting</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1065" name="__codelineno-0-1065"></a>    <span class="o">**</span><span class="n">model_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1066" name="__codelineno-0-1066"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-1067" name="__codelineno-0-1067"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the posterior predictive on input data `x`.</span>
<a id="__codelineno-0-1068" name="__codelineno-0-1068"></a>
<a id="__codelineno-0-1069" name="__codelineno-0-1069"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1070" name="__codelineno-0-1070"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1071" name="__codelineno-0-1071"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-1072" name="__codelineno-0-1072"></a><span class="sd">        `(batch_size, input_shape)` if tensor. If MutableMapping, must contain</span>
<a id="__codelineno-0-1073" name="__codelineno-0-1073"></a><span class="sd">        the said tensor.</span>
<a id="__codelineno-0-1074" name="__codelineno-0-1074"></a>
<a id="__codelineno-0-1075" name="__codelineno-0-1075"></a><span class="sd">    pred_type : {&#39;glm&#39;, &#39;nn&#39;}, default=&#39;glm&#39;</span>
<a id="__codelineno-0-1076" name="__codelineno-0-1076"></a><span class="sd">        type of posterior predictive, linearized GLM predictive or neural</span>
<a id="__codelineno-0-1077" name="__codelineno-0-1077"></a><span class="sd">        network sampling predictive. The GLM predictive is consistent with</span>
<a id="__codelineno-0-1078" name="__codelineno-0-1078"></a><span class="sd">        the curvature approximations used here. When Laplace is done only</span>
<a id="__codelineno-0-1079" name="__codelineno-0-1079"></a><span class="sd">        on subset of parameters (i.e. some grad are disabled),</span>
<a id="__codelineno-0-1080" name="__codelineno-0-1080"></a><span class="sd">        only `nn` predictive is supported.</span>
<a id="__codelineno-0-1081" name="__codelineno-0-1081"></a>
<a id="__codelineno-0-1082" name="__codelineno-0-1082"></a><span class="sd">    link_approx : {&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;}</span>
<a id="__codelineno-0-1083" name="__codelineno-0-1083"></a><span class="sd">        how to approximate the classification link function for the `&#39;glm&#39;`.</span>
<a id="__codelineno-0-1084" name="__codelineno-0-1084"></a><span class="sd">        For `pred_type=&#39;nn&#39;`, only &#39;mc&#39; is possible.</span>
<a id="__codelineno-0-1085" name="__codelineno-0-1085"></a>
<a id="__codelineno-0-1086" name="__codelineno-0-1086"></a><span class="sd">    joint : bool</span>
<a id="__codelineno-0-1087" name="__codelineno-0-1087"></a><span class="sd">        Whether to output a joint predictive distribution in regression with</span>
<a id="__codelineno-0-1088" name="__codelineno-0-1088"></a><span class="sd">        `pred_type=&#39;glm&#39;`. If set to `True`, the predictive distribution</span>
<a id="__codelineno-0-1089" name="__codelineno-0-1089"></a><span class="sd">        has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).</span>
<a id="__codelineno-0-1090" name="__codelineno-0-1090"></a><span class="sd">        If `False`, then only outputs the marginal predictive distribution.</span>
<a id="__codelineno-0-1091" name="__codelineno-0-1091"></a><span class="sd">        Only available for regression and GLM predictive.</span>
<a id="__codelineno-0-1092" name="__codelineno-0-1092"></a>
<a id="__codelineno-0-1093" name="__codelineno-0-1093"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-1094" name="__codelineno-0-1094"></a><span class="sd">        number of samples for `link_approx=&#39;mc&#39;`.</span>
<a id="__codelineno-0-1095" name="__codelineno-0-1095"></a>
<a id="__codelineno-0-1096" name="__codelineno-0-1096"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-1097" name="__codelineno-0-1097"></a><span class="sd">        whether to use a diagonalized posterior predictive on the outputs.</span>
<a id="__codelineno-0-1098" name="__codelineno-0-1098"></a><span class="sd">        Only works for `pred_type=&#39;glm&#39;` when `joint=False` in regression.</span>
<a id="__codelineno-0-1099" name="__codelineno-0-1099"></a><span class="sd">        In the case of last-layer Laplace with a diagonal or Kron Hessian,</span>
<a id="__codelineno-0-1100" name="__codelineno-0-1100"></a><span class="sd">        setting this to `True` makes computation much(!) faster for large</span>
<a id="__codelineno-0-1101" name="__codelineno-0-1101"></a><span class="sd">        number of outputs.</span>
<a id="__codelineno-0-1102" name="__codelineno-0-1102"></a>
<a id="__codelineno-0-1103" name="__codelineno-0-1103"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1104" name="__codelineno-0-1104"></a><span class="sd">        random number generator to control the samples (if sampling used).</span>
<a id="__codelineno-0-1105" name="__codelineno-0-1105"></a>
<a id="__codelineno-0-1106" name="__codelineno-0-1106"></a><span class="sd">    fitting : bool, default=False</span>
<a id="__codelineno-0-1107" name="__codelineno-0-1107"></a><span class="sd">        whether or not this predictive call is done during fitting. Only useful for</span>
<a id="__codelineno-0-1108" name="__codelineno-0-1108"></a><span class="sd">        reward modeling: the likelihood is set to `&quot;regression&quot;` when `False` and</span>
<a id="__codelineno-0-1109" name="__codelineno-0-1109"></a><span class="sd">        `&quot;classification&quot;` when `True`.</span>
<a id="__codelineno-0-1110" name="__codelineno-0-1110"></a>
<a id="__codelineno-0-1111" name="__codelineno-0-1111"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1112" name="__codelineno-0-1112"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1113" name="__codelineno-0-1113"></a><span class="sd">    predictive: torch.Tensor or tuple[torch.Tensor]</span>
<a id="__codelineno-0-1114" name="__codelineno-0-1114"></a><span class="sd">        For `likelihood=&#39;classification&#39;`, a torch.Tensor is returned with</span>
<a id="__codelineno-0-1115" name="__codelineno-0-1115"></a><span class="sd">        a distribution over classes (similar to a Softmax).</span>
<a id="__codelineno-0-1116" name="__codelineno-0-1116"></a><span class="sd">        For `likelihood=&#39;regression&#39;`, a tuple of torch.Tensor is returned</span>
<a id="__codelineno-0-1117" name="__codelineno-0-1117"></a><span class="sd">        with the mean and the predictive variance.</span>
<a id="__codelineno-0-1118" name="__codelineno-0-1118"></a><span class="sd">        For `likelihood=&#39;regression&#39;` and `joint=True`, a tuple of torch.Tensor</span>
<a id="__codelineno-0-1119" name="__codelineno-0-1119"></a><span class="sd">        is returned with the mean and the predictive covariance.</span>
<a id="__codelineno-0-1120" name="__codelineno-0-1120"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1121" name="__codelineno-0-1121"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">pred</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">PredType</span><span class="p">]:</span>
<a id="__codelineno-0-1122" name="__codelineno-0-1122"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only glm and nn supported as prediction types.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1123" name="__codelineno-0-1123"></a>
<a id="__codelineno-0-1124" name="__codelineno-0-1124"></a>    <span class="k">if</span> <span class="n">link_approx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">la</span> <span class="k">for</span> <span class="n">la</span> <span class="ow">in</span> <span class="n">LinkApprox</span><span class="p">]:</span>
<a id="__codelineno-0-1125" name="__codelineno-0-1125"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported link approximation </span><span class="si">{</span><span class="n">link_approx</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1126" name="__codelineno-0-1126"></a>
<a id="__codelineno-0-1127" name="__codelineno-0-1127"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">NN</span> <span class="ow">and</span> <span class="n">link_approx</span> <span class="o">!=</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">MC</span><span class="p">:</span>
<a id="__codelineno-0-1128" name="__codelineno-0-1128"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-1129" name="__codelineno-0-1129"></a>            <span class="s2">&quot;Only mc link approximation is supported for nn prediction type.&quot;</span>
<a id="__codelineno-0-1130" name="__codelineno-0-1130"></a>        <span class="p">)</span>
<a id="__codelineno-0-1131" name="__codelineno-0-1131"></a>
<a id="__codelineno-0-1132" name="__codelineno-0-1132"></a>    <span class="k">if</span> <span class="n">generator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1133" name="__codelineno-0-1133"></a>        <span class="k">if</span> <span class="p">(</span>
<a id="__codelineno-0-1134" name="__codelineno-0-1134"></a>            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">)</span>
<a id="__codelineno-0-1135" name="__codelineno-0-1135"></a>            <span class="ow">or</span> <span class="n">generator</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>
<a id="__codelineno-0-1136" name="__codelineno-0-1136"></a>        <span class="p">):</span>
<a id="__codelineno-0-1137" name="__codelineno-0-1137"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid random generator (check type and device).&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1138" name="__codelineno-0-1138"></a>
<a id="__codelineno-0-1139" name="__codelineno-0-1139"></a>    <span class="n">likelihood</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span>
<a id="__codelineno-0-1140" name="__codelineno-0-1140"></a>    <span class="k">if</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REWARD_MODELING</span><span class="p">:</span>
<a id="__codelineno-0-1141" name="__codelineno-0-1141"></a>        <span class="n">likelihood</span> <span class="o">=</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">CLASSIFICATION</span> <span class="k">if</span> <span class="n">fitting</span> <span class="k">else</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span>
<a id="__codelineno-0-1142" name="__codelineno-0-1142"></a>
<a id="__codelineno-0-1143" name="__codelineno-0-1143"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">:</span>
<a id="__codelineno-0-1144" name="__codelineno-0-1144"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_forward_call</span><span class="p">(</span>
<a id="__codelineno-0-1145" name="__codelineno-0-1145"></a>            <span class="n">x</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">joint</span><span class="p">,</span> <span class="n">link_approx</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span>
<a id="__codelineno-0-1146" name="__codelineno-0-1146"></a>        <span class="p">)</span>
<a id="__codelineno-0-1147" name="__codelineno-0-1147"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1148" name="__codelineno-0-1148"></a>        <span class="k">if</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-1149" name="__codelineno-0-1149"></a>            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_predictive_samples</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
<a id="__codelineno-0-1150" name="__codelineno-0-1150"></a>            <span class="k">return</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">samples</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-1151" name="__codelineno-0-1151"></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># classification; the average is computed online</span>
<a id="__codelineno-0-1152" name="__codelineno-0-1152"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_predictive_classification</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.KronLLLaplace._glm_forward_call" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">_glm_forward_call</span>


<a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">_glm_forward_call</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(likelihood)">likelihood</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(joint)">joint</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(link_approx)">link_approx</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox" href="../enums/#laplace.utils.enums.LinkApprox">LinkApprox</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox.PROBIT" href="../enums/#laplace.utils.enums.LinkApprox.PROBIT">PROBIT</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the posterior predictive on input data <code>x</code> for "glm" pred type.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_forward_call(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p><code>(batch_size, input_shape)</code> if tensor. If MutableMapping, must contain
the said tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_forward_call(likelihood)" class="doc doc-heading doc-heading-parameter">              <b><code>likelihood</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(likelihood)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a> in {&#39;classification&#39;, &#39;regression&#39;, &#39;reward_modeling&#39;}</code>)
          –
          <div class="doc-md-description">
            <p>determines the log likelihood Hessian approximation.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_forward_call(link_approx)" class="doc doc-heading doc-heading-parameter">              <b><code>link_approx</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(link_approx)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;)</code>, default:
                  <code>&#39;mc&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>how to approximate the classification link function for the <code>'glm'</code>.
For <code>pred_type='nn'</code>, only 'mc' is possible.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_forward_call(joint)" class="doc doc-heading doc-heading-parameter">              <b><code>joint</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(joint)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to output a joint predictive distribution in regression with
<code>pred_type='glm'</code>. If set to <code>True</code>, the predictive distribution
has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).
If <code>False</code>, then only outputs the marginal predictive distribution.
Only available for regression and GLM predictive.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_forward_call(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples for <code>link_approx='mc'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_forward_call(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_forward_call(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized posterior predictive on the outputs.
Only works for <code>pred_type='glm'</code> and <code>link_approx='mc'</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>predictive</code></b> (              <code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<span title="torch.Tensor">Tensor</span>]</code>
)          –
          <div class="doc-md-description">
            <p>For <code>likelihood='classification'</code>, a torch.Tensor is returned with
a distribution over classes (similar to a Softmax).
For <code>likelihood='regression'</code>, a tuple of torch.Tensor is returned
with the mean and the predictive variance.
For <code>likelihood='regression'</code> and <code>joint=True</code>, a tuple of torch.Tensor
is returned with the mean and the predictive covariance.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-598">598</a></span>
<span class="normal"><a href="#__codelineno-0-599">599</a></span>
<span class="normal"><a href="#__codelineno-0-600">600</a></span>
<span class="normal"><a href="#__codelineno-0-601">601</a></span>
<span class="normal"><a href="#__codelineno-0-602">602</a></span>
<span class="normal"><a href="#__codelineno-0-603">603</a></span>
<span class="normal"><a href="#__codelineno-0-604">604</a></span>
<span class="normal"><a href="#__codelineno-0-605">605</a></span>
<span class="normal"><a href="#__codelineno-0-606">606</a></span>
<span class="normal"><a href="#__codelineno-0-607">607</a></span>
<span class="normal"><a href="#__codelineno-0-608">608</a></span>
<span class="normal"><a href="#__codelineno-0-609">609</a></span>
<span class="normal"><a href="#__codelineno-0-610">610</a></span>
<span class="normal"><a href="#__codelineno-0-611">611</a></span>
<span class="normal"><a href="#__codelineno-0-612">612</a></span>
<span class="normal"><a href="#__codelineno-0-613">613</a></span>
<span class="normal"><a href="#__codelineno-0-614">614</a></span>
<span class="normal"><a href="#__codelineno-0-615">615</a></span>
<span class="normal"><a href="#__codelineno-0-616">616</a></span>
<span class="normal"><a href="#__codelineno-0-617">617</a></span>
<span class="normal"><a href="#__codelineno-0-618">618</a></span>
<span class="normal"><a href="#__codelineno-0-619">619</a></span>
<span class="normal"><a href="#__codelineno-0-620">620</a></span>
<span class="normal"><a href="#__codelineno-0-621">621</a></span>
<span class="normal"><a href="#__codelineno-0-622">622</a></span>
<span class="normal"><a href="#__codelineno-0-623">623</a></span>
<span class="normal"><a href="#__codelineno-0-624">624</a></span>
<span class="normal"><a href="#__codelineno-0-625">625</a></span>
<span class="normal"><a href="#__codelineno-0-626">626</a></span>
<span class="normal"><a href="#__codelineno-0-627">627</a></span>
<span class="normal"><a href="#__codelineno-0-628">628</a></span>
<span class="normal"><a href="#__codelineno-0-629">629</a></span>
<span class="normal"><a href="#__codelineno-0-630">630</a></span>
<span class="normal"><a href="#__codelineno-0-631">631</a></span>
<span class="normal"><a href="#__codelineno-0-632">632</a></span>
<span class="normal"><a href="#__codelineno-0-633">633</a></span>
<span class="normal"><a href="#__codelineno-0-634">634</a></span>
<span class="normal"><a href="#__codelineno-0-635">635</a></span>
<span class="normal"><a href="#__codelineno-0-636">636</a></span>
<span class="normal"><a href="#__codelineno-0-637">637</a></span>
<span class="normal"><a href="#__codelineno-0-638">638</a></span>
<span class="normal"><a href="#__codelineno-0-639">639</a></span>
<span class="normal"><a href="#__codelineno-0-640">640</a></span>
<span class="normal"><a href="#__codelineno-0-641">641</a></span>
<span class="normal"><a href="#__codelineno-0-642">642</a></span>
<span class="normal"><a href="#__codelineno-0-643">643</a></span>
<span class="normal"><a href="#__codelineno-0-644">644</a></span>
<span class="normal"><a href="#__codelineno-0-645">645</a></span>
<span class="normal"><a href="#__codelineno-0-646">646</a></span>
<span class="normal"><a href="#__codelineno-0-647">647</a></span>
<span class="normal"><a href="#__codelineno-0-648">648</a></span>
<span class="normal"><a href="#__codelineno-0-649">649</a></span>
<span class="normal"><a href="#__codelineno-0-650">650</a></span>
<span class="normal"><a href="#__codelineno-0-651">651</a></span>
<span class="normal"><a href="#__codelineno-0-652">652</a></span>
<span class="normal"><a href="#__codelineno-0-653">653</a></span>
<span class="normal"><a href="#__codelineno-0-654">654</a></span>
<span class="normal"><a href="#__codelineno-0-655">655</a></span>
<span class="normal"><a href="#__codelineno-0-656">656</a></span>
<span class="normal"><a href="#__codelineno-0-657">657</a></span>
<span class="normal"><a href="#__codelineno-0-658">658</a></span>
<span class="normal"><a href="#__codelineno-0-659">659</a></span>
<span class="normal"><a href="#__codelineno-0-660">660</a></span>
<span class="normal"><a href="#__codelineno-0-661">661</a></span>
<span class="normal"><a href="#__codelineno-0-662">662</a></span>
<span class="normal"><a href="#__codelineno-0-663">663</a></span>
<span class="normal"><a href="#__codelineno-0-664">664</a></span>
<span class="normal"><a href="#__codelineno-0-665">665</a></span>
<span class="normal"><a href="#__codelineno-0-666">666</a></span>
<span class="normal"><a href="#__codelineno-0-667">667</a></span>
<span class="normal"><a href="#__codelineno-0-668">668</a></span>
<span class="normal"><a href="#__codelineno-0-669">669</a></span>
<span class="normal"><a href="#__codelineno-0-670">670</a></span>
<span class="normal"><a href="#__codelineno-0-671">671</a></span>
<span class="normal"><a href="#__codelineno-0-672">672</a></span>
<span class="normal"><a href="#__codelineno-0-673">673</a></span>
<span class="normal"><a href="#__codelineno-0-674">674</a></span>
<span class="normal"><a href="#__codelineno-0-675">675</a></span>
<span class="normal"><a href="#__codelineno-0-676">676</a></span>
<span class="normal"><a href="#__codelineno-0-677">677</a></span>
<span class="normal"><a href="#__codelineno-0-678">678</a></span>
<span class="normal"><a href="#__codelineno-0-679">679</a></span>
<span class="normal"><a href="#__codelineno-0-680">680</a></span>
<span class="normal"><a href="#__codelineno-0-681">681</a></span>
<span class="normal"><a href="#__codelineno-0-682">682</a></span>
<span class="normal"><a href="#__codelineno-0-683">683</a></span>
<span class="normal"><a href="#__codelineno-0-684">684</a></span>
<span class="normal"><a href="#__codelineno-0-685">685</a></span>
<span class="normal"><a href="#__codelineno-0-686">686</a></span>
<span class="normal"><a href="#__codelineno-0-687">687</a></span>
<span class="normal"><a href="#__codelineno-0-688">688</a></span>
<span class="normal"><a href="#__codelineno-0-689">689</a></span>
<span class="normal"><a href="#__codelineno-0-690">690</a></span>
<span class="normal"><a href="#__codelineno-0-691">691</a></span>
<span class="normal"><a href="#__codelineno-0-692">692</a></span>
<span class="normal"><a href="#__codelineno-0-693">693</a></span>
<span class="normal"><a href="#__codelineno-0-694">694</a></span>
<span class="normal"><a href="#__codelineno-0-695">695</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-598" name="__codelineno-0-598"></a><span class="k">def</span> <span class="nf">_glm_forward_call</span><span class="p">(</span>
<a id="__codelineno-0-599" name="__codelineno-0-599"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-600" name="__codelineno-0-600"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">,</span>
<a id="__codelineno-0-601" name="__codelineno-0-601"></a>    <span class="n">likelihood</span><span class="p">:</span> <span class="n">Likelihood</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-602" name="__codelineno-0-602"></a>    <span class="n">joint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-603" name="__codelineno-0-603"></a>    <span class="n">link_approx</span><span class="p">:</span> <span class="n">LinkApprox</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">PROBIT</span><span class="p">,</span>
<a id="__codelineno-0-604" name="__codelineno-0-604"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-605" name="__codelineno-0-605"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-606" name="__codelineno-0-606"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-607" name="__codelineno-0-607"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the posterior predictive on input data `x` for &quot;glm&quot; pred type.</span>
<a id="__codelineno-0-608" name="__codelineno-0-608"></a>
<a id="__codelineno-0-609" name="__codelineno-0-609"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-610" name="__codelineno-0-610"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-611" name="__codelineno-0-611"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-612" name="__codelineno-0-612"></a><span class="sd">        `(batch_size, input_shape)` if tensor. If MutableMapping, must contain</span>
<a id="__codelineno-0-613" name="__codelineno-0-613"></a><span class="sd">        the said tensor.</span>
<a id="__codelineno-0-614" name="__codelineno-0-614"></a>
<a id="__codelineno-0-615" name="__codelineno-0-615"></a><span class="sd">    likelihood : Likelihood or str in {&#39;classification&#39;, &#39;regression&#39;, &#39;reward_modeling&#39;}</span>
<a id="__codelineno-0-616" name="__codelineno-0-616"></a><span class="sd">        determines the log likelihood Hessian approximation.</span>
<a id="__codelineno-0-617" name="__codelineno-0-617"></a>
<a id="__codelineno-0-618" name="__codelineno-0-618"></a><span class="sd">    link_approx : {&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;}</span>
<a id="__codelineno-0-619" name="__codelineno-0-619"></a><span class="sd">        how to approximate the classification link function for the `&#39;glm&#39;`.</span>
<a id="__codelineno-0-620" name="__codelineno-0-620"></a><span class="sd">        For `pred_type=&#39;nn&#39;`, only &#39;mc&#39; is possible.</span>
<a id="__codelineno-0-621" name="__codelineno-0-621"></a>
<a id="__codelineno-0-622" name="__codelineno-0-622"></a><span class="sd">    joint : bool</span>
<a id="__codelineno-0-623" name="__codelineno-0-623"></a><span class="sd">        Whether to output a joint predictive distribution in regression with</span>
<a id="__codelineno-0-624" name="__codelineno-0-624"></a><span class="sd">        `pred_type=&#39;glm&#39;`. If set to `True`, the predictive distribution</span>
<a id="__codelineno-0-625" name="__codelineno-0-625"></a><span class="sd">        has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).</span>
<a id="__codelineno-0-626" name="__codelineno-0-626"></a><span class="sd">        If `False`, then only outputs the marginal predictive distribution.</span>
<a id="__codelineno-0-627" name="__codelineno-0-627"></a><span class="sd">        Only available for regression and GLM predictive.</span>
<a id="__codelineno-0-628" name="__codelineno-0-628"></a>
<a id="__codelineno-0-629" name="__codelineno-0-629"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-630" name="__codelineno-0-630"></a><span class="sd">        number of samples for `link_approx=&#39;mc&#39;`.</span>
<a id="__codelineno-0-631" name="__codelineno-0-631"></a>
<a id="__codelineno-0-632" name="__codelineno-0-632"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-633" name="__codelineno-0-633"></a><span class="sd">        whether to use a diagonalized posterior predictive on the outputs.</span>
<a id="__codelineno-0-634" name="__codelineno-0-634"></a><span class="sd">        Only works for `pred_type=&#39;glm&#39;` and `link_approx=&#39;mc&#39;`.</span>
<a id="__codelineno-0-635" name="__codelineno-0-635"></a>
<a id="__codelineno-0-636" name="__codelineno-0-636"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-637" name="__codelineno-0-637"></a><span class="sd">    -------</span>
<a id="__codelineno-0-638" name="__codelineno-0-638"></a><span class="sd">    predictive: torch.Tensor or tuple[torch.Tensor]</span>
<a id="__codelineno-0-639" name="__codelineno-0-639"></a><span class="sd">        For `likelihood=&#39;classification&#39;`, a torch.Tensor is returned with</span>
<a id="__codelineno-0-640" name="__codelineno-0-640"></a><span class="sd">        a distribution over classes (similar to a Softmax).</span>
<a id="__codelineno-0-641" name="__codelineno-0-641"></a><span class="sd">        For `likelihood=&#39;regression&#39;`, a tuple of torch.Tensor is returned</span>
<a id="__codelineno-0-642" name="__codelineno-0-642"></a><span class="sd">        with the mean and the predictive variance.</span>
<a id="__codelineno-0-643" name="__codelineno-0-643"></a><span class="sd">        For `likelihood=&#39;regression&#39;` and `joint=True`, a tuple of torch.Tensor</span>
<a id="__codelineno-0-644" name="__codelineno-0-644"></a><span class="sd">        is returned with the mean and the predictive covariance.</span>
<a id="__codelineno-0-645" name="__codelineno-0-645"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-646" name="__codelineno-0-646"></a>    <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_distribution</span><span class="p">(</span>
<a id="__codelineno-0-647" name="__codelineno-0-647"></a>        <span class="n">x</span><span class="p">,</span> <span class="n">joint</span><span class="o">=</span><span class="n">joint</span> <span class="ow">and</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span>
<a id="__codelineno-0-648" name="__codelineno-0-648"></a>    <span class="p">)</span>
<a id="__codelineno-0-649" name="__codelineno-0-649"></a>
<a id="__codelineno-0-650" name="__codelineno-0-650"></a>    <span class="k">if</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-651" name="__codelineno-0-651"></a>        <span class="k">if</span> <span class="n">diagonal_output</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">joint</span><span class="p">:</span>
<a id="__codelineno-0-652" name="__codelineno-0-652"></a>            <span class="n">f_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_var</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-653" name="__codelineno-0-653"></a>        <span class="k">return</span> <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span>
<a id="__codelineno-0-654" name="__codelineno-0-654"></a>
<a id="__codelineno-0-655" name="__codelineno-0-655"></a>    <span class="k">if</span> <span class="n">link_approx</span> <span class="o">==</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">MC</span><span class="p">:</span>
<a id="__codelineno-0-656" name="__codelineno-0-656"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-657" name="__codelineno-0-657"></a>            <span class="n">f_mu</span><span class="p">,</span>
<a id="__codelineno-0-658" name="__codelineno-0-658"></a>            <span class="n">f_var</span><span class="p">,</span>
<a id="__codelineno-0-659" name="__codelineno-0-659"></a>            <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span>
<a id="__codelineno-0-660" name="__codelineno-0-660"></a>            <span class="n">diagonal_output</span><span class="o">=</span><span class="n">diagonal_output</span><span class="p">,</span>
<a id="__codelineno-0-661" name="__codelineno-0-661"></a>        <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-662" name="__codelineno-0-662"></a>    <span class="k">elif</span> <span class="n">link_approx</span> <span class="o">==</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">PROBIT</span><span class="p">:</span>
<a id="__codelineno-0-663" name="__codelineno-0-663"></a>        <span class="n">kappa</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">8</span> <span class="o">*</span> <span class="n">f_var</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<a id="__codelineno-0-664" name="__codelineno-0-664"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">kappa</span> <span class="o">*</span> <span class="n">f_mu</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-665" name="__codelineno-0-665"></a>    <span class="k">elif</span> <span class="s2">&quot;bridge&quot;</span> <span class="ow">in</span> <span class="n">link_approx</span><span class="p">:</span>
<a id="__codelineno-0-666" name="__codelineno-0-666"></a>        <span class="c1"># zero mean correction</span>
<a id="__codelineno-0-667" name="__codelineno-0-667"></a>        <span class="n">f_mu</span> <span class="o">-=</span> <span class="p">(</span>
<a id="__codelineno-0-668" name="__codelineno-0-668"></a>            <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-669" name="__codelineno-0-669"></a>            <span class="o">*</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-670" name="__codelineno-0-670"></a>            <span class="o">/</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-671" name="__codelineno-0-671"></a>        <span class="p">)</span>
<a id="__codelineno-0-672" name="__codelineno-0-672"></a>        <span class="n">f_var</span> <span class="o">-=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
<a id="__codelineno-0-673" name="__codelineno-0-673"></a>            <span class="s2">&quot;bi,bj-&gt;bij&quot;</span><span class="p">,</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-674" name="__codelineno-0-674"></a>        <span class="p">)</span> <span class="o">/</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-675" name="__codelineno-0-675"></a>
<a id="__codelineno-0-676" name="__codelineno-0-676"></a>        <span class="c1"># Laplace Bridge</span>
<a id="__codelineno-0-677" name="__codelineno-0-677"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-678" name="__codelineno-0-678"></a>        <span class="n">f_var_diag</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_var</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-679" name="__codelineno-0-679"></a>
<a id="__codelineno-0-680" name="__codelineno-0-680"></a>        <span class="c1"># optional: variance correction</span>
<a id="__codelineno-0-681" name="__codelineno-0-681"></a>        <span class="k">if</span> <span class="n">link_approx</span> <span class="o">==</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">BRIDGE_NORM</span><span class="p">:</span>
<a id="__codelineno-0-682" name="__codelineno-0-682"></a>            <span class="n">f_var_diag_mean</span> <span class="o">=</span> <span class="n">f_var_diag</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-683" name="__codelineno-0-683"></a>            <span class="n">f_var_diag_mean</span> <span class="o">/=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span>
<a id="__codelineno-0-684" name="__codelineno-0-684"></a>                <span class="p">[</span><span class="n">K</span> <span class="o">/</span> <span class="mi">2</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>
<a id="__codelineno-0-685" name="__codelineno-0-685"></a>            <span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
<a id="__codelineno-0-686" name="__codelineno-0-686"></a>            <span class="n">f_mu</span> <span class="o">/=</span> <span class="n">f_var_diag_mean</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-687" name="__codelineno-0-687"></a>            <span class="n">f_var_diag</span> <span class="o">/=</span> <span class="n">f_var_diag_mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-688" name="__codelineno-0-688"></a>
<a id="__codelineno-0-689" name="__codelineno-0-689"></a>        <span class="n">sum_exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">f_mu</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-690" name="__codelineno-0-690"></a>        <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">K</span> <span class="o">+</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">/</span> <span class="n">K</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sum_exp</span><span class="p">)</span> <span class="o">/</span> <span class="n">f_var_diag</span>
<a id="__codelineno-0-691" name="__codelineno-0-691"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">alpha</span> <span class="o">/</span> <span class="n">alpha</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">nan</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<a id="__codelineno-0-692" name="__codelineno-0-692"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-693" name="__codelineno-0-693"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-694" name="__codelineno-0-694"></a>            <span class="s2">&quot;Prediction path invalid. Check the likelihood, pred_type, link_approx combination!&quot;</span>
<a id="__codelineno-0-695" name="__codelineno-0-695"></a>        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.KronLLLaplace._glm_functional_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">_glm_functional_samples</span>


<a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">_glm_functional_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(f_mu)">f_mu</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(f_var)">f_var</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the posterior functional on input data <code>x</code> using "glm" prediction
type.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_functional_samples(f_mu)" class="doc doc-heading doc-heading-parameter">              <b><code>f_mu</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(f_mu)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive mean <code>(batch_size, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_functional_samples(f_var)" class="doc doc-heading doc-heading-parameter">              <b><code>f_var</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(f_var)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive covariances <code>(batch_size, output_shape, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_functional_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_functional_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_functional_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_functional_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-697">697</a></span>
<span class="normal"><a href="#__codelineno-0-698">698</a></span>
<span class="normal"><a href="#__codelineno-0-699">699</a></span>
<span class="normal"><a href="#__codelineno-0-700">700</a></span>
<span class="normal"><a href="#__codelineno-0-701">701</a></span>
<span class="normal"><a href="#__codelineno-0-702">702</a></span>
<span class="normal"><a href="#__codelineno-0-703">703</a></span>
<span class="normal"><a href="#__codelineno-0-704">704</a></span>
<span class="normal"><a href="#__codelineno-0-705">705</a></span>
<span class="normal"><a href="#__codelineno-0-706">706</a></span>
<span class="normal"><a href="#__codelineno-0-707">707</a></span>
<span class="normal"><a href="#__codelineno-0-708">708</a></span>
<span class="normal"><a href="#__codelineno-0-709">709</a></span>
<span class="normal"><a href="#__codelineno-0-710">710</a></span>
<span class="normal"><a href="#__codelineno-0-711">711</a></span>
<span class="normal"><a href="#__codelineno-0-712">712</a></span>
<span class="normal"><a href="#__codelineno-0-713">713</a></span>
<span class="normal"><a href="#__codelineno-0-714">714</a></span>
<span class="normal"><a href="#__codelineno-0-715">715</a></span>
<span class="normal"><a href="#__codelineno-0-716">716</a></span>
<span class="normal"><a href="#__codelineno-0-717">717</a></span>
<span class="normal"><a href="#__codelineno-0-718">718</a></span>
<span class="normal"><a href="#__codelineno-0-719">719</a></span>
<span class="normal"><a href="#__codelineno-0-720">720</a></span>
<span class="normal"><a href="#__codelineno-0-721">721</a></span>
<span class="normal"><a href="#__codelineno-0-722">722</a></span>
<span class="normal"><a href="#__codelineno-0-723">723</a></span>
<span class="normal"><a href="#__codelineno-0-724">724</a></span>
<span class="normal"><a href="#__codelineno-0-725">725</a></span>
<span class="normal"><a href="#__codelineno-0-726">726</a></span>
<span class="normal"><a href="#__codelineno-0-727">727</a></span>
<span class="normal"><a href="#__codelineno-0-728">728</a></span>
<span class="normal"><a href="#__codelineno-0-729">729</a></span>
<span class="normal"><a href="#__codelineno-0-730">730</a></span>
<span class="normal"><a href="#__codelineno-0-731">731</a></span>
<span class="normal"><a href="#__codelineno-0-732">732</a></span>
<span class="normal"><a href="#__codelineno-0-733">733</a></span>
<span class="normal"><a href="#__codelineno-0-734">734</a></span>
<span class="normal"><a href="#__codelineno-0-735">735</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-697" name="__codelineno-0-697"></a><span class="k">def</span> <span class="nf">_glm_functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-698" name="__codelineno-0-698"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-699" name="__codelineno-0-699"></a>    <span class="n">f_mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-700" name="__codelineno-0-700"></a>    <span class="n">f_var</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-701" name="__codelineno-0-701"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-702" name="__codelineno-0-702"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-703" name="__codelineno-0-703"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-704" name="__codelineno-0-704"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-705" name="__codelineno-0-705"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the posterior functional on input data `x` using &quot;glm&quot; prediction</span>
<a id="__codelineno-0-706" name="__codelineno-0-706"></a><span class="sd">    type.</span>
<a id="__codelineno-0-707" name="__codelineno-0-707"></a>
<a id="__codelineno-0-708" name="__codelineno-0-708"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-709" name="__codelineno-0-709"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-710" name="__codelineno-0-710"></a><span class="sd">    f_mu : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-711" name="__codelineno-0-711"></a><span class="sd">        glm predictive mean `(batch_size, output_shape)`</span>
<a id="__codelineno-0-712" name="__codelineno-0-712"></a>
<a id="__codelineno-0-713" name="__codelineno-0-713"></a><span class="sd">    f_var : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-714" name="__codelineno-0-714"></a><span class="sd">        glm predictive covariances `(batch_size, output_shape, output_shape)`</span>
<a id="__codelineno-0-715" name="__codelineno-0-715"></a>
<a id="__codelineno-0-716" name="__codelineno-0-716"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-717" name="__codelineno-0-717"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-718" name="__codelineno-0-718"></a>
<a id="__codelineno-0-719" name="__codelineno-0-719"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-720" name="__codelineno-0-720"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-721" name="__codelineno-0-721"></a>
<a id="__codelineno-0-722" name="__codelineno-0-722"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-723" name="__codelineno-0-723"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-724" name="__codelineno-0-724"></a>
<a id="__codelineno-0-725" name="__codelineno-0-725"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-726" name="__codelineno-0-726"></a><span class="sd">    -------</span>
<a id="__codelineno-0-727" name="__codelineno-0-727"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-728" name="__codelineno-0-728"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-729" name="__codelineno-0-729"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-730" name="__codelineno-0-730"></a>    <span class="k">assert</span> <span class="n">f_var</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">f_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<a id="__codelineno-0-731" name="__codelineno-0-731"></a>
<a id="__codelineno-0-732" name="__codelineno-0-732"></a>    <span class="k">if</span> <span class="n">diagonal_output</span><span class="p">:</span>
<a id="__codelineno-0-733" name="__codelineno-0-733"></a>        <span class="n">f_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_var</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-734" name="__codelineno-0-734"></a>
<a id="__codelineno-0-735" name="__codelineno-0-735"></a>    <span class="k">return</span> <span class="n">normal_samples</span><span class="p">(</span><span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">generator</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.KronLLLaplace._glm_predictive_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">_glm_predictive_samples</span>


<a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">_glm_predictive_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(f_mu)">f_mu</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(f_var)">f_var</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the posterior predictive on input data <code>x</code> using "glm" prediction
type. I.e., the inverse-link function correponding to the likelihood is applied
on top of the functional sample.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_predictive_samples(f_mu)" class="doc doc-heading doc-heading-parameter">              <b><code>f_mu</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(f_mu)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive mean <code>(batch_size, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_predictive_samples(f_var)" class="doc doc-heading doc-heading-parameter">              <b><code>f_var</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(f_var)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive covariances <code>(batch_size, output_shape, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_predictive_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_predictive_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace._glm_predictive_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.KronLLLaplace._glm_predictive_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-737">737</a></span>
<span class="normal"><a href="#__codelineno-0-738">738</a></span>
<span class="normal"><a href="#__codelineno-0-739">739</a></span>
<span class="normal"><a href="#__codelineno-0-740">740</a></span>
<span class="normal"><a href="#__codelineno-0-741">741</a></span>
<span class="normal"><a href="#__codelineno-0-742">742</a></span>
<span class="normal"><a href="#__codelineno-0-743">743</a></span>
<span class="normal"><a href="#__codelineno-0-744">744</a></span>
<span class="normal"><a href="#__codelineno-0-745">745</a></span>
<span class="normal"><a href="#__codelineno-0-746">746</a></span>
<span class="normal"><a href="#__codelineno-0-747">747</a></span>
<span class="normal"><a href="#__codelineno-0-748">748</a></span>
<span class="normal"><a href="#__codelineno-0-749">749</a></span>
<span class="normal"><a href="#__codelineno-0-750">750</a></span>
<span class="normal"><a href="#__codelineno-0-751">751</a></span>
<span class="normal"><a href="#__codelineno-0-752">752</a></span>
<span class="normal"><a href="#__codelineno-0-753">753</a></span>
<span class="normal"><a href="#__codelineno-0-754">754</a></span>
<span class="normal"><a href="#__codelineno-0-755">755</a></span>
<span class="normal"><a href="#__codelineno-0-756">756</a></span>
<span class="normal"><a href="#__codelineno-0-757">757</a></span>
<span class="normal"><a href="#__codelineno-0-758">758</a></span>
<span class="normal"><a href="#__codelineno-0-759">759</a></span>
<span class="normal"><a href="#__codelineno-0-760">760</a></span>
<span class="normal"><a href="#__codelineno-0-761">761</a></span>
<span class="normal"><a href="#__codelineno-0-762">762</a></span>
<span class="normal"><a href="#__codelineno-0-763">763</a></span>
<span class="normal"><a href="#__codelineno-0-764">764</a></span>
<span class="normal"><a href="#__codelineno-0-765">765</a></span>
<span class="normal"><a href="#__codelineno-0-766">766</a></span>
<span class="normal"><a href="#__codelineno-0-767">767</a></span>
<span class="normal"><a href="#__codelineno-0-768">768</a></span>
<span class="normal"><a href="#__codelineno-0-769">769</a></span>
<span class="normal"><a href="#__codelineno-0-770">770</a></span>
<span class="normal"><a href="#__codelineno-0-771">771</a></span>
<span class="normal"><a href="#__codelineno-0-772">772</a></span>
<span class="normal"><a href="#__codelineno-0-773">773</a></span>
<span class="normal"><a href="#__codelineno-0-774">774</a></span>
<span class="normal"><a href="#__codelineno-0-775">775</a></span>
<span class="normal"><a href="#__codelineno-0-776">776</a></span>
<span class="normal"><a href="#__codelineno-0-777">777</a></span>
<span class="normal"><a href="#__codelineno-0-778">778</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-737" name="__codelineno-0-737"></a><span class="k">def</span> <span class="nf">_glm_predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-738" name="__codelineno-0-738"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-739" name="__codelineno-0-739"></a>    <span class="n">f_mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-740" name="__codelineno-0-740"></a>    <span class="n">f_var</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-741" name="__codelineno-0-741"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-742" name="__codelineno-0-742"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-743" name="__codelineno-0-743"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-744" name="__codelineno-0-744"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-745" name="__codelineno-0-745"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the posterior predictive on input data `x` using &quot;glm&quot; prediction</span>
<a id="__codelineno-0-746" name="__codelineno-0-746"></a><span class="sd">    type. I.e., the inverse-link function correponding to the likelihood is applied</span>
<a id="__codelineno-0-747" name="__codelineno-0-747"></a><span class="sd">    on top of the functional sample.</span>
<a id="__codelineno-0-748" name="__codelineno-0-748"></a>
<a id="__codelineno-0-749" name="__codelineno-0-749"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-750" name="__codelineno-0-750"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-751" name="__codelineno-0-751"></a><span class="sd">    f_mu : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-752" name="__codelineno-0-752"></a><span class="sd">        glm predictive mean `(batch_size, output_shape)`</span>
<a id="__codelineno-0-753" name="__codelineno-0-753"></a>
<a id="__codelineno-0-754" name="__codelineno-0-754"></a><span class="sd">    f_var : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-755" name="__codelineno-0-755"></a><span class="sd">        glm predictive covariances `(batch_size, output_shape, output_shape)`</span>
<a id="__codelineno-0-756" name="__codelineno-0-756"></a>
<a id="__codelineno-0-757" name="__codelineno-0-757"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-758" name="__codelineno-0-758"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-759" name="__codelineno-0-759"></a>
<a id="__codelineno-0-760" name="__codelineno-0-760"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-761" name="__codelineno-0-761"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-762" name="__codelineno-0-762"></a>
<a id="__codelineno-0-763" name="__codelineno-0-763"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-764" name="__codelineno-0-764"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-765" name="__codelineno-0-765"></a>
<a id="__codelineno-0-766" name="__codelineno-0-766"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-767" name="__codelineno-0-767"></a><span class="sd">    -------</span>
<a id="__codelineno-0-768" name="__codelineno-0-768"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-769" name="__codelineno-0-769"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-770" name="__codelineno-0-770"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-771" name="__codelineno-0-771"></a>    <span class="n">f_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-772" name="__codelineno-0-772"></a>        <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span><span class="p">,</span> <span class="n">generator</span>
<a id="__codelineno-0-773" name="__codelineno-0-773"></a>    <span class="p">)</span>
<a id="__codelineno-0-774" name="__codelineno-0-774"></a>
<a id="__codelineno-0-775" name="__codelineno-0-775"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-776" name="__codelineno-0-776"></a>        <span class="k">return</span> <span class="n">f_samples</span>
<a id="__codelineno-0-777" name="__codelineno-0-777"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-778" name="__codelineno-0-778"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">f_samples</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.KronLLLaplace.log_prob" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">log_prob</span>


<a href="#laplace.lllaplace.KronLLLaplace.log_prob" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">log_prob</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.log_prob(value)">value</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.log_prob(normalized)">normalized</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the log probability under the (current) Laplace approximation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.log_prob(value)" class="doc doc-heading doc-heading-parameter">              <b><code>value</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.log_prob(value)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.log_prob(normalized)" class="doc doc-heading doc-heading-parameter">              <b><code>normalized</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.log_prob(normalized)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>whether to return log of a properly normalized Gaussian or just the
terms that depend on <code>value</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_prob</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-996"> 996</a></span>
<span class="normal"><a href="#__codelineno-0-997"> 997</a></span>
<span class="normal"><a href="#__codelineno-0-998"> 998</a></span>
<span class="normal"><a href="#__codelineno-0-999"> 999</a></span>
<span class="normal"><a href="#__codelineno-0-1000">1000</a></span>
<span class="normal"><a href="#__codelineno-0-1001">1001</a></span>
<span class="normal"><a href="#__codelineno-0-1002">1002</a></span>
<span class="normal"><a href="#__codelineno-0-1003">1003</a></span>
<span class="normal"><a href="#__codelineno-0-1004">1004</a></span>
<span class="normal"><a href="#__codelineno-0-1005">1005</a></span>
<span class="normal"><a href="#__codelineno-0-1006">1006</a></span>
<span class="normal"><a href="#__codelineno-0-1007">1007</a></span>
<span class="normal"><a href="#__codelineno-0-1008">1008</a></span>
<span class="normal"><a href="#__codelineno-0-1009">1009</a></span>
<span class="normal"><a href="#__codelineno-0-1010">1010</a></span>
<span class="normal"><a href="#__codelineno-0-1011">1011</a></span>
<span class="normal"><a href="#__codelineno-0-1012">1012</a></span>
<span class="normal"><a href="#__codelineno-0-1013">1013</a></span>
<span class="normal"><a href="#__codelineno-0-1014">1014</a></span>
<span class="normal"><a href="#__codelineno-0-1015">1015</a></span>
<span class="normal"><a href="#__codelineno-0-1016">1016</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-996" name="__codelineno-0-996"></a><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">normalized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-997" name="__codelineno-0-997"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the log probability under the (current) Laplace approximation.</span>
<a id="__codelineno-0-998" name="__codelineno-0-998"></a>
<a id="__codelineno-0-999" name="__codelineno-0-999"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1000" name="__codelineno-0-1000"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1001" name="__codelineno-0-1001"></a><span class="sd">    value: torch.Tensor</span>
<a id="__codelineno-0-1002" name="__codelineno-0-1002"></a><span class="sd">    normalized : bool, default=True</span>
<a id="__codelineno-0-1003" name="__codelineno-0-1003"></a><span class="sd">        whether to return log of a properly normalized Gaussian or just the</span>
<a id="__codelineno-0-1004" name="__codelineno-0-1004"></a><span class="sd">        terms that depend on `value`.</span>
<a id="__codelineno-0-1005" name="__codelineno-0-1005"></a>
<a id="__codelineno-0-1006" name="__codelineno-0-1006"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1007" name="__codelineno-0-1007"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1008" name="__codelineno-0-1008"></a><span class="sd">    log_prob : torch.Tensor</span>
<a id="__codelineno-0-1009" name="__codelineno-0-1009"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1010" name="__codelineno-0-1010"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">normalized</span><span class="p">:</span>
<a id="__codelineno-0-1011" name="__codelineno-0-1011"></a>        <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">square_norm</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-0-1012" name="__codelineno-0-1012"></a>    <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-1013" name="__codelineno-0-1013"></a>        <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">n_params</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">pi</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_det_posterior_precision</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-0-1014" name="__codelineno-0-1014"></a>    <span class="p">)</span>
<a id="__codelineno-0-1015" name="__codelineno-0-1015"></a>    <span class="n">log_prob</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">square_norm</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-0-1016" name="__codelineno-0-1016"></a>    <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.KronLLLaplace.functional_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">functional_samples</span>


<a href="#laplace.lllaplace.KronLLLaplace.functional_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">functional_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.functional_samples(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.functional_samples(pred_type)">pred_type</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType" href="../enums/#laplace.utils.enums.PredType">PredType</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType.GLM" href="../enums/#laplace.utils.enums.PredType.GLM">GLM</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.functional_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.functional_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.functional_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the function-space posterior on input data <code>x</code>.
Can be used, for example, for Thompson sampling or to compute an arbitrary
expectation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.functional_samples(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.functional_samples(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>input data <code>(batch_size, input_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.functional_samples(pred_type)" class="doc doc-heading doc-heading-parameter">              <b><code>pred_type</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.functional_samples(pred_type)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;glm&#39;, &#39;nn&#39;)</code>, default:
                  <code>&#39;glm&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>type of posterior predictive, linearized GLM predictive or neural
network sampling predictive. The GLM predictive is consistent with
the curvature approximations used here.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.functional_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.functional_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.functional_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.functional_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.
Only applies when <code>pred_type='glm'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.functional_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.functional_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1154">1154</a></span>
<span class="normal"><a href="#__codelineno-0-1155">1155</a></span>
<span class="normal"><a href="#__codelineno-0-1156">1156</a></span>
<span class="normal"><a href="#__codelineno-0-1157">1157</a></span>
<span class="normal"><a href="#__codelineno-0-1158">1158</a></span>
<span class="normal"><a href="#__codelineno-0-1159">1159</a></span>
<span class="normal"><a href="#__codelineno-0-1160">1160</a></span>
<span class="normal"><a href="#__codelineno-0-1161">1161</a></span>
<span class="normal"><a href="#__codelineno-0-1162">1162</a></span>
<span class="normal"><a href="#__codelineno-0-1163">1163</a></span>
<span class="normal"><a href="#__codelineno-0-1164">1164</a></span>
<span class="normal"><a href="#__codelineno-0-1165">1165</a></span>
<span class="normal"><a href="#__codelineno-0-1166">1166</a></span>
<span class="normal"><a href="#__codelineno-0-1167">1167</a></span>
<span class="normal"><a href="#__codelineno-0-1168">1168</a></span>
<span class="normal"><a href="#__codelineno-0-1169">1169</a></span>
<span class="normal"><a href="#__codelineno-0-1170">1170</a></span>
<span class="normal"><a href="#__codelineno-0-1171">1171</a></span>
<span class="normal"><a href="#__codelineno-0-1172">1172</a></span>
<span class="normal"><a href="#__codelineno-0-1173">1173</a></span>
<span class="normal"><a href="#__codelineno-0-1174">1174</a></span>
<span class="normal"><a href="#__codelineno-0-1175">1175</a></span>
<span class="normal"><a href="#__codelineno-0-1176">1176</a></span>
<span class="normal"><a href="#__codelineno-0-1177">1177</a></span>
<span class="normal"><a href="#__codelineno-0-1178">1178</a></span>
<span class="normal"><a href="#__codelineno-0-1179">1179</a></span>
<span class="normal"><a href="#__codelineno-0-1180">1180</a></span>
<span class="normal"><a href="#__codelineno-0-1181">1181</a></span>
<span class="normal"><a href="#__codelineno-0-1182">1182</a></span>
<span class="normal"><a href="#__codelineno-0-1183">1183</a></span>
<span class="normal"><a href="#__codelineno-0-1184">1184</a></span>
<span class="normal"><a href="#__codelineno-0-1185">1185</a></span>
<span class="normal"><a href="#__codelineno-0-1186">1186</a></span>
<span class="normal"><a href="#__codelineno-0-1187">1187</a></span>
<span class="normal"><a href="#__codelineno-0-1188">1188</a></span>
<span class="normal"><a href="#__codelineno-0-1189">1189</a></span>
<span class="normal"><a href="#__codelineno-0-1190">1190</a></span>
<span class="normal"><a href="#__codelineno-0-1191">1191</a></span>
<span class="normal"><a href="#__codelineno-0-1192">1192</a></span>
<span class="normal"><a href="#__codelineno-0-1193">1193</a></span>
<span class="normal"><a href="#__codelineno-0-1194">1194</a></span>
<span class="normal"><a href="#__codelineno-0-1195">1195</a></span>
<span class="normal"><a href="#__codelineno-0-1196">1196</a></span>
<span class="normal"><a href="#__codelineno-0-1197">1197</a></span>
<span class="normal"><a href="#__codelineno-0-1198">1198</a></span>
<span class="normal"><a href="#__codelineno-0-1199">1199</a></span>
<span class="normal"><a href="#__codelineno-0-1200">1200</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1154" name="__codelineno-0-1154"></a><span class="k">def</span> <span class="nf">functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-1155" name="__codelineno-0-1155"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1156" name="__codelineno-0-1156"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1157" name="__codelineno-0-1157"></a>    <span class="n">pred_type</span><span class="p">:</span> <span class="n">PredType</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">,</span>
<a id="__codelineno-0-1158" name="__codelineno-0-1158"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-1159" name="__codelineno-0-1159"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1160" name="__codelineno-0-1160"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1161" name="__codelineno-0-1161"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1162" name="__codelineno-0-1162"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the function-space posterior on input data `x`.</span>
<a id="__codelineno-0-1163" name="__codelineno-0-1163"></a><span class="sd">    Can be used, for example, for Thompson sampling or to compute an arbitrary</span>
<a id="__codelineno-0-1164" name="__codelineno-0-1164"></a><span class="sd">    expectation.</span>
<a id="__codelineno-0-1165" name="__codelineno-0-1165"></a>
<a id="__codelineno-0-1166" name="__codelineno-0-1166"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1167" name="__codelineno-0-1167"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1168" name="__codelineno-0-1168"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-1169" name="__codelineno-0-1169"></a><span class="sd">        input data `(batch_size, input_shape)`</span>
<a id="__codelineno-0-1170" name="__codelineno-0-1170"></a>
<a id="__codelineno-0-1171" name="__codelineno-0-1171"></a><span class="sd">    pred_type : {&#39;glm&#39;, &#39;nn&#39;}, default=&#39;glm&#39;</span>
<a id="__codelineno-0-1172" name="__codelineno-0-1172"></a><span class="sd">        type of posterior predictive, linearized GLM predictive or neural</span>
<a id="__codelineno-0-1173" name="__codelineno-0-1173"></a><span class="sd">        network sampling predictive. The GLM predictive is consistent with</span>
<a id="__codelineno-0-1174" name="__codelineno-0-1174"></a><span class="sd">        the curvature approximations used here.</span>
<a id="__codelineno-0-1175" name="__codelineno-0-1175"></a>
<a id="__codelineno-0-1176" name="__codelineno-0-1176"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-1177" name="__codelineno-0-1177"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-1178" name="__codelineno-0-1178"></a>
<a id="__codelineno-0-1179" name="__codelineno-0-1179"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-1180" name="__codelineno-0-1180"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-1181" name="__codelineno-0-1181"></a><span class="sd">        Only applies when `pred_type=&#39;glm&#39;`.</span>
<a id="__codelineno-0-1182" name="__codelineno-0-1182"></a>
<a id="__codelineno-0-1183" name="__codelineno-0-1183"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1184" name="__codelineno-0-1184"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-1185" name="__codelineno-0-1185"></a>
<a id="__codelineno-0-1186" name="__codelineno-0-1186"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1187" name="__codelineno-0-1187"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1188" name="__codelineno-0-1188"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-1189" name="__codelineno-0-1189"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-1190" name="__codelineno-0-1190"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1191" name="__codelineno-0-1191"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">PredType</span><span class="o">.</span><span class="n">__members__</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<a id="__codelineno-0-1192" name="__codelineno-0-1192"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only glm and nn supported as prediction types.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1193" name="__codelineno-0-1193"></a>
<a id="__codelineno-0-1194" name="__codelineno-0-1194"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">:</span>
<a id="__codelineno-0-1195" name="__codelineno-0-1195"></a>        <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_distribution</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-1196" name="__codelineno-0-1196"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-1197" name="__codelineno-0-1197"></a>            <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span><span class="p">,</span> <span class="n">generator</span>
<a id="__codelineno-0-1198" name="__codelineno-0-1198"></a>        <span class="p">)</span>
<a id="__codelineno-0-1199" name="__codelineno-0-1199"></a>    <span class="k">else</span><span class="p">:</span>  <span class="c1"># &#39;nn&#39;</span>
<a id="__codelineno-0-1200" name="__codelineno-0-1200"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_functional_samples</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">generator</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.KronLLLaplace.predictive_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">predictive_samples</span>


<a href="#laplace.lllaplace.KronLLLaplace.predictive_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">predictive_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.predictive_samples(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.predictive_samples(pred_type)">pred_type</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType" href="../enums/#laplace.utils.enums.PredType">PredType</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType.GLM" href="../enums/#laplace.utils.enums.PredType.GLM">GLM</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.predictive_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.predictive_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.KronLLLaplace.predictive_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the posterior predictive on input data <code>x</code>. I.e., the respective
inverse-link function (e.g. softmax) is applied on top of the functional
sample.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.predictive_samples(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>input data <code>(batch_size, input_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.predictive_samples(pred_type)" class="doc doc-heading doc-heading-parameter">              <b><code>pred_type</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(pred_type)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;glm&#39;, &#39;nn&#39;)</code>, default:
                  <code>&#39;glm&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>type of posterior predictive, linearized GLM predictive or neural
network sampling predictive. The GLM predictive is consistent with
the curvature approximations used here.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.predictive_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.predictive_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.
Only applies when <code>pred_type='glm'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.KronLLLaplace.predictive_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.KronLLLaplace.predictive_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1202">1202</a></span>
<span class="normal"><a href="#__codelineno-0-1203">1203</a></span>
<span class="normal"><a href="#__codelineno-0-1204">1204</a></span>
<span class="normal"><a href="#__codelineno-0-1205">1205</a></span>
<span class="normal"><a href="#__codelineno-0-1206">1206</a></span>
<span class="normal"><a href="#__codelineno-0-1207">1207</a></span>
<span class="normal"><a href="#__codelineno-0-1208">1208</a></span>
<span class="normal"><a href="#__codelineno-0-1209">1209</a></span>
<span class="normal"><a href="#__codelineno-0-1210">1210</a></span>
<span class="normal"><a href="#__codelineno-0-1211">1211</a></span>
<span class="normal"><a href="#__codelineno-0-1212">1212</a></span>
<span class="normal"><a href="#__codelineno-0-1213">1213</a></span>
<span class="normal"><a href="#__codelineno-0-1214">1214</a></span>
<span class="normal"><a href="#__codelineno-0-1215">1215</a></span>
<span class="normal"><a href="#__codelineno-0-1216">1216</a></span>
<span class="normal"><a href="#__codelineno-0-1217">1217</a></span>
<span class="normal"><a href="#__codelineno-0-1218">1218</a></span>
<span class="normal"><a href="#__codelineno-0-1219">1219</a></span>
<span class="normal"><a href="#__codelineno-0-1220">1220</a></span>
<span class="normal"><a href="#__codelineno-0-1221">1221</a></span>
<span class="normal"><a href="#__codelineno-0-1222">1222</a></span>
<span class="normal"><a href="#__codelineno-0-1223">1223</a></span>
<span class="normal"><a href="#__codelineno-0-1224">1224</a></span>
<span class="normal"><a href="#__codelineno-0-1225">1225</a></span>
<span class="normal"><a href="#__codelineno-0-1226">1226</a></span>
<span class="normal"><a href="#__codelineno-0-1227">1227</a></span>
<span class="normal"><a href="#__codelineno-0-1228">1228</a></span>
<span class="normal"><a href="#__codelineno-0-1229">1229</a></span>
<span class="normal"><a href="#__codelineno-0-1230">1230</a></span>
<span class="normal"><a href="#__codelineno-0-1231">1231</a></span>
<span class="normal"><a href="#__codelineno-0-1232">1232</a></span>
<span class="normal"><a href="#__codelineno-0-1233">1233</a></span>
<span class="normal"><a href="#__codelineno-0-1234">1234</a></span>
<span class="normal"><a href="#__codelineno-0-1235">1235</a></span>
<span class="normal"><a href="#__codelineno-0-1236">1236</a></span>
<span class="normal"><a href="#__codelineno-0-1237">1237</a></span>
<span class="normal"><a href="#__codelineno-0-1238">1238</a></span>
<span class="normal"><a href="#__codelineno-0-1239">1239</a></span>
<span class="normal"><a href="#__codelineno-0-1240">1240</a></span>
<span class="normal"><a href="#__codelineno-0-1241">1241</a></span>
<span class="normal"><a href="#__codelineno-0-1242">1242</a></span>
<span class="normal"><a href="#__codelineno-0-1243">1243</a></span>
<span class="normal"><a href="#__codelineno-0-1244">1244</a></span>
<span class="normal"><a href="#__codelineno-0-1245">1245</a></span>
<span class="normal"><a href="#__codelineno-0-1246">1246</a></span>
<span class="normal"><a href="#__codelineno-0-1247">1247</a></span>
<span class="normal"><a href="#__codelineno-0-1248">1248</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1202" name="__codelineno-0-1202"></a><span class="k">def</span> <span class="nf">predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-1203" name="__codelineno-0-1203"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1204" name="__codelineno-0-1204"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1205" name="__codelineno-0-1205"></a>    <span class="n">pred_type</span><span class="p">:</span> <span class="n">PredType</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">,</span>
<a id="__codelineno-0-1206" name="__codelineno-0-1206"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-1207" name="__codelineno-0-1207"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1208" name="__codelineno-0-1208"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1209" name="__codelineno-0-1209"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1210" name="__codelineno-0-1210"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the posterior predictive on input data `x`. I.e., the respective</span>
<a id="__codelineno-0-1211" name="__codelineno-0-1211"></a><span class="sd">    inverse-link function (e.g. softmax) is applied on top of the functional</span>
<a id="__codelineno-0-1212" name="__codelineno-0-1212"></a><span class="sd">    sample.</span>
<a id="__codelineno-0-1213" name="__codelineno-0-1213"></a>
<a id="__codelineno-0-1214" name="__codelineno-0-1214"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1215" name="__codelineno-0-1215"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1216" name="__codelineno-0-1216"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-1217" name="__codelineno-0-1217"></a><span class="sd">        input data `(batch_size, input_shape)`</span>
<a id="__codelineno-0-1218" name="__codelineno-0-1218"></a>
<a id="__codelineno-0-1219" name="__codelineno-0-1219"></a><span class="sd">    pred_type : {&#39;glm&#39;, &#39;nn&#39;}, default=&#39;glm&#39;</span>
<a id="__codelineno-0-1220" name="__codelineno-0-1220"></a><span class="sd">        type of posterior predictive, linearized GLM predictive or neural</span>
<a id="__codelineno-0-1221" name="__codelineno-0-1221"></a><span class="sd">        network sampling predictive. The GLM predictive is consistent with</span>
<a id="__codelineno-0-1222" name="__codelineno-0-1222"></a><span class="sd">        the curvature approximations used here.</span>
<a id="__codelineno-0-1223" name="__codelineno-0-1223"></a>
<a id="__codelineno-0-1224" name="__codelineno-0-1224"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-1225" name="__codelineno-0-1225"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-1226" name="__codelineno-0-1226"></a>
<a id="__codelineno-0-1227" name="__codelineno-0-1227"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-1228" name="__codelineno-0-1228"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-1229" name="__codelineno-0-1229"></a><span class="sd">        Only applies when `pred_type=&#39;glm&#39;`.</span>
<a id="__codelineno-0-1230" name="__codelineno-0-1230"></a>
<a id="__codelineno-0-1231" name="__codelineno-0-1231"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1232" name="__codelineno-0-1232"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-1233" name="__codelineno-0-1233"></a>
<a id="__codelineno-0-1234" name="__codelineno-0-1234"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1235" name="__codelineno-0-1235"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1236" name="__codelineno-0-1236"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-1237" name="__codelineno-0-1237"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-1238" name="__codelineno-0-1238"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1239" name="__codelineno-0-1239"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">PredType</span><span class="o">.</span><span class="n">__members__</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<a id="__codelineno-0-1240" name="__codelineno-0-1240"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only glm and nn supported as prediction types.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1241" name="__codelineno-0-1241"></a>
<a id="__codelineno-0-1242" name="__codelineno-0-1242"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">:</span>
<a id="__codelineno-0-1243" name="__codelineno-0-1243"></a>        <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_distribution</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-1244" name="__codelineno-0-1244"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-1245" name="__codelineno-0-1245"></a>            <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span><span class="p">,</span> <span class="n">generator</span>
<a id="__codelineno-0-1246" name="__codelineno-0-1246"></a>        <span class="p">)</span>
<a id="__codelineno-0-1247" name="__codelineno-0-1247"></a>    <span class="k">else</span><span class="p">:</span>  <span class="c1"># &#39;nn&#39;</span>
<a id="__codelineno-0-1248" name="__codelineno-0-1248"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_predictive_samples</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">generator</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="laplace.lllaplace.FullLLLaplace" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">FullLLLaplace</span>


<a href="#laplace.lllaplace.FullLLLaplace" class="headerlink" title="Permanent link">#</a></h2>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">FullLLLaplace</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n"><span title="torch.nn.Module">Module</span></span><span class="p">,</span> <span class="n">likelihood</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n">sigma_noise</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">prior_precision</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">prior_mean</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">|</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">temperature</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">enable_backprop</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">feature_reduction</span><span class="p">:</span> <span class="n"><span title="laplace.utils.feature_extractor.FeatureReduction">FeatureReduction</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dict_key_x</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="s1">&#39;input_ids&#39;</span><span class="p">,</span> <span class="n">dict_key_y</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="s1">&#39;labels&#39;</span><span class="p">,</span> <span class="n">backend</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#type">type</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="laplace.curvature.curvature.CurvatureInterface" href="../curvatures/#laplace.curvature.CurvatureInterface">CurvatureInterface</a></span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">last_layer_name</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">backend_kwargs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">asdl_fisher_kwargs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="laplace.lllaplace.LLLaplace" href="#laplace.lllaplace.LLLaplace">LLLaplace</a></code>, <code><a class="autorefs autorefs-internal" title="laplace.baselaplace.FullLaplace" href="../parametriclaplace/#laplace.baselaplace.FullLaplace">FullLaplace</a></code></p>


        <p>Last-layer Laplace approximation with full, i.e., dense, log likelihood Hessian approximation
and hence posterior precision. Based on the chosen <code>backend</code> parameter, the full
approximation can be, for example, a generalized Gauss-Newton matrix.
Mathematically, we have <span class="arithmatex">\(P \in \mathbb{R}^{P \times P}\)</span>.
See <code>FullLaplace</code>, <code>LLLaplace</code>, and <code>BaseLaplace</code> for the full interface.</p>









<p><span class="doc-section-title">Methods:</span></p>
    <ul>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.fit" href="#laplace.lllaplace.FullLLLaplace.fit">fit</a></code></b>
            –
            <div class="doc-md-description">
              <p>Fit the local Laplace approximation at the parameters of the model.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.log_marginal_likelihood" href="#laplace.lllaplace.FullLLLaplace.log_marginal_likelihood">log_marginal_likelihood</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the Laplace approximation to the log marginal likelihood subject</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.__call__" href="#laplace.lllaplace.FullLLLaplace.__call__">__call__</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the posterior predictive on input data <code>x</code>.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.log_prob" href="#laplace.lllaplace.FullLLLaplace.log_prob">log_prob</a></code></b>
            –
            <div class="doc-md-description">
              <p>Compute the log probability under the (current) Laplace approximation.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.functional_samples" href="#laplace.lllaplace.FullLLLaplace.functional_samples">functional_samples</a></code></b>
            –
            <div class="doc-md-description">
              <p>Sample from the function-space posterior on input data <code>x</code>.</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.predictive_samples" href="#laplace.lllaplace.FullLLLaplace.predictive_samples">predictive_samples</a></code></b>
            –
            <div class="doc-md-description">
              <p>Sample from the posterior predictive on input data <code>x</code>. I.e., the respective</p>
            </div>
          </li>
          <li class="doc-section-item field-body">
            <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.functional_variance_fast" href="#laplace.lllaplace.FullLLLaplace.functional_variance_fast">functional_variance_fast</a></code></b>
            –
            <div class="doc-md-description">
              <p>Should be overriden if there exists a trick to make this fast!</p>
            </div>
          </li>
    </ul>




<p><span class="doc-section-title">Attributes:</span></p>
    <ul>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.log_likelihood" href="#laplace.lllaplace.FullLLLaplace.log_likelihood">log_likelihood</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute log likelihood on the training data after <code>.fit()</code> has been called.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.prior_precision_diag" href="#laplace.lllaplace.FullLLLaplace.prior_precision_diag">prior_precision_diag</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Obtain the diagonal prior precision <span class="arithmatex">\(p_0\)</span> constructed from either</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.scatter" href="#laplace.lllaplace.FullLLLaplace.scatter">scatter</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Computes the <em>scatter</em>, a term of the log marginal likelihood that</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.log_det_prior_precision" href="#laplace.lllaplace.FullLLLaplace.log_det_prior_precision">log_det_prior_precision</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute log determinant of the prior precision</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.log_det_ratio" href="#laplace.lllaplace.FullLLLaplace.log_det_ratio">log_det_ratio</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Compute the log determinant ratio, a part of the log marginal likelihood.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.posterior_precision" href="#laplace.lllaplace.FullLLLaplace.posterior_precision">posterior_precision</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Posterior precision <span class="arithmatex">\(P\)</span>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.posterior_scale" href="#laplace.lllaplace.FullLLLaplace.posterior_scale">posterior_scale</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Posterior scale (square root of the covariance), i.e.,</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
          <b><code><a class="autorefs autorefs-internal" title="laplace.lllaplace.FullLLLaplace.posterior_covariance" href="#laplace.lllaplace.FullLLLaplace.posterior_covariance">posterior_covariance</a></code></b>
              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            <p>Posterior covariance, i.e., <span class="arithmatex">\(P^{-1}\)</span>.</p>
          </div>
        </li>
    </ul>

                  <details class="quote">
                    <summary>Source code in <code>laplace/lllaplace.py</code></summary>
                    <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-101">101</a></span>
<span class="normal"><a href="#__codelineno-0-102">102</a></span>
<span class="normal"><a href="#__codelineno-0-103">103</a></span>
<span class="normal"><a href="#__codelineno-0-104">104</a></span>
<span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span>
<span class="normal"><a href="#__codelineno-0-131">131</a></span>
<span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span>
<span class="normal"><a href="#__codelineno-0-160">160</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-101" name="__codelineno-0-101"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-102" name="__codelineno-0-102"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-103" name="__codelineno-0-103"></a>    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
<a id="__codelineno-0-104" name="__codelineno-0-104"></a>    <span class="n">likelihood</span><span class="p">:</span> <span class="n">Likelihood</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-105" name="__codelineno-0-105"></a>    <span class="n">sigma_noise</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-106" name="__codelineno-0-106"></a>    <span class="n">prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-107" name="__codelineno-0-107"></a>    <span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-108" name="__codelineno-0-108"></a>    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-109" name="__codelineno-0-109"></a>    <span class="n">enable_backprop</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-110" name="__codelineno-0-110"></a>    <span class="n">feature_reduction</span><span class="p">:</span> <span class="n">FeatureReduction</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-111" name="__codelineno-0-111"></a>    <span class="n">dict_key_x</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;input_ids&quot;</span><span class="p">,</span>
<a id="__codelineno-0-112" name="__codelineno-0-112"></a>    <span class="n">dict_key_y</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span>
<a id="__codelineno-0-113" name="__codelineno-0-113"></a>    <span class="n">backend</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">CurvatureInterface</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-114" name="__codelineno-0-114"></a>    <span class="n">last_layer_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-115" name="__codelineno-0-115"></a>    <span class="n">backend_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-116" name="__codelineno-0-116"></a>    <span class="n">asdl_fisher_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="p">):</span>
<a id="__codelineno-0-118" name="__codelineno-0-118"></a>    <span class="k">if</span> <span class="n">asdl_fisher_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-119" name="__codelineno-0-119"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Last-layer Laplace does not support asdl_fisher_kwargs.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-120" name="__codelineno-0-120"></a>
<a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">H</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-122" name="__codelineno-0-122"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
<a id="__codelineno-0-123" name="__codelineno-0-123"></a>        <span class="n">model</span><span class="p">,</span>
<a id="__codelineno-0-124" name="__codelineno-0-124"></a>        <span class="n">likelihood</span><span class="p">,</span>
<a id="__codelineno-0-125" name="__codelineno-0-125"></a>        <span class="n">sigma_noise</span><span class="o">=</span><span class="n">sigma_noise</span><span class="p">,</span>
<a id="__codelineno-0-126" name="__codelineno-0-126"></a>        <span class="n">prior_precision</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
<a id="__codelineno-0-127" name="__codelineno-0-127"></a>        <span class="n">prior_mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
<a id="__codelineno-0-129" name="__codelineno-0-129"></a>        <span class="n">enable_backprop</span><span class="o">=</span><span class="n">enable_backprop</span><span class="p">,</span>
<a id="__codelineno-0-130" name="__codelineno-0-130"></a>        <span class="n">dict_key_x</span><span class="o">=</span><span class="n">dict_key_x</span><span class="p">,</span>
<a id="__codelineno-0-131" name="__codelineno-0-131"></a>        <span class="n">dict_key_y</span><span class="o">=</span><span class="n">dict_key_y</span><span class="p">,</span>
<a id="__codelineno-0-132" name="__codelineno-0-132"></a>        <span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">,</span>
<a id="__codelineno-0-133" name="__codelineno-0-133"></a>        <span class="n">backend_kwargs</span><span class="o">=</span><span class="n">backend_kwargs</span><span class="p">,</span>
<a id="__codelineno-0-134" name="__codelineno-0-134"></a>    <span class="p">)</span>
<a id="__codelineno-0-135" name="__codelineno-0-135"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">FeatureExtractor</span><span class="p">(</span>
<a id="__codelineno-0-136" name="__codelineno-0-136"></a>        <span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
<a id="__codelineno-0-137" name="__codelineno-0-137"></a>        <span class="n">last_layer_name</span><span class="o">=</span><span class="n">last_layer_name</span><span class="p">,</span>
<a id="__codelineno-0-138" name="__codelineno-0-138"></a>        <span class="n">enable_backprop</span><span class="o">=</span><span class="n">enable_backprop</span><span class="p">,</span>
<a id="__codelineno-0-139" name="__codelineno-0-139"></a>        <span class="n">feature_reduction</span><span class="o">=</span><span class="n">feature_reduction</span><span class="p">,</span>
<a id="__codelineno-0-140" name="__codelineno-0-140"></a>    <span class="p">)</span>
<a id="__codelineno-0-141" name="__codelineno-0-141"></a>
<a id="__codelineno-0-142" name="__codelineno-0-142"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-143" name="__codelineno-0-143"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-144" name="__codelineno-0-144"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-0-146" name="__codelineno-0-146"></a>        <span class="c1"># ignore checks of prior mean setter temporarily, check on .fit()</span>
<a id="__codelineno-0-147" name="__codelineno-0-147"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">prior_precision</span>
<a id="__codelineno-0-148" name="__codelineno-0-148"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">prior_mean</span>
<a id="__codelineno-0-149" name="__codelineno-0-149"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-150" name="__codelineno-0-150"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span>
<a id="__codelineno-0-151" name="__codelineno-0-151"></a>            <span class="n">parameters_to_vector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<a id="__codelineno-0-152" name="__codelineno-0-152"></a>        <span class="p">)</span>
<a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
<a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">prior_precision</span>
<a id="__codelineno-0-155" name="__codelineno-0-155"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">prior_mean</span>
<a id="__codelineno-0-156" name="__codelineno-0-156"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span>
<a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_init_H</span><span class="p">()</span>
<a id="__codelineno-0-158" name="__codelineno-0-158"></a>
<a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_backend_kwargs</span><span class="p">[</span><span class="s2">&quot;last_layer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-0-160" name="__codelineno-0-160"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">_last_layer_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="n">last_layer_name</span>
</code></pre></div></td></tr></table></div>
                  </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.FullLLLaplace.log_likelihood" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_likelihood</span>


<a href="#laplace.lllaplace.FullLLLaplace.log_likelihood" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_likelihood</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute log likelihood on the training data after <code>.fit()</code> has been called.
The log likelihood is computed on-demand based on the loss and, for example,
the observation noise which makes it differentiable in the latter for
iterative updates.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_likelihood</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.FullLLLaplace.prior_precision_diag" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">prior_precision_diag</span>


<a href="#laplace.lllaplace.FullLLLaplace.prior_precision_diag" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">prior_precision_diag</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Obtain the diagonal prior precision <span class="arithmatex">\(p_0\)</span> constructed from either
a scalar or diagonal prior precision.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>prior_precision_diag</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.FullLLLaplace.scatter" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">scatter</span>


<a href="#laplace.lllaplace.FullLLLaplace.scatter" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">scatter</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Computes the <em>scatter</em>, a term of the log marginal likelihood that
corresponds to L-2 regularization:
<code>scatter</code> = <span class="arithmatex">\((\theta_{MAP} - \mu_0)^{T} P_0 (\theta_{MAP} - \mu_0) \)</span>.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>scatter</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.FullLLLaplace.log_det_prior_precision" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_det_prior_precision</span>


<a href="#laplace.lllaplace.FullLLLaplace.log_det_prior_precision" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_det_prior_precision</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute log determinant of the prior precision
<span class="arithmatex">\(\log \det P_0\)</span></p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_det</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.FullLLLaplace.log_det_ratio" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">log_det_ratio</span>


<a href="#laplace.lllaplace.FullLLLaplace.log_det_ratio" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">log_det_ratio</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the log determinant ratio, a part of the log marginal likelihood.</p>
<div class="arithmatex">\[
    \log \frac{\det P}{\det P_0} = \log \det P - \log \det P_0
\]</div>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_det_ratio</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.FullLLLaplace.posterior_precision" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">posterior_precision</span>


<a href="#laplace.lllaplace.FullLLLaplace.posterior_precision" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">posterior_precision</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Posterior precision <span class="arithmatex">\(P\)</span>.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>precision</code></b> (              <code><span title="torch.tensor">tensor</span></code>
)          –
          <div class="doc-md-description">
            <p><code>(parameters, parameters)</code></p>
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.FullLLLaplace.posterior_scale" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">posterior_scale</span>


<a href="#laplace.lllaplace.FullLLLaplace.posterior_scale" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">posterior_scale</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Posterior scale (square root of the covariance), i.e.,
<span class="arithmatex">\(P^{-\frac{1}{2}}\)</span>.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>scale</code></b> (              <code><span title="torch.tensor">tensor</span></code>
)          –
          <div class="doc-md-description">
            <p><code>(parameters, parameters)</code></p>
          </div>
        </li>
    </ul>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="laplace.lllaplace.FullLLLaplace.posterior_covariance" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">posterior_covariance</span>


<a href="#laplace.lllaplace.FullLLLaplace.posterior_covariance" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="n">posterior_covariance</span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Posterior covariance, i.e., <span class="arithmatex">\(P^{-1}\)</span>.</p>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>covariance</code></b> (              <code><span title="torch.tensor">tensor</span></code>
)          –
          <div class="doc-md-description">
            <p><code>(parameters, parameters)</code></p>
          </div>
        </li>
    </ul>
    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.FullLLLaplace.fit" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">fit</span>


<a href="#laplace.lllaplace.FullLLLaplace.fit" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">fit</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.fit(train_loader)">train_loader</a></span><span class="p">:</span> <span class="n"><span title="torch.utils.data.DataLoader">DataLoader</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.fit(override)">override</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.fit(progress_bar)">progress_bar</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Fit the local Laplace approximation at the parameters of the model.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.fit(train_loader)" class="doc doc-heading doc-heading-parameter">              <b><code>train_loader</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.fit(train_loader)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.data.utils.DataLoader">DataLoader</span></code>)
          –
          <div class="doc-md-description">
            <p>each iterate is a training batch, either <code>(X, y)</code> tensors or a dict-like
object containing keys as expressed by <code>self.dict_key_x</code> and
<code>self.dict_key_y</code>. <code>train_loader.dataset</code> needs to be set to access
<span class="arithmatex">\(N\)</span>, size of the data set.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.fit(override)" class="doc doc-heading doc-heading-parameter">              <b><code>override</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.fit(override)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>whether to initialize H, loss, and n_data again; setting to False is useful for
online learning settings to accumulate a sequential posterior approximation.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.fit(progress_bar)" class="doc doc-heading doc-heading-parameter">              <b><code>progress_bar</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.fit(progress_bar)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/lllaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span>
<span class="normal"><a href="#__codelineno-0-203">203</a></span>
<span class="normal"><a href="#__codelineno-0-204">204</a></span>
<span class="normal"><a href="#__codelineno-0-205">205</a></span>
<span class="normal"><a href="#__codelineno-0-206">206</a></span>
<span class="normal"><a href="#__codelineno-0-207">207</a></span>
<span class="normal"><a href="#__codelineno-0-208">208</a></span>
<span class="normal"><a href="#__codelineno-0-209">209</a></span>
<span class="normal"><a href="#__codelineno-0-210">210</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
<a id="__codelineno-0-163" name="__codelineno-0-163"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="n">train_loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
<a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-0-166" name="__codelineno-0-166"></a>    <span class="n">progress_bar</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-167" name="__codelineno-0-167"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Fit the local Laplace approximation at the parameters of the model.</span>
<a id="__codelineno-0-169" name="__codelineno-0-169"></a>
<a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-172" name="__codelineno-0-172"></a><span class="sd">    train_loader : torch.data.utils.DataLoader</span>
<a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">        each iterate is a training batch, either `(X, y)` tensors or a dict-like</span>
<a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">        object containing keys as expressed by `self.dict_key_x` and</span>
<a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">        `self.dict_key_y`. `train_loader.dataset` needs to be set to access</span>
<a id="__codelineno-0-176" name="__codelineno-0-176"></a><span class="sd">        \\(N\\), size of the data set.</span>
<a id="__codelineno-0-177" name="__codelineno-0-177"></a><span class="sd">    override : bool, default=True</span>
<a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">        whether to initialize H, loss, and n_data again; setting to False is useful for</span>
<a id="__codelineno-0-179" name="__codelineno-0-179"></a><span class="sd">        online learning settings to accumulate a sequential posterior approximation.</span>
<a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">    progress_bar: bool, default=False</span>
<a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-182" name="__codelineno-0-182"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">override</span><span class="p">:</span>
<a id="__codelineno-0-183" name="__codelineno-0-183"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-184" name="__codelineno-0-184"></a>            <span class="s2">&quot;Last-layer Laplace approximations do not support `override=False`.&quot;</span>
<a id="__codelineno-0-185" name="__codelineno-0-185"></a>        <span class="p">)</span>
<a id="__codelineno-0-186" name="__codelineno-0-186"></a>
<a id="__codelineno-0-187" name="__codelineno-0-187"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<a id="__codelineno-0-188" name="__codelineno-0-188"></a>
<a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-190" name="__codelineno-0-190"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="n">MutableMapping</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
<a id="__codelineno-0-191" name="__codelineno-0-191"></a>            <span class="nb">iter</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
<a id="__codelineno-0-192" name="__codelineno-0-192"></a>        <span class="p">)</span>
<a id="__codelineno-0-193" name="__codelineno-0-193"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_find_last_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<a id="__codelineno-0-194" name="__codelineno-0-194"></a>        <span class="n">params</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">parameters_to_vector</span><span class="p">(</span>
<a id="__codelineno-0-195" name="__codelineno-0-195"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
<a id="__codelineno-0-196" name="__codelineno-0-196"></a>        <span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<a id="__codelineno-0-197" name="__codelineno-0-197"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_params</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<a id="__codelineno-0-198" name="__codelineno-0-198"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span>
<a id="__codelineno-0-199" name="__codelineno-0-199"></a>        <span class="c1"># here, check the already set prior precision again</span>
<a id="__codelineno-0-200" name="__codelineno-0-200"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_precision</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior_precision</span>
<a id="__codelineno-0-201" name="__codelineno-0-201"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior_mean</span>
<a id="__codelineno-0-202" name="__codelineno-0-202"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_init_H</span><span class="p">()</span>
<a id="__codelineno-0-203" name="__codelineno-0-203"></a>
<a id="__codelineno-0-204" name="__codelineno-0-204"></a>    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="n">override</span><span class="p">)</span>
<a id="__codelineno-0-205" name="__codelineno-0-205"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">parameters_to_vector</span><span class="p">(</span>
<a id="__codelineno-0-206" name="__codelineno-0-206"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">last_layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
<a id="__codelineno-0-207" name="__codelineno-0-207"></a>    <span class="p">)</span>
<a id="__codelineno-0-208" name="__codelineno-0-208"></a>
<a id="__codelineno-0-209" name="__codelineno-0-209"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_backprop</span><span class="p">:</span>
<a id="__codelineno-0-210" name="__codelineno-0-210"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.FullLLLaplace.log_marginal_likelihood" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">log_marginal_likelihood</span>


<a href="#laplace.lllaplace.FullLLLaplace.log_marginal_likelihood" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">log_marginal_likelihood</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.log_marginal_likelihood(prior_precision)">prior_precision</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.log_marginal_likelihood(sigma_noise)">sigma_noise</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the Laplace approximation to the log marginal likelihood subject
to specific Hessian approximations that subclasses implement.
Requires that the Laplace approximation has been fit before.
The resulting torch.Tensor is differentiable in <code>prior_precision</code> and
<code>sigma_noise</code> if these have gradients enabled.
By passing <code>prior_precision</code> or <code>sigma_noise</code>, the current value is
overwritten. This is useful for iterating on the log marginal likelihood.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.log_marginal_likelihood(prior_precision)" class="doc doc-heading doc-heading-parameter">              <b><code>prior_precision</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.log_marginal_likelihood(prior_precision)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>prior precision if should be changed from current <code>prior_precision</code> value</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.log_marginal_likelihood(sigma_noise)" class="doc doc-heading doc-heading-parameter">              <b><code>sigma_noise</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.log_marginal_likelihood(sigma_noise)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>observation noise standard deviation if should be changed</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_marglik</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1018">1018</a></span>
<span class="normal"><a href="#__codelineno-0-1019">1019</a></span>
<span class="normal"><a href="#__codelineno-0-1020">1020</a></span>
<span class="normal"><a href="#__codelineno-0-1021">1021</a></span>
<span class="normal"><a href="#__codelineno-0-1022">1022</a></span>
<span class="normal"><a href="#__codelineno-0-1023">1023</a></span>
<span class="normal"><a href="#__codelineno-0-1024">1024</a></span>
<span class="normal"><a href="#__codelineno-0-1025">1025</a></span>
<span class="normal"><a href="#__codelineno-0-1026">1026</a></span>
<span class="normal"><a href="#__codelineno-0-1027">1027</a></span>
<span class="normal"><a href="#__codelineno-0-1028">1028</a></span>
<span class="normal"><a href="#__codelineno-0-1029">1029</a></span>
<span class="normal"><a href="#__codelineno-0-1030">1030</a></span>
<span class="normal"><a href="#__codelineno-0-1031">1031</a></span>
<span class="normal"><a href="#__codelineno-0-1032">1032</a></span>
<span class="normal"><a href="#__codelineno-0-1033">1033</a></span>
<span class="normal"><a href="#__codelineno-0-1034">1034</a></span>
<span class="normal"><a href="#__codelineno-0-1035">1035</a></span>
<span class="normal"><a href="#__codelineno-0-1036">1036</a></span>
<span class="normal"><a href="#__codelineno-0-1037">1037</a></span>
<span class="normal"><a href="#__codelineno-0-1038">1038</a></span>
<span class="normal"><a href="#__codelineno-0-1039">1039</a></span>
<span class="normal"><a href="#__codelineno-0-1040">1040</a></span>
<span class="normal"><a href="#__codelineno-0-1041">1041</a></span>
<span class="normal"><a href="#__codelineno-0-1042">1042</a></span>
<span class="normal"><a href="#__codelineno-0-1043">1043</a></span>
<span class="normal"><a href="#__codelineno-0-1044">1044</a></span>
<span class="normal"><a href="#__codelineno-0-1045">1045</a></span>
<span class="normal"><a href="#__codelineno-0-1046">1046</a></span>
<span class="normal"><a href="#__codelineno-0-1047">1047</a></span>
<span class="normal"><a href="#__codelineno-0-1048">1048</a></span>
<span class="normal"><a href="#__codelineno-0-1049">1049</a></span>
<span class="normal"><a href="#__codelineno-0-1050">1050</a></span>
<span class="normal"><a href="#__codelineno-0-1051">1051</a></span>
<span class="normal"><a href="#__codelineno-0-1052">1052</a></span>
<span class="normal"><a href="#__codelineno-0-1053">1053</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1018" name="__codelineno-0-1018"></a><span class="k">def</span> <span class="nf">log_marginal_likelihood</span><span class="p">(</span>
<a id="__codelineno-0-1019" name="__codelineno-0-1019"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1020" name="__codelineno-0-1020"></a>    <span class="n">prior_precision</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1021" name="__codelineno-0-1021"></a>    <span class="n">sigma_noise</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1022" name="__codelineno-0-1022"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1023" name="__codelineno-0-1023"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the Laplace approximation to the log marginal likelihood subject</span>
<a id="__codelineno-0-1024" name="__codelineno-0-1024"></a><span class="sd">    to specific Hessian approximations that subclasses implement.</span>
<a id="__codelineno-0-1025" name="__codelineno-0-1025"></a><span class="sd">    Requires that the Laplace approximation has been fit before.</span>
<a id="__codelineno-0-1026" name="__codelineno-0-1026"></a><span class="sd">    The resulting torch.Tensor is differentiable in `prior_precision` and</span>
<a id="__codelineno-0-1027" name="__codelineno-0-1027"></a><span class="sd">    `sigma_noise` if these have gradients enabled.</span>
<a id="__codelineno-0-1028" name="__codelineno-0-1028"></a><span class="sd">    By passing `prior_precision` or `sigma_noise`, the current value is</span>
<a id="__codelineno-0-1029" name="__codelineno-0-1029"></a><span class="sd">    overwritten. This is useful for iterating on the log marginal likelihood.</span>
<a id="__codelineno-0-1030" name="__codelineno-0-1030"></a>
<a id="__codelineno-0-1031" name="__codelineno-0-1031"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1032" name="__codelineno-0-1032"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1033" name="__codelineno-0-1033"></a><span class="sd">    prior_precision : torch.Tensor, optional</span>
<a id="__codelineno-0-1034" name="__codelineno-0-1034"></a><span class="sd">        prior precision if should be changed from current `prior_precision` value</span>
<a id="__codelineno-0-1035" name="__codelineno-0-1035"></a><span class="sd">    sigma_noise : torch.Tensor, optional</span>
<a id="__codelineno-0-1036" name="__codelineno-0-1036"></a><span class="sd">        observation noise standard deviation if should be changed</span>
<a id="__codelineno-0-1037" name="__codelineno-0-1037"></a>
<a id="__codelineno-0-1038" name="__codelineno-0-1038"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1039" name="__codelineno-0-1039"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1040" name="__codelineno-0-1040"></a><span class="sd">    log_marglik : torch.Tensor</span>
<a id="__codelineno-0-1041" name="__codelineno-0-1041"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1042" name="__codelineno-0-1042"></a>    <span class="c1"># update prior precision (useful when iterating on marglik)</span>
<a id="__codelineno-0-1043" name="__codelineno-0-1043"></a>    <span class="k">if</span> <span class="n">prior_precision</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1044" name="__codelineno-0-1044"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">prior_precision</span> <span class="o">=</span> <span class="n">prior_precision</span>
<a id="__codelineno-0-1045" name="__codelineno-0-1045"></a>
<a id="__codelineno-0-1046" name="__codelineno-0-1046"></a>    <span class="c1"># update sigma_noise (useful when iterating on marglik)</span>
<a id="__codelineno-0-1047" name="__codelineno-0-1047"></a>    <span class="k">if</span> <span class="n">sigma_noise</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1048" name="__codelineno-0-1048"></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="o">!=</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-1049" name="__codelineno-0-1049"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Can only change sigma_noise for regression.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1050" name="__codelineno-0-1050"></a>
<a id="__codelineno-0-1051" name="__codelineno-0-1051"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_noise</span> <span class="o">=</span> <span class="n">sigma_noise</span>
<a id="__codelineno-0-1052" name="__codelineno-0-1052"></a>
<a id="__codelineno-0-1053" name="__codelineno-0-1053"></a>    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_likelihood</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_det_ratio</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scatter</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.FullLLLaplace.__call__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">__call__</span>


<a href="#laplace.lllaplace.FullLLLaplace.__call__" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="fm">__call__</span><span class="p">(</span><span class="nf"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.__call__(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.__call__(pred_type)">pred_type</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType" href="../enums/#laplace.utils.enums.PredType">PredType</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType.GLM" href="../enums/#laplace.utils.enums.PredType.GLM">GLM</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.__call__(joint)">joint</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.__call__(link_approx)">link_approx</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox" href="../enums/#laplace.utils.enums.LinkApprox">LinkApprox</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox.PROBIT" href="../enums/#laplace.utils.enums.LinkApprox.PROBIT">PROBIT</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.__call__(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.__call__(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.__call__(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.__call__(fitting)">fitting</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">**model_kwargs</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#dict">dict</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the posterior predictive on input data <code>x</code>.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.__call__(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.__call__(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p><code>(batch_size, input_shape)</code> if tensor. If MutableMapping, must contain
the said tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.__call__(pred_type)" class="doc doc-heading doc-heading-parameter">              <b><code>pred_type</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.__call__(pred_type)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;glm&#39;, &#39;nn&#39;)</code>, default:
                  <code>&#39;glm&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>type of posterior predictive, linearized GLM predictive or neural
network sampling predictive. The GLM predictive is consistent with
the curvature approximations used here. When Laplace is done only
on subset of parameters (i.e. some grad are disabled),
only <code>nn</code> predictive is supported.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.__call__(link_approx)" class="doc doc-heading doc-heading-parameter">              <b><code>link_approx</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.__call__(link_approx)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;)</code>, default:
                  <code>&#39;mc&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>how to approximate the classification link function for the <code>'glm'</code>.
For <code>pred_type='nn'</code>, only 'mc' is possible.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.__call__(joint)" class="doc doc-heading doc-heading-parameter">              <b><code>joint</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.__call__(joint)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to output a joint predictive distribution in regression with
<code>pred_type='glm'</code>. If set to <code>True</code>, the predictive distribution
has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).
If <code>False</code>, then only outputs the marginal predictive distribution.
Only available for regression and GLM predictive.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.__call__(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.__call__(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples for <code>link_approx='mc'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.__call__(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.__call__(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized posterior predictive on the outputs.
Only works for <code>pred_type='glm'</code> when <code>joint=False</code> in regression.
In the case of last-layer Laplace with a diagonal or Kron Hessian,
setting this to <code>True</code> makes computation much(!) faster for large
number of outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.__call__(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.__call__(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used).</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.__call__(fitting)" class="doc doc-heading doc-heading-parameter">              <b><code>fitting</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.__call__(fitting)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether or not this predictive call is done during fitting. Only useful for
reward modeling: the likelihood is set to <code>"regression"</code> when <code>False</code> and
<code>"classification"</code> when <code>True</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>predictive</code></b> (              <code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<span title="torch.Tensor">Tensor</span>]</code>
)          –
          <div class="doc-md-description">
            <p>For <code>likelihood='classification'</code>, a torch.Tensor is returned with
a distribution over classes (similar to a Softmax).
For <code>likelihood='regression'</code>, a tuple of torch.Tensor is returned
with the mean and the predictive variance.
For <code>likelihood='regression'</code> and <code>joint=True</code>, a tuple of torch.Tensor
is returned with the mean and the predictive covariance.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1055">1055</a></span>
<span class="normal"><a href="#__codelineno-0-1056">1056</a></span>
<span class="normal"><a href="#__codelineno-0-1057">1057</a></span>
<span class="normal"><a href="#__codelineno-0-1058">1058</a></span>
<span class="normal"><a href="#__codelineno-0-1059">1059</a></span>
<span class="normal"><a href="#__codelineno-0-1060">1060</a></span>
<span class="normal"><a href="#__codelineno-0-1061">1061</a></span>
<span class="normal"><a href="#__codelineno-0-1062">1062</a></span>
<span class="normal"><a href="#__codelineno-0-1063">1063</a></span>
<span class="normal"><a href="#__codelineno-0-1064">1064</a></span>
<span class="normal"><a href="#__codelineno-0-1065">1065</a></span>
<span class="normal"><a href="#__codelineno-0-1066">1066</a></span>
<span class="normal"><a href="#__codelineno-0-1067">1067</a></span>
<span class="normal"><a href="#__codelineno-0-1068">1068</a></span>
<span class="normal"><a href="#__codelineno-0-1069">1069</a></span>
<span class="normal"><a href="#__codelineno-0-1070">1070</a></span>
<span class="normal"><a href="#__codelineno-0-1071">1071</a></span>
<span class="normal"><a href="#__codelineno-0-1072">1072</a></span>
<span class="normal"><a href="#__codelineno-0-1073">1073</a></span>
<span class="normal"><a href="#__codelineno-0-1074">1074</a></span>
<span class="normal"><a href="#__codelineno-0-1075">1075</a></span>
<span class="normal"><a href="#__codelineno-0-1076">1076</a></span>
<span class="normal"><a href="#__codelineno-0-1077">1077</a></span>
<span class="normal"><a href="#__codelineno-0-1078">1078</a></span>
<span class="normal"><a href="#__codelineno-0-1079">1079</a></span>
<span class="normal"><a href="#__codelineno-0-1080">1080</a></span>
<span class="normal"><a href="#__codelineno-0-1081">1081</a></span>
<span class="normal"><a href="#__codelineno-0-1082">1082</a></span>
<span class="normal"><a href="#__codelineno-0-1083">1083</a></span>
<span class="normal"><a href="#__codelineno-0-1084">1084</a></span>
<span class="normal"><a href="#__codelineno-0-1085">1085</a></span>
<span class="normal"><a href="#__codelineno-0-1086">1086</a></span>
<span class="normal"><a href="#__codelineno-0-1087">1087</a></span>
<span class="normal"><a href="#__codelineno-0-1088">1088</a></span>
<span class="normal"><a href="#__codelineno-0-1089">1089</a></span>
<span class="normal"><a href="#__codelineno-0-1090">1090</a></span>
<span class="normal"><a href="#__codelineno-0-1091">1091</a></span>
<span class="normal"><a href="#__codelineno-0-1092">1092</a></span>
<span class="normal"><a href="#__codelineno-0-1093">1093</a></span>
<span class="normal"><a href="#__codelineno-0-1094">1094</a></span>
<span class="normal"><a href="#__codelineno-0-1095">1095</a></span>
<span class="normal"><a href="#__codelineno-0-1096">1096</a></span>
<span class="normal"><a href="#__codelineno-0-1097">1097</a></span>
<span class="normal"><a href="#__codelineno-0-1098">1098</a></span>
<span class="normal"><a href="#__codelineno-0-1099">1099</a></span>
<span class="normal"><a href="#__codelineno-0-1100">1100</a></span>
<span class="normal"><a href="#__codelineno-0-1101">1101</a></span>
<span class="normal"><a href="#__codelineno-0-1102">1102</a></span>
<span class="normal"><a href="#__codelineno-0-1103">1103</a></span>
<span class="normal"><a href="#__codelineno-0-1104">1104</a></span>
<span class="normal"><a href="#__codelineno-0-1105">1105</a></span>
<span class="normal"><a href="#__codelineno-0-1106">1106</a></span>
<span class="normal"><a href="#__codelineno-0-1107">1107</a></span>
<span class="normal"><a href="#__codelineno-0-1108">1108</a></span>
<span class="normal"><a href="#__codelineno-0-1109">1109</a></span>
<span class="normal"><a href="#__codelineno-0-1110">1110</a></span>
<span class="normal"><a href="#__codelineno-0-1111">1111</a></span>
<span class="normal"><a href="#__codelineno-0-1112">1112</a></span>
<span class="normal"><a href="#__codelineno-0-1113">1113</a></span>
<span class="normal"><a href="#__codelineno-0-1114">1114</a></span>
<span class="normal"><a href="#__codelineno-0-1115">1115</a></span>
<span class="normal"><a href="#__codelineno-0-1116">1116</a></span>
<span class="normal"><a href="#__codelineno-0-1117">1117</a></span>
<span class="normal"><a href="#__codelineno-0-1118">1118</a></span>
<span class="normal"><a href="#__codelineno-0-1119">1119</a></span>
<span class="normal"><a href="#__codelineno-0-1120">1120</a></span>
<span class="normal"><a href="#__codelineno-0-1121">1121</a></span>
<span class="normal"><a href="#__codelineno-0-1122">1122</a></span>
<span class="normal"><a href="#__codelineno-0-1123">1123</a></span>
<span class="normal"><a href="#__codelineno-0-1124">1124</a></span>
<span class="normal"><a href="#__codelineno-0-1125">1125</a></span>
<span class="normal"><a href="#__codelineno-0-1126">1126</a></span>
<span class="normal"><a href="#__codelineno-0-1127">1127</a></span>
<span class="normal"><a href="#__codelineno-0-1128">1128</a></span>
<span class="normal"><a href="#__codelineno-0-1129">1129</a></span>
<span class="normal"><a href="#__codelineno-0-1130">1130</a></span>
<span class="normal"><a href="#__codelineno-0-1131">1131</a></span>
<span class="normal"><a href="#__codelineno-0-1132">1132</a></span>
<span class="normal"><a href="#__codelineno-0-1133">1133</a></span>
<span class="normal"><a href="#__codelineno-0-1134">1134</a></span>
<span class="normal"><a href="#__codelineno-0-1135">1135</a></span>
<span class="normal"><a href="#__codelineno-0-1136">1136</a></span>
<span class="normal"><a href="#__codelineno-0-1137">1137</a></span>
<span class="normal"><a href="#__codelineno-0-1138">1138</a></span>
<span class="normal"><a href="#__codelineno-0-1139">1139</a></span>
<span class="normal"><a href="#__codelineno-0-1140">1140</a></span>
<span class="normal"><a href="#__codelineno-0-1141">1141</a></span>
<span class="normal"><a href="#__codelineno-0-1142">1142</a></span>
<span class="normal"><a href="#__codelineno-0-1143">1143</a></span>
<span class="normal"><a href="#__codelineno-0-1144">1144</a></span>
<span class="normal"><a href="#__codelineno-0-1145">1145</a></span>
<span class="normal"><a href="#__codelineno-0-1146">1146</a></span>
<span class="normal"><a href="#__codelineno-0-1147">1147</a></span>
<span class="normal"><a href="#__codelineno-0-1148">1148</a></span>
<span class="normal"><a href="#__codelineno-0-1149">1149</a></span>
<span class="normal"><a href="#__codelineno-0-1150">1150</a></span>
<span class="normal"><a href="#__codelineno-0-1151">1151</a></span>
<span class="normal"><a href="#__codelineno-0-1152">1152</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1055" name="__codelineno-0-1055"></a><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
<a id="__codelineno-0-1056" name="__codelineno-0-1056"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1057" name="__codelineno-0-1057"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1058" name="__codelineno-0-1058"></a>    <span class="n">pred_type</span><span class="p">:</span> <span class="n">PredType</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">,</span>
<a id="__codelineno-0-1059" name="__codelineno-0-1059"></a>    <span class="n">joint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1060" name="__codelineno-0-1060"></a>    <span class="n">link_approx</span><span class="p">:</span> <span class="n">LinkApprox</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">PROBIT</span><span class="p">,</span>
<a id="__codelineno-0-1061" name="__codelineno-0-1061"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-1062" name="__codelineno-0-1062"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1063" name="__codelineno-0-1063"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1064" name="__codelineno-0-1064"></a>    <span class="n">fitting</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1065" name="__codelineno-0-1065"></a>    <span class="o">**</span><span class="n">model_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1066" name="__codelineno-0-1066"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-1067" name="__codelineno-0-1067"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the posterior predictive on input data `x`.</span>
<a id="__codelineno-0-1068" name="__codelineno-0-1068"></a>
<a id="__codelineno-0-1069" name="__codelineno-0-1069"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1070" name="__codelineno-0-1070"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1071" name="__codelineno-0-1071"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-1072" name="__codelineno-0-1072"></a><span class="sd">        `(batch_size, input_shape)` if tensor. If MutableMapping, must contain</span>
<a id="__codelineno-0-1073" name="__codelineno-0-1073"></a><span class="sd">        the said tensor.</span>
<a id="__codelineno-0-1074" name="__codelineno-0-1074"></a>
<a id="__codelineno-0-1075" name="__codelineno-0-1075"></a><span class="sd">    pred_type : {&#39;glm&#39;, &#39;nn&#39;}, default=&#39;glm&#39;</span>
<a id="__codelineno-0-1076" name="__codelineno-0-1076"></a><span class="sd">        type of posterior predictive, linearized GLM predictive or neural</span>
<a id="__codelineno-0-1077" name="__codelineno-0-1077"></a><span class="sd">        network sampling predictive. The GLM predictive is consistent with</span>
<a id="__codelineno-0-1078" name="__codelineno-0-1078"></a><span class="sd">        the curvature approximations used here. When Laplace is done only</span>
<a id="__codelineno-0-1079" name="__codelineno-0-1079"></a><span class="sd">        on subset of parameters (i.e. some grad are disabled),</span>
<a id="__codelineno-0-1080" name="__codelineno-0-1080"></a><span class="sd">        only `nn` predictive is supported.</span>
<a id="__codelineno-0-1081" name="__codelineno-0-1081"></a>
<a id="__codelineno-0-1082" name="__codelineno-0-1082"></a><span class="sd">    link_approx : {&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;}</span>
<a id="__codelineno-0-1083" name="__codelineno-0-1083"></a><span class="sd">        how to approximate the classification link function for the `&#39;glm&#39;`.</span>
<a id="__codelineno-0-1084" name="__codelineno-0-1084"></a><span class="sd">        For `pred_type=&#39;nn&#39;`, only &#39;mc&#39; is possible.</span>
<a id="__codelineno-0-1085" name="__codelineno-0-1085"></a>
<a id="__codelineno-0-1086" name="__codelineno-0-1086"></a><span class="sd">    joint : bool</span>
<a id="__codelineno-0-1087" name="__codelineno-0-1087"></a><span class="sd">        Whether to output a joint predictive distribution in regression with</span>
<a id="__codelineno-0-1088" name="__codelineno-0-1088"></a><span class="sd">        `pred_type=&#39;glm&#39;`. If set to `True`, the predictive distribution</span>
<a id="__codelineno-0-1089" name="__codelineno-0-1089"></a><span class="sd">        has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).</span>
<a id="__codelineno-0-1090" name="__codelineno-0-1090"></a><span class="sd">        If `False`, then only outputs the marginal predictive distribution.</span>
<a id="__codelineno-0-1091" name="__codelineno-0-1091"></a><span class="sd">        Only available for regression and GLM predictive.</span>
<a id="__codelineno-0-1092" name="__codelineno-0-1092"></a>
<a id="__codelineno-0-1093" name="__codelineno-0-1093"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-1094" name="__codelineno-0-1094"></a><span class="sd">        number of samples for `link_approx=&#39;mc&#39;`.</span>
<a id="__codelineno-0-1095" name="__codelineno-0-1095"></a>
<a id="__codelineno-0-1096" name="__codelineno-0-1096"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-1097" name="__codelineno-0-1097"></a><span class="sd">        whether to use a diagonalized posterior predictive on the outputs.</span>
<a id="__codelineno-0-1098" name="__codelineno-0-1098"></a><span class="sd">        Only works for `pred_type=&#39;glm&#39;` when `joint=False` in regression.</span>
<a id="__codelineno-0-1099" name="__codelineno-0-1099"></a><span class="sd">        In the case of last-layer Laplace with a diagonal or Kron Hessian,</span>
<a id="__codelineno-0-1100" name="__codelineno-0-1100"></a><span class="sd">        setting this to `True` makes computation much(!) faster for large</span>
<a id="__codelineno-0-1101" name="__codelineno-0-1101"></a><span class="sd">        number of outputs.</span>
<a id="__codelineno-0-1102" name="__codelineno-0-1102"></a>
<a id="__codelineno-0-1103" name="__codelineno-0-1103"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1104" name="__codelineno-0-1104"></a><span class="sd">        random number generator to control the samples (if sampling used).</span>
<a id="__codelineno-0-1105" name="__codelineno-0-1105"></a>
<a id="__codelineno-0-1106" name="__codelineno-0-1106"></a><span class="sd">    fitting : bool, default=False</span>
<a id="__codelineno-0-1107" name="__codelineno-0-1107"></a><span class="sd">        whether or not this predictive call is done during fitting. Only useful for</span>
<a id="__codelineno-0-1108" name="__codelineno-0-1108"></a><span class="sd">        reward modeling: the likelihood is set to `&quot;regression&quot;` when `False` and</span>
<a id="__codelineno-0-1109" name="__codelineno-0-1109"></a><span class="sd">        `&quot;classification&quot;` when `True`.</span>
<a id="__codelineno-0-1110" name="__codelineno-0-1110"></a>
<a id="__codelineno-0-1111" name="__codelineno-0-1111"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1112" name="__codelineno-0-1112"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1113" name="__codelineno-0-1113"></a><span class="sd">    predictive: torch.Tensor or tuple[torch.Tensor]</span>
<a id="__codelineno-0-1114" name="__codelineno-0-1114"></a><span class="sd">        For `likelihood=&#39;classification&#39;`, a torch.Tensor is returned with</span>
<a id="__codelineno-0-1115" name="__codelineno-0-1115"></a><span class="sd">        a distribution over classes (similar to a Softmax).</span>
<a id="__codelineno-0-1116" name="__codelineno-0-1116"></a><span class="sd">        For `likelihood=&#39;regression&#39;`, a tuple of torch.Tensor is returned</span>
<a id="__codelineno-0-1117" name="__codelineno-0-1117"></a><span class="sd">        with the mean and the predictive variance.</span>
<a id="__codelineno-0-1118" name="__codelineno-0-1118"></a><span class="sd">        For `likelihood=&#39;regression&#39;` and `joint=True`, a tuple of torch.Tensor</span>
<a id="__codelineno-0-1119" name="__codelineno-0-1119"></a><span class="sd">        is returned with the mean and the predictive covariance.</span>
<a id="__codelineno-0-1120" name="__codelineno-0-1120"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1121" name="__codelineno-0-1121"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">pred</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">PredType</span><span class="p">]:</span>
<a id="__codelineno-0-1122" name="__codelineno-0-1122"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only glm and nn supported as prediction types.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1123" name="__codelineno-0-1123"></a>
<a id="__codelineno-0-1124" name="__codelineno-0-1124"></a>    <span class="k">if</span> <span class="n">link_approx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">la</span> <span class="k">for</span> <span class="n">la</span> <span class="ow">in</span> <span class="n">LinkApprox</span><span class="p">]:</span>
<a id="__codelineno-0-1125" name="__codelineno-0-1125"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported link approximation </span><span class="si">{</span><span class="n">link_approx</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1126" name="__codelineno-0-1126"></a>
<a id="__codelineno-0-1127" name="__codelineno-0-1127"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">NN</span> <span class="ow">and</span> <span class="n">link_approx</span> <span class="o">!=</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">MC</span><span class="p">:</span>
<a id="__codelineno-0-1128" name="__codelineno-0-1128"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-1129" name="__codelineno-0-1129"></a>            <span class="s2">&quot;Only mc link approximation is supported for nn prediction type.&quot;</span>
<a id="__codelineno-0-1130" name="__codelineno-0-1130"></a>        <span class="p">)</span>
<a id="__codelineno-0-1131" name="__codelineno-0-1131"></a>
<a id="__codelineno-0-1132" name="__codelineno-0-1132"></a>    <span class="k">if</span> <span class="n">generator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<a id="__codelineno-0-1133" name="__codelineno-0-1133"></a>        <span class="k">if</span> <span class="p">(</span>
<a id="__codelineno-0-1134" name="__codelineno-0-1134"></a>            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">)</span>
<a id="__codelineno-0-1135" name="__codelineno-0-1135"></a>            <span class="ow">or</span> <span class="n">generator</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span>
<a id="__codelineno-0-1136" name="__codelineno-0-1136"></a>        <span class="p">):</span>
<a id="__codelineno-0-1137" name="__codelineno-0-1137"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid random generator (check type and device).&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1138" name="__codelineno-0-1138"></a>
<a id="__codelineno-0-1139" name="__codelineno-0-1139"></a>    <span class="n">likelihood</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span>
<a id="__codelineno-0-1140" name="__codelineno-0-1140"></a>    <span class="k">if</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REWARD_MODELING</span><span class="p">:</span>
<a id="__codelineno-0-1141" name="__codelineno-0-1141"></a>        <span class="n">likelihood</span> <span class="o">=</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">CLASSIFICATION</span> <span class="k">if</span> <span class="n">fitting</span> <span class="k">else</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span>
<a id="__codelineno-0-1142" name="__codelineno-0-1142"></a>
<a id="__codelineno-0-1143" name="__codelineno-0-1143"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">:</span>
<a id="__codelineno-0-1144" name="__codelineno-0-1144"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_forward_call</span><span class="p">(</span>
<a id="__codelineno-0-1145" name="__codelineno-0-1145"></a>            <span class="n">x</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">,</span> <span class="n">joint</span><span class="p">,</span> <span class="n">link_approx</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span>
<a id="__codelineno-0-1146" name="__codelineno-0-1146"></a>        <span class="p">)</span>
<a id="__codelineno-0-1147" name="__codelineno-0-1147"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-1148" name="__codelineno-0-1148"></a>        <span class="k">if</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-1149" name="__codelineno-0-1149"></a>            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_predictive_samples</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
<a id="__codelineno-0-1150" name="__codelineno-0-1150"></a>            <span class="k">return</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">samples</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-1151" name="__codelineno-0-1151"></a>        <span class="k">else</span><span class="p">:</span>  <span class="c1"># classification; the average is computed online</span>
<a id="__codelineno-0-1152" name="__codelineno-0-1152"></a>            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_predictive_classification</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="o">**</span><span class="n">model_kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.FullLLLaplace._glm_forward_call" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">_glm_forward_call</span>


<a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">_glm_forward_call</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(likelihood)">likelihood</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(joint)">joint</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(link_approx)">link_approx</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox" href="../enums/#laplace.utils.enums.LinkApprox">LinkApprox</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.LinkApprox.PROBIT" href="../enums/#laplace.utils.enums.LinkApprox.PROBIT">PROBIT</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a></span><span class="p">[</span><span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the posterior predictive on input data <code>x</code> for "glm" pred type.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_forward_call(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p><code>(batch_size, input_shape)</code> if tensor. If MutableMapping, must contain
the said tensor.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_forward_call(likelihood)" class="doc doc-heading doc-heading-parameter">              <b><code>likelihood</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(likelihood)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-internal" title="laplace.utils.enums.Likelihood" href="../enums/#laplace.utils.enums.Likelihood">Likelihood</a> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a> in {&#39;classification&#39;, &#39;regression&#39;, &#39;reward_modeling&#39;}</code>)
          –
          <div class="doc-md-description">
            <p>determines the log likelihood Hessian approximation.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_forward_call(link_approx)" class="doc doc-heading doc-heading-parameter">              <b><code>link_approx</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(link_approx)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;)</code>, default:
                  <code>&#39;mc&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>how to approximate the classification link function for the <code>'glm'</code>.
For <code>pred_type='nn'</code>, only 'mc' is possible.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_forward_call(joint)" class="doc doc-heading doc-heading-parameter">              <b><code>joint</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(joint)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>Whether to output a joint predictive distribution in regression with
<code>pred_type='glm'</code>. If set to <code>True</code>, the predictive distribution
has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).
If <code>False</code>, then only outputs the marginal predictive distribution.
Only available for regression and GLM predictive.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_forward_call(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples for <code>link_approx='mc'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_forward_call(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_forward_call(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized posterior predictive on the outputs.
Only works for <code>pred_type='glm'</code> and <code>link_approx='mc'</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>predictive</code></b> (              <code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a>[<span title="torch.Tensor">Tensor</span>]</code>
)          –
          <div class="doc-md-description">
            <p>For <code>likelihood='classification'</code>, a torch.Tensor is returned with
a distribution over classes (similar to a Softmax).
For <code>likelihood='regression'</code>, a tuple of torch.Tensor is returned
with the mean and the predictive variance.
For <code>likelihood='regression'</code> and <code>joint=True</code>, a tuple of torch.Tensor
is returned with the mean and the predictive covariance.</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-598">598</a></span>
<span class="normal"><a href="#__codelineno-0-599">599</a></span>
<span class="normal"><a href="#__codelineno-0-600">600</a></span>
<span class="normal"><a href="#__codelineno-0-601">601</a></span>
<span class="normal"><a href="#__codelineno-0-602">602</a></span>
<span class="normal"><a href="#__codelineno-0-603">603</a></span>
<span class="normal"><a href="#__codelineno-0-604">604</a></span>
<span class="normal"><a href="#__codelineno-0-605">605</a></span>
<span class="normal"><a href="#__codelineno-0-606">606</a></span>
<span class="normal"><a href="#__codelineno-0-607">607</a></span>
<span class="normal"><a href="#__codelineno-0-608">608</a></span>
<span class="normal"><a href="#__codelineno-0-609">609</a></span>
<span class="normal"><a href="#__codelineno-0-610">610</a></span>
<span class="normal"><a href="#__codelineno-0-611">611</a></span>
<span class="normal"><a href="#__codelineno-0-612">612</a></span>
<span class="normal"><a href="#__codelineno-0-613">613</a></span>
<span class="normal"><a href="#__codelineno-0-614">614</a></span>
<span class="normal"><a href="#__codelineno-0-615">615</a></span>
<span class="normal"><a href="#__codelineno-0-616">616</a></span>
<span class="normal"><a href="#__codelineno-0-617">617</a></span>
<span class="normal"><a href="#__codelineno-0-618">618</a></span>
<span class="normal"><a href="#__codelineno-0-619">619</a></span>
<span class="normal"><a href="#__codelineno-0-620">620</a></span>
<span class="normal"><a href="#__codelineno-0-621">621</a></span>
<span class="normal"><a href="#__codelineno-0-622">622</a></span>
<span class="normal"><a href="#__codelineno-0-623">623</a></span>
<span class="normal"><a href="#__codelineno-0-624">624</a></span>
<span class="normal"><a href="#__codelineno-0-625">625</a></span>
<span class="normal"><a href="#__codelineno-0-626">626</a></span>
<span class="normal"><a href="#__codelineno-0-627">627</a></span>
<span class="normal"><a href="#__codelineno-0-628">628</a></span>
<span class="normal"><a href="#__codelineno-0-629">629</a></span>
<span class="normal"><a href="#__codelineno-0-630">630</a></span>
<span class="normal"><a href="#__codelineno-0-631">631</a></span>
<span class="normal"><a href="#__codelineno-0-632">632</a></span>
<span class="normal"><a href="#__codelineno-0-633">633</a></span>
<span class="normal"><a href="#__codelineno-0-634">634</a></span>
<span class="normal"><a href="#__codelineno-0-635">635</a></span>
<span class="normal"><a href="#__codelineno-0-636">636</a></span>
<span class="normal"><a href="#__codelineno-0-637">637</a></span>
<span class="normal"><a href="#__codelineno-0-638">638</a></span>
<span class="normal"><a href="#__codelineno-0-639">639</a></span>
<span class="normal"><a href="#__codelineno-0-640">640</a></span>
<span class="normal"><a href="#__codelineno-0-641">641</a></span>
<span class="normal"><a href="#__codelineno-0-642">642</a></span>
<span class="normal"><a href="#__codelineno-0-643">643</a></span>
<span class="normal"><a href="#__codelineno-0-644">644</a></span>
<span class="normal"><a href="#__codelineno-0-645">645</a></span>
<span class="normal"><a href="#__codelineno-0-646">646</a></span>
<span class="normal"><a href="#__codelineno-0-647">647</a></span>
<span class="normal"><a href="#__codelineno-0-648">648</a></span>
<span class="normal"><a href="#__codelineno-0-649">649</a></span>
<span class="normal"><a href="#__codelineno-0-650">650</a></span>
<span class="normal"><a href="#__codelineno-0-651">651</a></span>
<span class="normal"><a href="#__codelineno-0-652">652</a></span>
<span class="normal"><a href="#__codelineno-0-653">653</a></span>
<span class="normal"><a href="#__codelineno-0-654">654</a></span>
<span class="normal"><a href="#__codelineno-0-655">655</a></span>
<span class="normal"><a href="#__codelineno-0-656">656</a></span>
<span class="normal"><a href="#__codelineno-0-657">657</a></span>
<span class="normal"><a href="#__codelineno-0-658">658</a></span>
<span class="normal"><a href="#__codelineno-0-659">659</a></span>
<span class="normal"><a href="#__codelineno-0-660">660</a></span>
<span class="normal"><a href="#__codelineno-0-661">661</a></span>
<span class="normal"><a href="#__codelineno-0-662">662</a></span>
<span class="normal"><a href="#__codelineno-0-663">663</a></span>
<span class="normal"><a href="#__codelineno-0-664">664</a></span>
<span class="normal"><a href="#__codelineno-0-665">665</a></span>
<span class="normal"><a href="#__codelineno-0-666">666</a></span>
<span class="normal"><a href="#__codelineno-0-667">667</a></span>
<span class="normal"><a href="#__codelineno-0-668">668</a></span>
<span class="normal"><a href="#__codelineno-0-669">669</a></span>
<span class="normal"><a href="#__codelineno-0-670">670</a></span>
<span class="normal"><a href="#__codelineno-0-671">671</a></span>
<span class="normal"><a href="#__codelineno-0-672">672</a></span>
<span class="normal"><a href="#__codelineno-0-673">673</a></span>
<span class="normal"><a href="#__codelineno-0-674">674</a></span>
<span class="normal"><a href="#__codelineno-0-675">675</a></span>
<span class="normal"><a href="#__codelineno-0-676">676</a></span>
<span class="normal"><a href="#__codelineno-0-677">677</a></span>
<span class="normal"><a href="#__codelineno-0-678">678</a></span>
<span class="normal"><a href="#__codelineno-0-679">679</a></span>
<span class="normal"><a href="#__codelineno-0-680">680</a></span>
<span class="normal"><a href="#__codelineno-0-681">681</a></span>
<span class="normal"><a href="#__codelineno-0-682">682</a></span>
<span class="normal"><a href="#__codelineno-0-683">683</a></span>
<span class="normal"><a href="#__codelineno-0-684">684</a></span>
<span class="normal"><a href="#__codelineno-0-685">685</a></span>
<span class="normal"><a href="#__codelineno-0-686">686</a></span>
<span class="normal"><a href="#__codelineno-0-687">687</a></span>
<span class="normal"><a href="#__codelineno-0-688">688</a></span>
<span class="normal"><a href="#__codelineno-0-689">689</a></span>
<span class="normal"><a href="#__codelineno-0-690">690</a></span>
<span class="normal"><a href="#__codelineno-0-691">691</a></span>
<span class="normal"><a href="#__codelineno-0-692">692</a></span>
<span class="normal"><a href="#__codelineno-0-693">693</a></span>
<span class="normal"><a href="#__codelineno-0-694">694</a></span>
<span class="normal"><a href="#__codelineno-0-695">695</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-598" name="__codelineno-0-598"></a><span class="k">def</span> <span class="nf">_glm_forward_call</span><span class="p">(</span>
<a id="__codelineno-0-599" name="__codelineno-0-599"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-600" name="__codelineno-0-600"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">,</span>
<a id="__codelineno-0-601" name="__codelineno-0-601"></a>    <span class="n">likelihood</span><span class="p">:</span> <span class="n">Likelihood</span> <span class="o">|</span> <span class="nb">str</span><span class="p">,</span>
<a id="__codelineno-0-602" name="__codelineno-0-602"></a>    <span class="n">joint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-603" name="__codelineno-0-603"></a>    <span class="n">link_approx</span><span class="p">:</span> <span class="n">LinkApprox</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">PROBIT</span><span class="p">,</span>
<a id="__codelineno-0-604" name="__codelineno-0-604"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-605" name="__codelineno-0-605"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-606" name="__codelineno-0-606"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<a id="__codelineno-0-607" name="__codelineno-0-607"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the posterior predictive on input data `x` for &quot;glm&quot; pred type.</span>
<a id="__codelineno-0-608" name="__codelineno-0-608"></a>
<a id="__codelineno-0-609" name="__codelineno-0-609"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-610" name="__codelineno-0-610"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-611" name="__codelineno-0-611"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-612" name="__codelineno-0-612"></a><span class="sd">        `(batch_size, input_shape)` if tensor. If MutableMapping, must contain</span>
<a id="__codelineno-0-613" name="__codelineno-0-613"></a><span class="sd">        the said tensor.</span>
<a id="__codelineno-0-614" name="__codelineno-0-614"></a>
<a id="__codelineno-0-615" name="__codelineno-0-615"></a><span class="sd">    likelihood : Likelihood or str in {&#39;classification&#39;, &#39;regression&#39;, &#39;reward_modeling&#39;}</span>
<a id="__codelineno-0-616" name="__codelineno-0-616"></a><span class="sd">        determines the log likelihood Hessian approximation.</span>
<a id="__codelineno-0-617" name="__codelineno-0-617"></a>
<a id="__codelineno-0-618" name="__codelineno-0-618"></a><span class="sd">    link_approx : {&#39;mc&#39;, &#39;probit&#39;, &#39;bridge&#39;, &#39;bridge_norm&#39;}</span>
<a id="__codelineno-0-619" name="__codelineno-0-619"></a><span class="sd">        how to approximate the classification link function for the `&#39;glm&#39;`.</span>
<a id="__codelineno-0-620" name="__codelineno-0-620"></a><span class="sd">        For `pred_type=&#39;nn&#39;`, only &#39;mc&#39; is possible.</span>
<a id="__codelineno-0-621" name="__codelineno-0-621"></a>
<a id="__codelineno-0-622" name="__codelineno-0-622"></a><span class="sd">    joint : bool</span>
<a id="__codelineno-0-623" name="__codelineno-0-623"></a><span class="sd">        Whether to output a joint predictive distribution in regression with</span>
<a id="__codelineno-0-624" name="__codelineno-0-624"></a><span class="sd">        `pred_type=&#39;glm&#39;`. If set to `True`, the predictive distribution</span>
<a id="__codelineno-0-625" name="__codelineno-0-625"></a><span class="sd">        has the same form as GP posterior, i.e. N([f(x1), ...,f(xm)], Cov[f(x1), ..., f(xm)]).</span>
<a id="__codelineno-0-626" name="__codelineno-0-626"></a><span class="sd">        If `False`, then only outputs the marginal predictive distribution.</span>
<a id="__codelineno-0-627" name="__codelineno-0-627"></a><span class="sd">        Only available for regression and GLM predictive.</span>
<a id="__codelineno-0-628" name="__codelineno-0-628"></a>
<a id="__codelineno-0-629" name="__codelineno-0-629"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-630" name="__codelineno-0-630"></a><span class="sd">        number of samples for `link_approx=&#39;mc&#39;`.</span>
<a id="__codelineno-0-631" name="__codelineno-0-631"></a>
<a id="__codelineno-0-632" name="__codelineno-0-632"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-633" name="__codelineno-0-633"></a><span class="sd">        whether to use a diagonalized posterior predictive on the outputs.</span>
<a id="__codelineno-0-634" name="__codelineno-0-634"></a><span class="sd">        Only works for `pred_type=&#39;glm&#39;` and `link_approx=&#39;mc&#39;`.</span>
<a id="__codelineno-0-635" name="__codelineno-0-635"></a>
<a id="__codelineno-0-636" name="__codelineno-0-636"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-637" name="__codelineno-0-637"></a><span class="sd">    -------</span>
<a id="__codelineno-0-638" name="__codelineno-0-638"></a><span class="sd">    predictive: torch.Tensor or tuple[torch.Tensor]</span>
<a id="__codelineno-0-639" name="__codelineno-0-639"></a><span class="sd">        For `likelihood=&#39;classification&#39;`, a torch.Tensor is returned with</span>
<a id="__codelineno-0-640" name="__codelineno-0-640"></a><span class="sd">        a distribution over classes (similar to a Softmax).</span>
<a id="__codelineno-0-641" name="__codelineno-0-641"></a><span class="sd">        For `likelihood=&#39;regression&#39;`, a tuple of torch.Tensor is returned</span>
<a id="__codelineno-0-642" name="__codelineno-0-642"></a><span class="sd">        with the mean and the predictive variance.</span>
<a id="__codelineno-0-643" name="__codelineno-0-643"></a><span class="sd">        For `likelihood=&#39;regression&#39;` and `joint=True`, a tuple of torch.Tensor</span>
<a id="__codelineno-0-644" name="__codelineno-0-644"></a><span class="sd">        is returned with the mean and the predictive covariance.</span>
<a id="__codelineno-0-645" name="__codelineno-0-645"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-646" name="__codelineno-0-646"></a>    <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_distribution</span><span class="p">(</span>
<a id="__codelineno-0-647" name="__codelineno-0-647"></a>        <span class="n">x</span><span class="p">,</span> <span class="n">joint</span><span class="o">=</span><span class="n">joint</span> <span class="ow">and</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span>
<a id="__codelineno-0-648" name="__codelineno-0-648"></a>    <span class="p">)</span>
<a id="__codelineno-0-649" name="__codelineno-0-649"></a>
<a id="__codelineno-0-650" name="__codelineno-0-650"></a>    <span class="k">if</span> <span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-651" name="__codelineno-0-651"></a>        <span class="k">if</span> <span class="n">diagonal_output</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">joint</span><span class="p">:</span>
<a id="__codelineno-0-652" name="__codelineno-0-652"></a>            <span class="n">f_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_var</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-653" name="__codelineno-0-653"></a>        <span class="k">return</span> <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span>
<a id="__codelineno-0-654" name="__codelineno-0-654"></a>
<a id="__codelineno-0-655" name="__codelineno-0-655"></a>    <span class="k">if</span> <span class="n">link_approx</span> <span class="o">==</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">MC</span><span class="p">:</span>
<a id="__codelineno-0-656" name="__codelineno-0-656"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-657" name="__codelineno-0-657"></a>            <span class="n">f_mu</span><span class="p">,</span>
<a id="__codelineno-0-658" name="__codelineno-0-658"></a>            <span class="n">f_var</span><span class="p">,</span>
<a id="__codelineno-0-659" name="__codelineno-0-659"></a>            <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span>
<a id="__codelineno-0-660" name="__codelineno-0-660"></a>            <span class="n">diagonal_output</span><span class="o">=</span><span class="n">diagonal_output</span><span class="p">,</span>
<a id="__codelineno-0-661" name="__codelineno-0-661"></a>        <span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-0-662" name="__codelineno-0-662"></a>    <span class="k">elif</span> <span class="n">link_approx</span> <span class="o">==</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">PROBIT</span><span class="p">:</span>
<a id="__codelineno-0-663" name="__codelineno-0-663"></a>        <span class="n">kappa</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">8</span> <span class="o">*</span> <span class="n">f_var</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<a id="__codelineno-0-664" name="__codelineno-0-664"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">kappa</span> <span class="o">*</span> <span class="n">f_mu</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-665" name="__codelineno-0-665"></a>    <span class="k">elif</span> <span class="s2">&quot;bridge&quot;</span> <span class="ow">in</span> <span class="n">link_approx</span><span class="p">:</span>
<a id="__codelineno-0-666" name="__codelineno-0-666"></a>        <span class="c1"># zero mean correction</span>
<a id="__codelineno-0-667" name="__codelineno-0-667"></a>        <span class="n">f_mu</span> <span class="o">-=</span> <span class="p">(</span>
<a id="__codelineno-0-668" name="__codelineno-0-668"></a>            <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-669" name="__codelineno-0-669"></a>            <span class="o">*</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-670" name="__codelineno-0-670"></a>            <span class="o">/</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-671" name="__codelineno-0-671"></a>        <span class="p">)</span>
<a id="__codelineno-0-672" name="__codelineno-0-672"></a>        <span class="n">f_var</span> <span class="o">-=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
<a id="__codelineno-0-673" name="__codelineno-0-673"></a>            <span class="s2">&quot;bi,bj-&gt;bij&quot;</span><span class="p">,</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-674" name="__codelineno-0-674"></a>        <span class="p">)</span> <span class="o">/</span> <span class="n">f_var</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-675" name="__codelineno-0-675"></a>
<a id="__codelineno-0-676" name="__codelineno-0-676"></a>        <span class="c1"># Laplace Bridge</span>
<a id="__codelineno-0-677" name="__codelineno-0-677"></a>        <span class="n">_</span><span class="p">,</span> <span class="n">K</span> <span class="o">=</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-678" name="__codelineno-0-678"></a>        <span class="n">f_var_diag</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_var</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-679" name="__codelineno-0-679"></a>
<a id="__codelineno-0-680" name="__codelineno-0-680"></a>        <span class="c1"># optional: variance correction</span>
<a id="__codelineno-0-681" name="__codelineno-0-681"></a>        <span class="k">if</span> <span class="n">link_approx</span> <span class="o">==</span> <span class="n">LinkApprox</span><span class="o">.</span><span class="n">BRIDGE_NORM</span><span class="p">:</span>
<a id="__codelineno-0-682" name="__codelineno-0-682"></a>            <span class="n">f_var_diag_mean</span> <span class="o">=</span> <span class="n">f_var_diag</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-683" name="__codelineno-0-683"></a>            <span class="n">f_var_diag_mean</span> <span class="o">/=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span>
<a id="__codelineno-0-684" name="__codelineno-0-684"></a>                <span class="p">[</span><span class="n">K</span> <span class="o">/</span> <span class="mi">2</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>
<a id="__codelineno-0-685" name="__codelineno-0-685"></a>            <span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
<a id="__codelineno-0-686" name="__codelineno-0-686"></a>            <span class="n">f_mu</span> <span class="o">/=</span> <span class="n">f_var_diag_mean</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-687" name="__codelineno-0-687"></a>            <span class="n">f_var_diag</span> <span class="o">/=</span> <span class="n">f_var_diag_mean</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-688" name="__codelineno-0-688"></a>
<a id="__codelineno-0-689" name="__codelineno-0-689"></a>        <span class="n">sum_exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">f_mu</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-690" name="__codelineno-0-690"></a>        <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">K</span> <span class="o">+</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span> <span class="o">/</span> <span class="n">K</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sum_exp</span><span class="p">)</span> <span class="o">/</span> <span class="n">f_var_diag</span>
<a id="__codelineno-0-691" name="__codelineno-0-691"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">alpha</span> <span class="o">/</span> <span class="n">alpha</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">nan</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<a id="__codelineno-0-692" name="__codelineno-0-692"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-693" name="__codelineno-0-693"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<a id="__codelineno-0-694" name="__codelineno-0-694"></a>            <span class="s2">&quot;Prediction path invalid. Check the likelihood, pred_type, link_approx combination!&quot;</span>
<a id="__codelineno-0-695" name="__codelineno-0-695"></a>        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.FullLLLaplace._glm_functional_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">_glm_functional_samples</span>


<a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">_glm_functional_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(f_mu)">f_mu</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(f_var)">f_var</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the posterior functional on input data <code>x</code> using "glm" prediction
type.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_functional_samples(f_mu)" class="doc doc-heading doc-heading-parameter">              <b><code>f_mu</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(f_mu)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive mean <code>(batch_size, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_functional_samples(f_var)" class="doc doc-heading doc-heading-parameter">              <b><code>f_var</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(f_var)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive covariances <code>(batch_size, output_shape, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_functional_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_functional_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_functional_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_functional_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-697">697</a></span>
<span class="normal"><a href="#__codelineno-0-698">698</a></span>
<span class="normal"><a href="#__codelineno-0-699">699</a></span>
<span class="normal"><a href="#__codelineno-0-700">700</a></span>
<span class="normal"><a href="#__codelineno-0-701">701</a></span>
<span class="normal"><a href="#__codelineno-0-702">702</a></span>
<span class="normal"><a href="#__codelineno-0-703">703</a></span>
<span class="normal"><a href="#__codelineno-0-704">704</a></span>
<span class="normal"><a href="#__codelineno-0-705">705</a></span>
<span class="normal"><a href="#__codelineno-0-706">706</a></span>
<span class="normal"><a href="#__codelineno-0-707">707</a></span>
<span class="normal"><a href="#__codelineno-0-708">708</a></span>
<span class="normal"><a href="#__codelineno-0-709">709</a></span>
<span class="normal"><a href="#__codelineno-0-710">710</a></span>
<span class="normal"><a href="#__codelineno-0-711">711</a></span>
<span class="normal"><a href="#__codelineno-0-712">712</a></span>
<span class="normal"><a href="#__codelineno-0-713">713</a></span>
<span class="normal"><a href="#__codelineno-0-714">714</a></span>
<span class="normal"><a href="#__codelineno-0-715">715</a></span>
<span class="normal"><a href="#__codelineno-0-716">716</a></span>
<span class="normal"><a href="#__codelineno-0-717">717</a></span>
<span class="normal"><a href="#__codelineno-0-718">718</a></span>
<span class="normal"><a href="#__codelineno-0-719">719</a></span>
<span class="normal"><a href="#__codelineno-0-720">720</a></span>
<span class="normal"><a href="#__codelineno-0-721">721</a></span>
<span class="normal"><a href="#__codelineno-0-722">722</a></span>
<span class="normal"><a href="#__codelineno-0-723">723</a></span>
<span class="normal"><a href="#__codelineno-0-724">724</a></span>
<span class="normal"><a href="#__codelineno-0-725">725</a></span>
<span class="normal"><a href="#__codelineno-0-726">726</a></span>
<span class="normal"><a href="#__codelineno-0-727">727</a></span>
<span class="normal"><a href="#__codelineno-0-728">728</a></span>
<span class="normal"><a href="#__codelineno-0-729">729</a></span>
<span class="normal"><a href="#__codelineno-0-730">730</a></span>
<span class="normal"><a href="#__codelineno-0-731">731</a></span>
<span class="normal"><a href="#__codelineno-0-732">732</a></span>
<span class="normal"><a href="#__codelineno-0-733">733</a></span>
<span class="normal"><a href="#__codelineno-0-734">734</a></span>
<span class="normal"><a href="#__codelineno-0-735">735</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-697" name="__codelineno-0-697"></a><span class="k">def</span> <span class="nf">_glm_functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-698" name="__codelineno-0-698"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-699" name="__codelineno-0-699"></a>    <span class="n">f_mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-700" name="__codelineno-0-700"></a>    <span class="n">f_var</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-701" name="__codelineno-0-701"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-702" name="__codelineno-0-702"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-703" name="__codelineno-0-703"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-704" name="__codelineno-0-704"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-705" name="__codelineno-0-705"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the posterior functional on input data `x` using &quot;glm&quot; prediction</span>
<a id="__codelineno-0-706" name="__codelineno-0-706"></a><span class="sd">    type.</span>
<a id="__codelineno-0-707" name="__codelineno-0-707"></a>
<a id="__codelineno-0-708" name="__codelineno-0-708"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-709" name="__codelineno-0-709"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-710" name="__codelineno-0-710"></a><span class="sd">    f_mu : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-711" name="__codelineno-0-711"></a><span class="sd">        glm predictive mean `(batch_size, output_shape)`</span>
<a id="__codelineno-0-712" name="__codelineno-0-712"></a>
<a id="__codelineno-0-713" name="__codelineno-0-713"></a><span class="sd">    f_var : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-714" name="__codelineno-0-714"></a><span class="sd">        glm predictive covariances `(batch_size, output_shape, output_shape)`</span>
<a id="__codelineno-0-715" name="__codelineno-0-715"></a>
<a id="__codelineno-0-716" name="__codelineno-0-716"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-717" name="__codelineno-0-717"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-718" name="__codelineno-0-718"></a>
<a id="__codelineno-0-719" name="__codelineno-0-719"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-720" name="__codelineno-0-720"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-721" name="__codelineno-0-721"></a>
<a id="__codelineno-0-722" name="__codelineno-0-722"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-723" name="__codelineno-0-723"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-724" name="__codelineno-0-724"></a>
<a id="__codelineno-0-725" name="__codelineno-0-725"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-726" name="__codelineno-0-726"></a><span class="sd">    -------</span>
<a id="__codelineno-0-727" name="__codelineno-0-727"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-728" name="__codelineno-0-728"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-729" name="__codelineno-0-729"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-730" name="__codelineno-0-730"></a>    <span class="k">assert</span> <span class="n">f_var</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">f_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">f_mu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>
<a id="__codelineno-0-731" name="__codelineno-0-731"></a>
<a id="__codelineno-0-732" name="__codelineno-0-732"></a>    <span class="k">if</span> <span class="n">diagonal_output</span><span class="p">:</span>
<a id="__codelineno-0-733" name="__codelineno-0-733"></a>        <span class="n">f_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_var</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<a id="__codelineno-0-734" name="__codelineno-0-734"></a>
<a id="__codelineno-0-735" name="__codelineno-0-735"></a>    <span class="k">return</span> <span class="n">normal_samples</span><span class="p">(</span><span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">generator</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.FullLLLaplace._glm_predictive_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">_glm_predictive_samples</span>


<a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">_glm_predictive_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(f_mu)">f_mu</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(f_var)">f_var</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the posterior predictive on input data <code>x</code> using "glm" prediction
type. I.e., the inverse-link function correponding to the likelihood is applied
on top of the functional sample.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_predictive_samples(f_mu)" class="doc doc-heading doc-heading-parameter">              <b><code>f_mu</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(f_mu)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive mean <code>(batch_size, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_predictive_samples(f_var)" class="doc doc-heading doc-heading-parameter">              <b><code>f_var</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(f_var)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>glm predictive covariances <code>(batch_size, output_shape, output_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_predictive_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_predictive_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace._glm_predictive_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.FullLLLaplace._glm_predictive_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-737">737</a></span>
<span class="normal"><a href="#__codelineno-0-738">738</a></span>
<span class="normal"><a href="#__codelineno-0-739">739</a></span>
<span class="normal"><a href="#__codelineno-0-740">740</a></span>
<span class="normal"><a href="#__codelineno-0-741">741</a></span>
<span class="normal"><a href="#__codelineno-0-742">742</a></span>
<span class="normal"><a href="#__codelineno-0-743">743</a></span>
<span class="normal"><a href="#__codelineno-0-744">744</a></span>
<span class="normal"><a href="#__codelineno-0-745">745</a></span>
<span class="normal"><a href="#__codelineno-0-746">746</a></span>
<span class="normal"><a href="#__codelineno-0-747">747</a></span>
<span class="normal"><a href="#__codelineno-0-748">748</a></span>
<span class="normal"><a href="#__codelineno-0-749">749</a></span>
<span class="normal"><a href="#__codelineno-0-750">750</a></span>
<span class="normal"><a href="#__codelineno-0-751">751</a></span>
<span class="normal"><a href="#__codelineno-0-752">752</a></span>
<span class="normal"><a href="#__codelineno-0-753">753</a></span>
<span class="normal"><a href="#__codelineno-0-754">754</a></span>
<span class="normal"><a href="#__codelineno-0-755">755</a></span>
<span class="normal"><a href="#__codelineno-0-756">756</a></span>
<span class="normal"><a href="#__codelineno-0-757">757</a></span>
<span class="normal"><a href="#__codelineno-0-758">758</a></span>
<span class="normal"><a href="#__codelineno-0-759">759</a></span>
<span class="normal"><a href="#__codelineno-0-760">760</a></span>
<span class="normal"><a href="#__codelineno-0-761">761</a></span>
<span class="normal"><a href="#__codelineno-0-762">762</a></span>
<span class="normal"><a href="#__codelineno-0-763">763</a></span>
<span class="normal"><a href="#__codelineno-0-764">764</a></span>
<span class="normal"><a href="#__codelineno-0-765">765</a></span>
<span class="normal"><a href="#__codelineno-0-766">766</a></span>
<span class="normal"><a href="#__codelineno-0-767">767</a></span>
<span class="normal"><a href="#__codelineno-0-768">768</a></span>
<span class="normal"><a href="#__codelineno-0-769">769</a></span>
<span class="normal"><a href="#__codelineno-0-770">770</a></span>
<span class="normal"><a href="#__codelineno-0-771">771</a></span>
<span class="normal"><a href="#__codelineno-0-772">772</a></span>
<span class="normal"><a href="#__codelineno-0-773">773</a></span>
<span class="normal"><a href="#__codelineno-0-774">774</a></span>
<span class="normal"><a href="#__codelineno-0-775">775</a></span>
<span class="normal"><a href="#__codelineno-0-776">776</a></span>
<span class="normal"><a href="#__codelineno-0-777">777</a></span>
<span class="normal"><a href="#__codelineno-0-778">778</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-737" name="__codelineno-0-737"></a><span class="k">def</span> <span class="nf">_glm_predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-738" name="__codelineno-0-738"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-739" name="__codelineno-0-739"></a>    <span class="n">f_mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-740" name="__codelineno-0-740"></a>    <span class="n">f_var</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<a id="__codelineno-0-741" name="__codelineno-0-741"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<a id="__codelineno-0-742" name="__codelineno-0-742"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-743" name="__codelineno-0-743"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-744" name="__codelineno-0-744"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-745" name="__codelineno-0-745"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the posterior predictive on input data `x` using &quot;glm&quot; prediction</span>
<a id="__codelineno-0-746" name="__codelineno-0-746"></a><span class="sd">    type. I.e., the inverse-link function correponding to the likelihood is applied</span>
<a id="__codelineno-0-747" name="__codelineno-0-747"></a><span class="sd">    on top of the functional sample.</span>
<a id="__codelineno-0-748" name="__codelineno-0-748"></a>
<a id="__codelineno-0-749" name="__codelineno-0-749"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-750" name="__codelineno-0-750"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-751" name="__codelineno-0-751"></a><span class="sd">    f_mu : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-752" name="__codelineno-0-752"></a><span class="sd">        glm predictive mean `(batch_size, output_shape)`</span>
<a id="__codelineno-0-753" name="__codelineno-0-753"></a>
<a id="__codelineno-0-754" name="__codelineno-0-754"></a><span class="sd">    f_var : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-755" name="__codelineno-0-755"></a><span class="sd">        glm predictive covariances `(batch_size, output_shape, output_shape)`</span>
<a id="__codelineno-0-756" name="__codelineno-0-756"></a>
<a id="__codelineno-0-757" name="__codelineno-0-757"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-758" name="__codelineno-0-758"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-759" name="__codelineno-0-759"></a>
<a id="__codelineno-0-760" name="__codelineno-0-760"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-761" name="__codelineno-0-761"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-762" name="__codelineno-0-762"></a>
<a id="__codelineno-0-763" name="__codelineno-0-763"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-764" name="__codelineno-0-764"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-765" name="__codelineno-0-765"></a>
<a id="__codelineno-0-766" name="__codelineno-0-766"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-767" name="__codelineno-0-767"></a><span class="sd">    -------</span>
<a id="__codelineno-0-768" name="__codelineno-0-768"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-769" name="__codelineno-0-769"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-770" name="__codelineno-0-770"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-771" name="__codelineno-0-771"></a>    <span class="n">f_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-772" name="__codelineno-0-772"></a>        <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span><span class="p">,</span> <span class="n">generator</span>
<a id="__codelineno-0-773" name="__codelineno-0-773"></a>    <span class="p">)</span>
<a id="__codelineno-0-774" name="__codelineno-0-774"></a>
<a id="__codelineno-0-775" name="__codelineno-0-775"></a>    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">likelihood</span> <span class="o">==</span> <span class="n">Likelihood</span><span class="o">.</span><span class="n">REGRESSION</span><span class="p">:</span>
<a id="__codelineno-0-776" name="__codelineno-0-776"></a>        <span class="k">return</span> <span class="n">f_samples</span>
<a id="__codelineno-0-777" name="__codelineno-0-777"></a>    <span class="k">else</span><span class="p">:</span>
<a id="__codelineno-0-778" name="__codelineno-0-778"></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">f_samples</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.FullLLLaplace.log_prob" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">log_prob</span>


<a href="#laplace.lllaplace.FullLLLaplace.log_prob" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">log_prob</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.log_prob(value)">value</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.log_prob(normalized)">normalized</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Compute the log probability under the (current) Laplace approximation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.log_prob(value)" class="doc doc-heading doc-heading-parameter">              <b><code>value</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.log_prob(value)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span></code>)
          –
          <div class="doc-md-description">
            
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.log_prob(normalized)" class="doc doc-heading doc-heading-parameter">              <b><code>normalized</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.log_prob(normalized)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>True</code>
)
          –
          <div class="doc-md-description">
            <p>whether to return log of a properly normalized Gaussian or just the
terms that depend on <code>value</code>.</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>log_prob</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-996"> 996</a></span>
<span class="normal"><a href="#__codelineno-0-997"> 997</a></span>
<span class="normal"><a href="#__codelineno-0-998"> 998</a></span>
<span class="normal"><a href="#__codelineno-0-999"> 999</a></span>
<span class="normal"><a href="#__codelineno-0-1000">1000</a></span>
<span class="normal"><a href="#__codelineno-0-1001">1001</a></span>
<span class="normal"><a href="#__codelineno-0-1002">1002</a></span>
<span class="normal"><a href="#__codelineno-0-1003">1003</a></span>
<span class="normal"><a href="#__codelineno-0-1004">1004</a></span>
<span class="normal"><a href="#__codelineno-0-1005">1005</a></span>
<span class="normal"><a href="#__codelineno-0-1006">1006</a></span>
<span class="normal"><a href="#__codelineno-0-1007">1007</a></span>
<span class="normal"><a href="#__codelineno-0-1008">1008</a></span>
<span class="normal"><a href="#__codelineno-0-1009">1009</a></span>
<span class="normal"><a href="#__codelineno-0-1010">1010</a></span>
<span class="normal"><a href="#__codelineno-0-1011">1011</a></span>
<span class="normal"><a href="#__codelineno-0-1012">1012</a></span>
<span class="normal"><a href="#__codelineno-0-1013">1013</a></span>
<span class="normal"><a href="#__codelineno-0-1014">1014</a></span>
<span class="normal"><a href="#__codelineno-0-1015">1015</a></span>
<span class="normal"><a href="#__codelineno-0-1016">1016</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-996" name="__codelineno-0-996"></a><span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">normalized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-997" name="__codelineno-0-997"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the log probability under the (current) Laplace approximation.</span>
<a id="__codelineno-0-998" name="__codelineno-0-998"></a>
<a id="__codelineno-0-999" name="__codelineno-0-999"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1000" name="__codelineno-0-1000"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1001" name="__codelineno-0-1001"></a><span class="sd">    value: torch.Tensor</span>
<a id="__codelineno-0-1002" name="__codelineno-0-1002"></a><span class="sd">    normalized : bool, default=True</span>
<a id="__codelineno-0-1003" name="__codelineno-0-1003"></a><span class="sd">        whether to return log of a properly normalized Gaussian or just the</span>
<a id="__codelineno-0-1004" name="__codelineno-0-1004"></a><span class="sd">        terms that depend on `value`.</span>
<a id="__codelineno-0-1005" name="__codelineno-0-1005"></a>
<a id="__codelineno-0-1006" name="__codelineno-0-1006"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1007" name="__codelineno-0-1007"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1008" name="__codelineno-0-1008"></a><span class="sd">    log_prob : torch.Tensor</span>
<a id="__codelineno-0-1009" name="__codelineno-0-1009"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1010" name="__codelineno-0-1010"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">normalized</span><span class="p">:</span>
<a id="__codelineno-0-1011" name="__codelineno-0-1011"></a>        <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">square_norm</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-0-1012" name="__codelineno-0-1012"></a>    <span class="n">log_prob</span> <span class="o">=</span> <span class="p">(</span>
<a id="__codelineno-0-1013" name="__codelineno-0-1013"></a>        <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">n_params</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">pi</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_det_posterior_precision</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-0-1014" name="__codelineno-0-1014"></a>    <span class="p">)</span>
<a id="__codelineno-0-1015" name="__codelineno-0-1015"></a>    <span class="n">log_prob</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">square_norm</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
<a id="__codelineno-0-1016" name="__codelineno-0-1016"></a>    <span class="k">return</span> <span class="n">log_prob</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.FullLLLaplace.functional_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">functional_samples</span>


<a href="#laplace.lllaplace.FullLLLaplace.functional_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">functional_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.functional_samples(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.functional_samples(pred_type)">pred_type</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType" href="../enums/#laplace.utils.enums.PredType">PredType</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType.GLM" href="../enums/#laplace.utils.enums.PredType.GLM">GLM</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.functional_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.functional_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.functional_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the function-space posterior on input data <code>x</code>.
Can be used, for example, for Thompson sampling or to compute an arbitrary
expectation.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.functional_samples(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.functional_samples(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>input data <code>(batch_size, input_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.functional_samples(pred_type)" class="doc doc-heading doc-heading-parameter">              <b><code>pred_type</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.functional_samples(pred_type)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;glm&#39;, &#39;nn&#39;)</code>, default:
                  <code>&#39;glm&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>type of posterior predictive, linearized GLM predictive or neural
network sampling predictive. The GLM predictive is consistent with
the curvature approximations used here.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.functional_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.functional_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.functional_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.functional_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.
Only applies when <code>pred_type='glm'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.functional_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.functional_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1154">1154</a></span>
<span class="normal"><a href="#__codelineno-0-1155">1155</a></span>
<span class="normal"><a href="#__codelineno-0-1156">1156</a></span>
<span class="normal"><a href="#__codelineno-0-1157">1157</a></span>
<span class="normal"><a href="#__codelineno-0-1158">1158</a></span>
<span class="normal"><a href="#__codelineno-0-1159">1159</a></span>
<span class="normal"><a href="#__codelineno-0-1160">1160</a></span>
<span class="normal"><a href="#__codelineno-0-1161">1161</a></span>
<span class="normal"><a href="#__codelineno-0-1162">1162</a></span>
<span class="normal"><a href="#__codelineno-0-1163">1163</a></span>
<span class="normal"><a href="#__codelineno-0-1164">1164</a></span>
<span class="normal"><a href="#__codelineno-0-1165">1165</a></span>
<span class="normal"><a href="#__codelineno-0-1166">1166</a></span>
<span class="normal"><a href="#__codelineno-0-1167">1167</a></span>
<span class="normal"><a href="#__codelineno-0-1168">1168</a></span>
<span class="normal"><a href="#__codelineno-0-1169">1169</a></span>
<span class="normal"><a href="#__codelineno-0-1170">1170</a></span>
<span class="normal"><a href="#__codelineno-0-1171">1171</a></span>
<span class="normal"><a href="#__codelineno-0-1172">1172</a></span>
<span class="normal"><a href="#__codelineno-0-1173">1173</a></span>
<span class="normal"><a href="#__codelineno-0-1174">1174</a></span>
<span class="normal"><a href="#__codelineno-0-1175">1175</a></span>
<span class="normal"><a href="#__codelineno-0-1176">1176</a></span>
<span class="normal"><a href="#__codelineno-0-1177">1177</a></span>
<span class="normal"><a href="#__codelineno-0-1178">1178</a></span>
<span class="normal"><a href="#__codelineno-0-1179">1179</a></span>
<span class="normal"><a href="#__codelineno-0-1180">1180</a></span>
<span class="normal"><a href="#__codelineno-0-1181">1181</a></span>
<span class="normal"><a href="#__codelineno-0-1182">1182</a></span>
<span class="normal"><a href="#__codelineno-0-1183">1183</a></span>
<span class="normal"><a href="#__codelineno-0-1184">1184</a></span>
<span class="normal"><a href="#__codelineno-0-1185">1185</a></span>
<span class="normal"><a href="#__codelineno-0-1186">1186</a></span>
<span class="normal"><a href="#__codelineno-0-1187">1187</a></span>
<span class="normal"><a href="#__codelineno-0-1188">1188</a></span>
<span class="normal"><a href="#__codelineno-0-1189">1189</a></span>
<span class="normal"><a href="#__codelineno-0-1190">1190</a></span>
<span class="normal"><a href="#__codelineno-0-1191">1191</a></span>
<span class="normal"><a href="#__codelineno-0-1192">1192</a></span>
<span class="normal"><a href="#__codelineno-0-1193">1193</a></span>
<span class="normal"><a href="#__codelineno-0-1194">1194</a></span>
<span class="normal"><a href="#__codelineno-0-1195">1195</a></span>
<span class="normal"><a href="#__codelineno-0-1196">1196</a></span>
<span class="normal"><a href="#__codelineno-0-1197">1197</a></span>
<span class="normal"><a href="#__codelineno-0-1198">1198</a></span>
<span class="normal"><a href="#__codelineno-0-1199">1199</a></span>
<span class="normal"><a href="#__codelineno-0-1200">1200</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1154" name="__codelineno-0-1154"></a><span class="k">def</span> <span class="nf">functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-1155" name="__codelineno-0-1155"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1156" name="__codelineno-0-1156"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1157" name="__codelineno-0-1157"></a>    <span class="n">pred_type</span><span class="p">:</span> <span class="n">PredType</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">,</span>
<a id="__codelineno-0-1158" name="__codelineno-0-1158"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-1159" name="__codelineno-0-1159"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1160" name="__codelineno-0-1160"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1161" name="__codelineno-0-1161"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1162" name="__codelineno-0-1162"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the function-space posterior on input data `x`.</span>
<a id="__codelineno-0-1163" name="__codelineno-0-1163"></a><span class="sd">    Can be used, for example, for Thompson sampling or to compute an arbitrary</span>
<a id="__codelineno-0-1164" name="__codelineno-0-1164"></a><span class="sd">    expectation.</span>
<a id="__codelineno-0-1165" name="__codelineno-0-1165"></a>
<a id="__codelineno-0-1166" name="__codelineno-0-1166"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1167" name="__codelineno-0-1167"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1168" name="__codelineno-0-1168"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-1169" name="__codelineno-0-1169"></a><span class="sd">        input data `(batch_size, input_shape)`</span>
<a id="__codelineno-0-1170" name="__codelineno-0-1170"></a>
<a id="__codelineno-0-1171" name="__codelineno-0-1171"></a><span class="sd">    pred_type : {&#39;glm&#39;, &#39;nn&#39;}, default=&#39;glm&#39;</span>
<a id="__codelineno-0-1172" name="__codelineno-0-1172"></a><span class="sd">        type of posterior predictive, linearized GLM predictive or neural</span>
<a id="__codelineno-0-1173" name="__codelineno-0-1173"></a><span class="sd">        network sampling predictive. The GLM predictive is consistent with</span>
<a id="__codelineno-0-1174" name="__codelineno-0-1174"></a><span class="sd">        the curvature approximations used here.</span>
<a id="__codelineno-0-1175" name="__codelineno-0-1175"></a>
<a id="__codelineno-0-1176" name="__codelineno-0-1176"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-1177" name="__codelineno-0-1177"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-1178" name="__codelineno-0-1178"></a>
<a id="__codelineno-0-1179" name="__codelineno-0-1179"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-1180" name="__codelineno-0-1180"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-1181" name="__codelineno-0-1181"></a><span class="sd">        Only applies when `pred_type=&#39;glm&#39;`.</span>
<a id="__codelineno-0-1182" name="__codelineno-0-1182"></a>
<a id="__codelineno-0-1183" name="__codelineno-0-1183"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1184" name="__codelineno-0-1184"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-1185" name="__codelineno-0-1185"></a>
<a id="__codelineno-0-1186" name="__codelineno-0-1186"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1187" name="__codelineno-0-1187"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1188" name="__codelineno-0-1188"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-1189" name="__codelineno-0-1189"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-1190" name="__codelineno-0-1190"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1191" name="__codelineno-0-1191"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">PredType</span><span class="o">.</span><span class="n">__members__</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<a id="__codelineno-0-1192" name="__codelineno-0-1192"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only glm and nn supported as prediction types.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1193" name="__codelineno-0-1193"></a>
<a id="__codelineno-0-1194" name="__codelineno-0-1194"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">:</span>
<a id="__codelineno-0-1195" name="__codelineno-0-1195"></a>        <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_distribution</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-1196" name="__codelineno-0-1196"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_functional_samples</span><span class="p">(</span>
<a id="__codelineno-0-1197" name="__codelineno-0-1197"></a>            <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span><span class="p">,</span> <span class="n">generator</span>
<a id="__codelineno-0-1198" name="__codelineno-0-1198"></a>        <span class="p">)</span>
<a id="__codelineno-0-1199" name="__codelineno-0-1199"></a>    <span class="k">else</span><span class="p">:</span>  <span class="c1"># &#39;nn&#39;</span>
<a id="__codelineno-0-1200" name="__codelineno-0-1200"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_functional_samples</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">generator</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.FullLLLaplace.predictive_samples" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">predictive_samples</span>


<a href="#laplace.lllaplace.FullLLLaplace.predictive_samples" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">predictive_samples</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.predictive_samples(x)">x</a></span><span class="p">:</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span><span class="p">,</span> <span class="n"><span title="torch.Tensor">Tensor</span></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a></span><span class="p">],</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.predictive_samples(pred_type)">pred_type</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType" href="../enums/#laplace.utils.enums.PredType">PredType</a></span> <span class="o">|</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></span> <span class="o">=</span> <span class="n"><a class="autorefs autorefs-internal" title="laplace.utils.enums.PredType.GLM" href="../enums/#laplace.utils.enums.PredType.GLM">GLM</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.predictive_samples(n_samples)">n_samples</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.predictive_samples(diagonal_output)">diagonal_output</a></span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.predictive_samples(generator)">generator</a></span><span class="p">:</span> <span class="n"><span title="torch.Generator">Generator</span></span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><span title="torch.Tensor">Tensor</span></span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Sample from the posterior predictive on input data <code>x</code>. I.e., the respective
inverse-link function (e.g. softmax) is applied on top of the functional
sample.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.predictive_samples(x)" class="doc doc-heading doc-heading-parameter">              <b><code>x</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(x)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Tensor">Tensor</span> or <a class="autorefs autorefs-external" title="collections.abc.MutableMapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping">MutableMapping</a></code>)
          –
          <div class="doc-md-description">
            <p>input data <code>(batch_size, input_shape)</code></p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.predictive_samples(pred_type)" class="doc doc-heading doc-heading-parameter">              <b><code>pred_type</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(pred_type)" class="headerlink" title="Permanent link">#</a></h4>              (<code>(&#39;glm&#39;, &#39;nn&#39;)</code>, default:
                  <code>&#39;glm&#39;</code>
)
          –
          <div class="doc-md-description">
            <p>type of posterior predictive, linearized GLM predictive or neural
network sampling predictive. The GLM predictive is consistent with
the curvature approximations used here.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.predictive_samples(n_samples)" class="doc doc-heading doc-heading-parameter">              <b><code>n_samples</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(n_samples)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>, default:
                  <code>100</code>
)
          –
          <div class="doc-md-description">
            <p>number of samples</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.predictive_samples(diagonal_output)" class="doc doc-heading doc-heading-parameter">              <b><code>diagonal_output</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(diagonal_output)" class="headerlink" title="Permanent link">#</a></h4>              (<code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>, default:
                  <code>False</code>
)
          –
          <div class="doc-md-description">
            <p>whether to use a diagonalized glm posterior predictive on the outputs.
Only applies when <code>pred_type='glm'</code>.</p>
          </div>
        </li>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.predictive_samples(generator)" class="doc doc-heading doc-heading-parameter">              <b><code>generator</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.predictive_samples(generator)" class="headerlink" title="Permanent link">#</a></h4>              (<code><span title="torch.Generator">Generator</span></code>, default:
                  <code>None</code>
)
          –
          <div class="doc-md-description">
            <p>random number generator to control the samples (if sampling used)</p>
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>samples</code></b> (              <code><span title="torch.Tensor">Tensor</span></code>
)          –
          <div class="doc-md-description">
            <p>samples <code>(n_samples, batch_size, output_shape)</code></p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/baselaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-1202">1202</a></span>
<span class="normal"><a href="#__codelineno-0-1203">1203</a></span>
<span class="normal"><a href="#__codelineno-0-1204">1204</a></span>
<span class="normal"><a href="#__codelineno-0-1205">1205</a></span>
<span class="normal"><a href="#__codelineno-0-1206">1206</a></span>
<span class="normal"><a href="#__codelineno-0-1207">1207</a></span>
<span class="normal"><a href="#__codelineno-0-1208">1208</a></span>
<span class="normal"><a href="#__codelineno-0-1209">1209</a></span>
<span class="normal"><a href="#__codelineno-0-1210">1210</a></span>
<span class="normal"><a href="#__codelineno-0-1211">1211</a></span>
<span class="normal"><a href="#__codelineno-0-1212">1212</a></span>
<span class="normal"><a href="#__codelineno-0-1213">1213</a></span>
<span class="normal"><a href="#__codelineno-0-1214">1214</a></span>
<span class="normal"><a href="#__codelineno-0-1215">1215</a></span>
<span class="normal"><a href="#__codelineno-0-1216">1216</a></span>
<span class="normal"><a href="#__codelineno-0-1217">1217</a></span>
<span class="normal"><a href="#__codelineno-0-1218">1218</a></span>
<span class="normal"><a href="#__codelineno-0-1219">1219</a></span>
<span class="normal"><a href="#__codelineno-0-1220">1220</a></span>
<span class="normal"><a href="#__codelineno-0-1221">1221</a></span>
<span class="normal"><a href="#__codelineno-0-1222">1222</a></span>
<span class="normal"><a href="#__codelineno-0-1223">1223</a></span>
<span class="normal"><a href="#__codelineno-0-1224">1224</a></span>
<span class="normal"><a href="#__codelineno-0-1225">1225</a></span>
<span class="normal"><a href="#__codelineno-0-1226">1226</a></span>
<span class="normal"><a href="#__codelineno-0-1227">1227</a></span>
<span class="normal"><a href="#__codelineno-0-1228">1228</a></span>
<span class="normal"><a href="#__codelineno-0-1229">1229</a></span>
<span class="normal"><a href="#__codelineno-0-1230">1230</a></span>
<span class="normal"><a href="#__codelineno-0-1231">1231</a></span>
<span class="normal"><a href="#__codelineno-0-1232">1232</a></span>
<span class="normal"><a href="#__codelineno-0-1233">1233</a></span>
<span class="normal"><a href="#__codelineno-0-1234">1234</a></span>
<span class="normal"><a href="#__codelineno-0-1235">1235</a></span>
<span class="normal"><a href="#__codelineno-0-1236">1236</a></span>
<span class="normal"><a href="#__codelineno-0-1237">1237</a></span>
<span class="normal"><a href="#__codelineno-0-1238">1238</a></span>
<span class="normal"><a href="#__codelineno-0-1239">1239</a></span>
<span class="normal"><a href="#__codelineno-0-1240">1240</a></span>
<span class="normal"><a href="#__codelineno-0-1241">1241</a></span>
<span class="normal"><a href="#__codelineno-0-1242">1242</a></span>
<span class="normal"><a href="#__codelineno-0-1243">1243</a></span>
<span class="normal"><a href="#__codelineno-0-1244">1244</a></span>
<span class="normal"><a href="#__codelineno-0-1245">1245</a></span>
<span class="normal"><a href="#__codelineno-0-1246">1246</a></span>
<span class="normal"><a href="#__codelineno-0-1247">1247</a></span>
<span class="normal"><a href="#__codelineno-0-1248">1248</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-1202" name="__codelineno-0-1202"></a><span class="k">def</span> <span class="nf">predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-1203" name="__codelineno-0-1203"></a>    <span class="bp">self</span><span class="p">,</span>
<a id="__codelineno-0-1204" name="__codelineno-0-1204"></a>    <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">MutableMapping</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">Any</span><span class="p">],</span>
<a id="__codelineno-0-1205" name="__codelineno-0-1205"></a>    <span class="n">pred_type</span><span class="p">:</span> <span class="n">PredType</span> <span class="o">|</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">,</span>
<a id="__codelineno-0-1206" name="__codelineno-0-1206"></a>    <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
<a id="__codelineno-0-1207" name="__codelineno-0-1207"></a>    <span class="n">diagonal_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-0-1208" name="__codelineno-0-1208"></a>    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<a id="__codelineno-0-1209" name="__codelineno-0-1209"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<a id="__codelineno-0-1210" name="__codelineno-0-1210"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sample from the posterior predictive on input data `x`. I.e., the respective</span>
<a id="__codelineno-0-1211" name="__codelineno-0-1211"></a><span class="sd">    inverse-link function (e.g. softmax) is applied on top of the functional</span>
<a id="__codelineno-0-1212" name="__codelineno-0-1212"></a><span class="sd">    sample.</span>
<a id="__codelineno-0-1213" name="__codelineno-0-1213"></a>
<a id="__codelineno-0-1214" name="__codelineno-0-1214"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-1215" name="__codelineno-0-1215"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-1216" name="__codelineno-0-1216"></a><span class="sd">    x : torch.Tensor or MutableMapping</span>
<a id="__codelineno-0-1217" name="__codelineno-0-1217"></a><span class="sd">        input data `(batch_size, input_shape)`</span>
<a id="__codelineno-0-1218" name="__codelineno-0-1218"></a>
<a id="__codelineno-0-1219" name="__codelineno-0-1219"></a><span class="sd">    pred_type : {&#39;glm&#39;, &#39;nn&#39;}, default=&#39;glm&#39;</span>
<a id="__codelineno-0-1220" name="__codelineno-0-1220"></a><span class="sd">        type of posterior predictive, linearized GLM predictive or neural</span>
<a id="__codelineno-0-1221" name="__codelineno-0-1221"></a><span class="sd">        network sampling predictive. The GLM predictive is consistent with</span>
<a id="__codelineno-0-1222" name="__codelineno-0-1222"></a><span class="sd">        the curvature approximations used here.</span>
<a id="__codelineno-0-1223" name="__codelineno-0-1223"></a>
<a id="__codelineno-0-1224" name="__codelineno-0-1224"></a><span class="sd">    n_samples : int</span>
<a id="__codelineno-0-1225" name="__codelineno-0-1225"></a><span class="sd">        number of samples</span>
<a id="__codelineno-0-1226" name="__codelineno-0-1226"></a>
<a id="__codelineno-0-1227" name="__codelineno-0-1227"></a><span class="sd">    diagonal_output : bool</span>
<a id="__codelineno-0-1228" name="__codelineno-0-1228"></a><span class="sd">        whether to use a diagonalized glm posterior predictive on the outputs.</span>
<a id="__codelineno-0-1229" name="__codelineno-0-1229"></a><span class="sd">        Only applies when `pred_type=&#39;glm&#39;`.</span>
<a id="__codelineno-0-1230" name="__codelineno-0-1230"></a>
<a id="__codelineno-0-1231" name="__codelineno-0-1231"></a><span class="sd">    generator : torch.Generator, optional</span>
<a id="__codelineno-0-1232" name="__codelineno-0-1232"></a><span class="sd">        random number generator to control the samples (if sampling used)</span>
<a id="__codelineno-0-1233" name="__codelineno-0-1233"></a>
<a id="__codelineno-0-1234" name="__codelineno-0-1234"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-1235" name="__codelineno-0-1235"></a><span class="sd">    -------</span>
<a id="__codelineno-0-1236" name="__codelineno-0-1236"></a><span class="sd">    samples : torch.Tensor</span>
<a id="__codelineno-0-1237" name="__codelineno-0-1237"></a><span class="sd">        samples `(n_samples, batch_size, output_shape)`</span>
<a id="__codelineno-0-1238" name="__codelineno-0-1238"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-1239" name="__codelineno-0-1239"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">PredType</span><span class="o">.</span><span class="n">__members__</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
<a id="__codelineno-0-1240" name="__codelineno-0-1240"></a>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only glm and nn supported as prediction types.&quot;</span><span class="p">)</span>
<a id="__codelineno-0-1241" name="__codelineno-0-1241"></a>
<a id="__codelineno-0-1242" name="__codelineno-0-1242"></a>    <span class="k">if</span> <span class="n">pred_type</span> <span class="o">==</span> <span class="n">PredType</span><span class="o">.</span><span class="n">GLM</span><span class="p">:</span>
<a id="__codelineno-0-1243" name="__codelineno-0-1243"></a>        <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_distribution</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<a id="__codelineno-0-1244" name="__codelineno-0-1244"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_glm_predictive_samples</span><span class="p">(</span>
<a id="__codelineno-0-1245" name="__codelineno-0-1245"></a>            <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">diagonal_output</span><span class="p">,</span> <span class="n">generator</span>
<a id="__codelineno-0-1246" name="__codelineno-0-1246"></a>        <span class="p">)</span>
<a id="__codelineno-0-1247" name="__codelineno-0-1247"></a>    <span class="k">else</span><span class="p">:</span>  <span class="c1"># &#39;nn&#39;</span>
<a id="__codelineno-0-1248" name="__codelineno-0-1248"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nn_predictive_samples</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">generator</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="laplace.lllaplace.FullLLLaplace.functional_variance_fast" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">functional_variance_fast</span>


<a href="#laplace.lllaplace.FullLLLaplace.functional_variance_fast" class="headerlink" title="Permanent link">#</a></h3>
<div class="doc-signature highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nf">functional_variance_fast</span><span class="p">(</span><span class="n"><a class="autorefs autorefs-internal" href="#laplace.lllaplace.FullLLLaplace.functional_variance_fast(X)">X</a></span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <p>Should be overriden if there exists a trick to make this fast!</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<h4 id="laplace.lllaplace.FullLLLaplace.functional_variance_fast(X)" class="doc doc-heading doc-heading-parameter">              <b><code>X</code></b>
<a href="#laplace.lllaplace.FullLLLaplace.functional_variance_fast(X)" class="headerlink" title="Permanent link">#</a></h4>          –
          <div class="doc-md-description">
            
          </div>
        </li>
    </ul>


<p><span class="doc-section-title">Returns:</span></p>
    <ul>
        <li class="doc-section-item field-body">
<b><code>f_var_diag</code></b> (              <code>torch.Tensor of shape (batch_size, num_outputs)</code>
)          –
          <div class="doc-md-description">
            <p>Corresponding to the diagonal of the covariance matrix of the outputs</p>
          </div>
        </li>
    </ul>

            <details class="quote">
              <summary>Source code in <code>laplace/lllaplace.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-239">239</a></span>
<span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-0-239" name="__codelineno-0-239"></a><span class="k">def</span> <span class="nf">functional_variance_fast</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<a id="__codelineno-0-240" name="__codelineno-0-240"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<a id="__codelineno-0-241" name="__codelineno-0-241"></a><span class="sd">    Should be overriden if there exists a trick to make this fast!</span>
<a id="__codelineno-0-242" name="__codelineno-0-242"></a>
<a id="__codelineno-0-243" name="__codelineno-0-243"></a><span class="sd">    Parameters</span>
<a id="__codelineno-0-244" name="__codelineno-0-244"></a><span class="sd">    ----------</span>
<a id="__codelineno-0-245" name="__codelineno-0-245"></a><span class="sd">    X: torch.Tensor of shape (batch_size, input_dim)</span>
<a id="__codelineno-0-246" name="__codelineno-0-246"></a>
<a id="__codelineno-0-247" name="__codelineno-0-247"></a><span class="sd">    Returns</span>
<a id="__codelineno-0-248" name="__codelineno-0-248"></a><span class="sd">    -------</span>
<a id="__codelineno-0-249" name="__codelineno-0-249"></a><span class="sd">    f_var_diag: torch.Tensor of shape (batch_size, num_outputs)</span>
<a id="__codelineno-0-250" name="__codelineno-0-250"></a><span class="sd">        Corresponding to the diagonal of the covariance matrix of the outputs</span>
<a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="sd">    &quot;&quot;&quot;</span>
<a id="__codelineno-0-252" name="__codelineno-0-252"></a>    <span class="n">Js</span><span class="p">,</span> <span class="n">f_mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">last_layer_jacobians</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_backprop</span><span class="p">)</span>
<a id="__codelineno-0-253" name="__codelineno-0-253"></a>    <span class="n">f_cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">functional_variance</span><span class="p">(</span><span class="n">Js</span><span class="p">)</span>  <span class="c1"># No trick possible for Full Laplace</span>
<a id="__codelineno-0-254" name="__codelineno-0-254"></a>    <span class="n">f_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">f_cov</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-0-255" name="__codelineno-0-255"></a>    <span class="k">return</span> <span class="n">f_mu</span><span class="p">,</span> <span class="n">f_var</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../functionallaplace/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Functional Laplace">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Functional Laplace
              </div>
            </div>
          </a>
        
        
          
          <a href="../subnetlaplace/" class="md-footer__link md-footer__link--next" aria-label="Next: Subnet Laplace">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Subnet Laplace
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/aleximmer/laplace" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://pypi.org/project/laplace-torch/" target="_blank" rel="noopener" title="pypi.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.indexes", "navigation.tracking", "content.code.annotate", "toc.follow", "navigation.footer", "navigation.top", "content.code.copy", "content.tabs.link"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>